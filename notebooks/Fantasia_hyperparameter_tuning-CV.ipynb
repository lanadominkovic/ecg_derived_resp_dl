{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9ba2612-1125-40bb-b8b8-cca81e21d655",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-09 15:24:44.092842: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlana-caldarevic1\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "from keras import layers\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Reshape\n",
    "from keras.layers import Conv1D,UpSampling1D,MaxPooling1D,concatenate\n",
    "from keras.layers import BatchNormalization\n",
    "import keras.models as models\n",
    "from tensorflow.keras.callbacks import LambdaCallback, EarlyStopping\n",
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "from matplotlib import pyplot as plt\n",
    "import random\n",
    "\n",
    "import scipy.signal as signal\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "\n",
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0b1299a-4a0d-4583-abd0-b08a01373618",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(size_0, input_size, regularizer, dp, kernel_size):\n",
    "\tdata_shape = input_size\n",
    "\tsize_0=size_0\n",
    "\tsize_1=size_0*2\n",
    "\tsize_2=size_1*2\n",
    "\tkernel_size=kernel_size\n",
    "\tregularizer=regularizer\n",
    "\tdp=dp\n",
    "\n",
    "\tin_data= layers.Input(shape=(data_shape,1))\n",
    "\tconv0 = Conv1D(size_0, kernel_size ,kernel_regularizer=keras.regularizers.l2(regularizer), activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(in_data)\n",
    "\tconv0=BatchNormalization()(conv0)\n",
    "\tconv0 = Conv1D(size_0, kernel_size ,kernel_regularizer=keras.regularizers.l2(regularizer) ,  activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv0)\n",
    "\tconv0=BatchNormalization()(conv0)\n",
    "\tpool0 = MaxPooling1D(pool_size=2)(conv0)\n",
    "\tconv1 = Conv1D(size_1, kernel_size ,kernel_regularizer=keras.regularizers.l2(regularizer), activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool0)\n",
    "\tconv1=BatchNormalization()(conv1)\n",
    "\tconv1_2 = Conv1D(size_1, kernel_size ,kernel_regularizer=keras.regularizers.l2(regularizer) ,  activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\n",
    "\tconv1_2=BatchNormalization()(conv1_2)\n",
    "\tconv1_2=Dropout(dp)(conv1_2)\n",
    "\tpool1_2 = MaxPooling1D(pool_size=2)(conv1_2)\n",
    "\tconv2 = Conv1D(size_2, kernel_size ,kernel_regularizer=keras.regularizers.l2(regularizer) ,  activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1_2)\n",
    "\tconv2=BatchNormalization()(conv2)\n",
    "\tconv2 = Conv1D(size_2, kernel_size ,kernel_regularizer=keras.regularizers.l2(regularizer) ,  activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\n",
    "\tconv2=BatchNormalization()(conv2)\n",
    "\tup10 = Conv1D(size_2, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling1D(size = 2)(conv2))\n",
    "\tup10=BatchNormalization()(up10)\n",
    "\tmerge10 = concatenate([conv1_2,up10], axis = 2)\n",
    "\tconv10 = Conv1D(size_1, kernel_size ,kernel_regularizer=keras.regularizers.l2(regularizer) ,  activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge10)\n",
    "\tconv10=BatchNormalization()(conv10)\n",
    "\tconv10 = Conv1D(size_1, kernel_size ,kernel_regularizer=keras.regularizers.l2(regularizer) ,  activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv10)\n",
    "\tconv10=BatchNormalization()(conv10)\n",
    "\tconv10=Dropout(dp)(conv10)\n",
    "\tup10_1 = Conv1D(size_1, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling1D(size = 2)(conv10))\n",
    "\tup10_1=BatchNormalization()(up10_1)\n",
    "\tmerge10_1 = concatenate([conv0,up10_1], axis = 2)\n",
    "\tconv10 = Conv1D(size_0, kernel_size ,kernel_regularizer=keras.regularizers.l2(regularizer) ,  activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge10_1)\n",
    "\tconv10=BatchNormalization()(conv10)\n",
    "\tconv10 = Conv1D(size_0, kernel_size ,kernel_regularizer=keras.regularizers.l2(regularizer) ,  activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv10)\n",
    "\tconv10=BatchNormalization()(conv10)\n",
    "\tout_data = Conv1D(1, kernel_size, activation = 'sigmoid', padding='same')(conv10)\n",
    "\tmodel = models.Model(inputs=[in_data], outputs=[out_data])\n",
    "\tmodel.summary()\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc049a23-8447-4b8f-8f3d-b456846bc73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(config=None):\n",
    "    if config:\n",
    "        wandb.init(config=config, project=\"fantasia-hp-tuning\")\n",
    "    else:\n",
    "        wandb.init()\n",
    "        config = wandb.config\n",
    "\n",
    "    lr = wandb.config.learning_rate\n",
    "    regularizer = wandb.config.regularizer\n",
    "    dp = wandb.config.dp\n",
    "    start_filters = wandb.config.start_filters\n",
    "    kernel_size = wandb.config.kernel_size\n",
    "    batch_size = wandb.config.batch_size\n",
    "\n",
    "    seed = 0\n",
    "    train_val_patients, test_patients = train_test_split(patients, test_size=0.15, random_state=seed)\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "\n",
    "    sampling_rate = 250\n",
    "    seconds_window = 32\n",
    "    downsampled_window_size = 1024\n",
    "    window_size = sampling_rate * seconds_window\n",
    "\n",
    "    validation_results = []\n",
    "    train_results = []\n",
    "\n",
    "    for fold, (train_index, val_index) in enumerate(kf.split(train_val_patients)):\n",
    "        train_patients = [train_val_patients[i] for i in train_index]\n",
    "        val_patients = [train_val_patients[i] for i in val_index]\n",
    "\n",
    "        windows_ecg_train, windows_resp_train = process_data_segment(data_filled, window_size, downsampled_window_size, train_patients)\n",
    "        windows_ecg_validation, windows_resp_validation = process_data_segment(data_filled, window_size, downsampled_window_size, val_patients)\n",
    "\n",
    "        model = create_model(start_filters, 1024, regularizer, dp, kernel_size)\n",
    "        adm = tf.keras.optimizers.Adam(learning_rate=lr, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
    "        model.compile(loss='mse', metrics=[correlation, 'mse'], optimizer=adm)\n",
    "\n",
    "        def log_representations_images(epoch, logs):\n",
    "            wandb.log({\n",
    "                \"loss\": logs['loss'],\n",
    "                \"CC\": logs['correlation'],\n",
    "                \"mse\": logs['mse'],\n",
    "                \"val_loss\": logs['val_loss'],\n",
    "                \"val_CC\": logs['val_correlation'],\n",
    "                \"val_mse\": logs['val_mse']\n",
    "            })\n",
    "            fig, ax = plt.subplots(2, 2, figsize=(12, 8))\n",
    "            fig.suptitle('Ground truth vs. Prediction')\n",
    "\n",
    "            for row in range(2):\n",
    "                train_idx = np.random.randint(0, windows_ecg_train.shape[0])\n",
    "                val_idx = np.random.randint(0, windows_ecg_validation.shape[0])\n",
    "\n",
    "                to_predict_train = np.array([windows_ecg_train[train_idx]])\n",
    "                ground_truth_train = windows_resp_train[train_idx]\n",
    "                prediction_train = model.predict(to_predict_train)[0]\n",
    "                prediction_train_score = model.evaluate(to_predict_train, np.array([ground_truth_train]), verbose=0)\n",
    "\n",
    "                to_predict_validation = np.array([windows_ecg_validation[val_idx]])\n",
    "                ground_truth_validation = windows_resp_validation[val_idx]\n",
    "                prediction_validation = model.predict(to_predict_validation)[0]\n",
    "                prediction_validation_score = model.evaluate(to_predict_validation, np.array([ground_truth_validation]), verbose=0)\n",
    "\n",
    "                ax[row, 0].plot(ground_truth_train, label='Ground Truth')\n",
    "                ax[row, 0].plot(prediction_train, label='Prediction')\n",
    "                ax[row, 0].set_title(f\"Train Loss: {prediction_train_score[0]:.4f}\")\n",
    "                ax[row, 0].legend()\n",
    "\n",
    "                ax[row, 1].plot(ground_truth_validation, label='Ground Truth')\n",
    "                ax[row, 1].plot(prediction_validation, label='Prediction')\n",
    "                ax[row, 1].set_title(f\"Valid Loss: {prediction_validation_score[0]:.4f}\")\n",
    "                ax[row, 1].legend()\n",
    "\n",
    "            wandb.log({\n",
    "                \"predictions_visualization\": wandb.Image(fig)\n",
    "            }, commit=False)\n",
    "            plt.close(fig)\n",
    "\n",
    "        # Early stopping callback\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "        run_name = wandb.run.name\n",
    "        checkpoint_path = f\"/home/lcaldarevic/workspace/ecg_derived_resp_dl/notebooks/models/{run_name}.weights.h5\"\n",
    "        checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "        cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                         save_weights_only=True,\n",
    "                                                         save_best_only=True,\n",
    "                                                         verbose=1)\n",
    "\n",
    "        print(\"model training starting\")\n",
    "        print(windows_ecg_train[:, :, :].shape)\n",
    "        history = model.fit(\n",
    "            windows_ecg_train[:, :, :], windows_resp_train[:, :, :],\n",
    "            epochs=200,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=True,\n",
    "            callbacks=[\n",
    "                LambdaCallback(on_epoch_end=log_representations_images),\n",
    "                early_stopping,\n",
    "                cp_callback\n",
    "            ],\n",
    "            validation_data=(windows_ecg_validation[:, :, :], windows_resp_validation[:, :, :])\n",
    "        )\n",
    "\n",
    "        # Log fold-specific results\n",
    "        val_loss = np.min(history.history['val_loss'])\n",
    "        val_cc = np.max(history.history['val_correlation'])\n",
    "        val_mse = np.min(history.history['val_mse'])\n",
    "\n",
    "        validation_results.append((val_loss, val_cc, val_mse))\n",
    "\n",
    "        wandb.log({\n",
    "            \"fold\": fold + 1,\n",
    "            \"val_loss\": val_loss,\n",
    "            \"val_cc\": val_cc,\n",
    "            \"val_mse\": val_mse\n",
    "        })\n",
    "\n",
    "        print(f\"Fold {fold+1} - Valid Loss: {val_loss:.4f}\")\n",
    "        print(f\"Fold {fold+1} - Valid Correlation: {val_cc:.4f}\")\n",
    "        print(f\"Fold {fold+1} - Valid MSE: {val_mse:.4f}\")\n",
    "\n",
    "        # Optionally, evaluate on the training set\n",
    "        train_loss = np.min(history.history['loss'])\n",
    "        train_cc = np.max(history.history['correlation'])\n",
    "        train_mse = np.min(history.history['mse'])\n",
    "\n",
    "        train_results.append((train_loss, train_cc, train_mse))\n",
    "\n",
    "        wandb.log({\n",
    "            \"fold\": fold + 1,\n",
    "            \"train_loss\": train_loss,\n",
    "            \"train_cc\": train_cc,\n",
    "            \"train_mse\": train_mse\n",
    "        })\n",
    "\n",
    "        print(f\"Fold {fold+1} - Train Loss: {train_loss:.4f}\")\n",
    "        print(f\"Fold {fold+1} - Train Correlation: {train_cc:.4f}\")\n",
    "        print(f\"Fold {fold+1} - Train MSE: {train_mse:.4f}\")\n",
    "\n",
    "    # Aggregate final results across all folds\n",
    "    avg_valid_loss = np.mean([res[0] for res in validation_results])\n",
    "    avg_valid_cc = np.mean([res[1] for res in validation_results])\n",
    "    avg_valid_mse = np.mean([res[2] for res in validation_results])\n",
    "\n",
    "    avg_train_loss = np.mean([res[0] for res in train_results])\n",
    "    avg_train_cc = np.mean([res[1] for res in train_results])\n",
    "    avg_train_mse = np.mean([res[2] for res in train_results])\n",
    "\n",
    "    # Log the aggregated results to W&B\n",
    "    wandb.log({\n",
    "        \"avg_valid_loss\": avg_valid_loss,\n",
    "        \"avg_valid_cc\": avg_valid_cc,\n",
    "        \"avg_valid_mse\": avg_valid_mse,\n",
    "        \"avg_train_loss\": avg_train_loss,\n",
    "        \"avg_train_cc\": avg_train_cc,\n",
    "        \"avg_train_mse\": avg_train_mse\n",
    "    })\n",
    "\n",
    "    print(f\"Average Valid Loss: {avg_valid_loss:.4f}\")\n",
    "    print(f\"Average Valid Correlation: {avg_valid_cc:.4f}\")\n",
    "    print(f\"Average Valid MSE: {avg_valid_mse:.4f}\")\n",
    "\n",
    "    print(f\"Average Train Loss: {avg_train_loss:.4f}\")\n",
    "    print(f\"Average Train Correlation: {avg_train_cc:.4f}\")\n",
    "    print(f\"Average Train MSE: {avg_train_mse:.4f}\")\n",
    "\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35b88f3d-262b-455d-b13f-b08c1918347f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def correlation(x, y):\n",
    "    min_y = tf.math.reduce_min(y)\n",
    "    max_y = tf.math.reduce_max(y)\n",
    "    r_up = tf.math.subtract(y, min_y)\n",
    "    r_down = max_y - min_y\n",
    "    new_y = r_up / r_down\n",
    "    \n",
    "    mx = tf.math.reduce_mean(x)\n",
    "    my = tf.math.reduce_mean(y)\n",
    "    xm, ym = x - mx, y - my\n",
    "    r_num = tf.reduce_sum(tf.multiply(xm, ym))\n",
    "    r_den = tf.sqrt(tf.multiply(tf.reduce_sum(tf.square(xm)), tf.reduce_sum(tf.square(ym))))\n",
    "    r = r_num / r_den\n",
    "    r = tf.maximum(tf.minimum(r, 1.0), -1.0)\n",
    "    \n",
    "    return 1 - r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ebedd41-7a74-44c7-8ab1-c05890987be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wfdb\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "def load_fantasia():\n",
    "    files = os.listdir(\"/home/lcaldarevic/workspace/fantasia-database-1.0.0/\")\n",
    "    files = [s.replace('.dat', '') for s in files if \".dat\" in s]\n",
    "    \n",
    "    data_fantasia = {}\n",
    "    patients_fantasia = []\n",
    "    \n",
    "    for i, participant in enumerate(files):\n",
    "        patients_fantasia.append(participant)\n",
    "    \n",
    "        data, info = wfdb.rdsamp(\"/home/lcaldarevic/workspace/fantasia-database-1.0.0/\" + participant)\n",
    "    \n",
    "        # Get signal\n",
    "        data = pd.DataFrame(data, columns=info[\"sig_name\"])\n",
    "        data_fantasia[participant] = np.array([data[\"ECG\"], data[\"RESP\"]])\n",
    "\n",
    "    return data_fantasia, patients_fantasia\n",
    "\n",
    "data, patients = load_fantasia()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a797001b-99ca-4a7e-9a9a-f2830601872a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data_segment(data, window_size, downsampled_window_size, patient_indices, method='clipping'):\n",
    "    overlap = 1 / 2\n",
    "\n",
    "    windows_ecg = []\n",
    "    windows_resp = []\n",
    "\n",
    "    for record_index in patient_indices:\n",
    "        N = len(data[record_index][0, :])\n",
    "        max_step = int(N // (window_size * overlap))\n",
    "        for step in range(1, max_step - 1):\n",
    "            start_idx = int(step) * int(window_size * overlap)\n",
    "            end_idx = start_idx + window_size\n",
    "            recrd_ecg = data[record_index][0, start_idx:end_idx]\n",
    "            recrd_resp = data[record_index][1, start_idx:end_idx]\n",
    "\n",
    "            if recrd_ecg.min() < recrd_ecg.max():\n",
    "                # Normalize ECG using mean and std deviation\n",
    "                #normalized_ecg = (recrd_ecg - recrd_ecg.mean()) / recrd_ecg.std()\n",
    "\n",
    "                normalized_ecg = (recrd_ecg - recrd_ecg.min()) / (recrd_ecg.max() - recrd_ecg.min())\n",
    "                normalized_ecg = signal.resample(normalized_ecg, downsampled_window_size)\n",
    "\n",
    "                if recrd_resp.min() < recrd_resp.max():\n",
    "                    normalized_resp = (recrd_resp - recrd_resp.min()) / (recrd_resp.max() - recrd_resp.min())\n",
    "                    normalized_resp = signal.resample(normalized_resp, downsampled_window_size)\n",
    "                    \n",
    "                    windows_ecg.append(np.float32(normalized_ecg))\n",
    "                    windows_resp.append(np.float32(normalized_resp))\n",
    "\n",
    "\n",
    "    windows_ecg = np.array(windows_ecg)[:, :, np.newaxis]\n",
    "    windows_resp = np.array(windows_resp)[:, :, np.newaxis]\n",
    "\n",
    "    print(windows_ecg.shape)\n",
    "    print(windows_resp.shape)\n",
    "\n",
    "    return windows_ecg, windows_resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24b4a038-a46e-4da7-b5d9-71172ba423cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN values found in patient data index: f2o10\n",
      "NaN values found in patient data index: f2y09\n",
      "NaN values found in patient data index: f2o06\n",
      "NaN values found in patient data index: f2y10\n",
      "NaN values found in patient data index: f2o09\n",
      "NaN values found in patient data index: f2y01\n",
      "NaN values found in patient data index: f2y08\n",
      "NaN values found in patient data index: f2y05\n",
      "NaN values found in patient data index: f2o05\n",
      "NaN values found in patient data index: f2o02\n"
     ]
    }
   ],
   "source": [
    "import neurokit2 as nk\n",
    "sampling_rate = 250\n",
    "def fill_nan_values(data):\n",
    "    filled_data = {}\n",
    "    for participant, signals in data.items():\n",
    "        ecg_data = signals[0, :]\n",
    "        resp_data = signals[1, :]\n",
    "\n",
    "        ecg_filled = nk.signal_interpolate(ecg_data, method='linear')\n",
    "        ecg_filled = nk.ecg_clean(ecg_filled, sampling_rate=sampling_rate, method=\"neurokit\")\n",
    "        \n",
    "        resp_filled = nk.signal_interpolate(resp_data, method='linear')\n",
    "        resp_filled = nk.rsp_clean(resp_filled, sampling_rate=sampling_rate)\n",
    "        \n",
    "        filled_data[participant] = np.vstack((ecg_filled, resp_filled))\n",
    "    \n",
    "    return filled_data\n",
    "\n",
    "def check_for_nan(data, patients):\n",
    "    for patient in patients:\n",
    "        if np.isnan(data[patient]).any():\n",
    "            print(f\"NaN values found in patient data index: {patient}\")\n",
    "\n",
    "check_for_nan(data, patients)\n",
    "\n",
    "data_filled = fill_nan_values(data)\n",
    "\n",
    "check_for_nan(data_filled, patients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a294c0fd-5e5d-496d-9ee1-cbf1fecaeab0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11930, 1024, 1)\n",
      "(11930, 1024, 1)\n",
      "(3115, 1024, 1)\n",
      "(3115, 1024, 1)\n",
      "(2804, 1024, 1)\n",
      "(2804, 1024, 1)\n"
     ]
    }
   ],
   "source": [
    "seed = 0\n",
    "train_val_patients, test_patients = train_test_split(patients, test_size=0.15, random_state=seed)\n",
    "train_val_patients_array = np.array(train_val_patients)\n",
    "\n",
    "train_patients, val_patients = train_test_split(train_val_patients, test_size=0.20, random_state=seed)\n",
    "\n",
    "sampling_rate = 250\n",
    "seconds_window = 32\n",
    "downsampled_window_size = 1024 # signal size\n",
    "window_size = sampling_rate * seconds_window # window size to split by\n",
    "\n",
    "windows_ecg_train, windows_resp_train = process_data_segment(data_filled, window_size, downsampled_window_size, train_patients)\n",
    "windows_ecg_validation, windows_resp_validation = process_data_segment(data_filled, window_size, downsampled_window_size, val_patients)\n",
    "windows_ecg_test, windows_resp_test = process_data_segment(data_filled, window_size, downsampled_window_size, test_patients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e2aac3d8-cd24-40d7-a6c6-82ea683576f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(windows_ecg_train.flatten(), bins=100, alpha=0.7, label=\"ecg train\")\n",
    "plt.hist(windows_ecg_validation.flatten(), bins=100, alpha=0.7, label=\"ecg valid\")\n",
    "plt.hist(windows_ecg_test.flatten(), bins=100, alpha=0.7, label=\"ecg test\")\n",
    "plt.title('Distribution of ECG Values')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.hist(windows_resp_train.flatten(), bins=100, alpha=0.7, label=\"resp train\")\n",
    "plt.hist(windows_resp_validation.flatten(), bins=100, alpha=0.7, label=\"resp valid\")\n",
    "plt.hist(windows_resp_test.flatten(), bins=100, alpha=0.7, label=\"resp test\")\n",
    "plt.title('Distribution of RESP Values')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2a678f5e-62c4-4730-a4d8-eb53b3dc4294",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sweep_config():\n",
    "    return {\n",
    "        'method': 'random',\n",
    "        'metric': {\n",
    "            'name': 'val_loss',\n",
    "            'goal': 'minimize'\n",
    "        },\n",
    "        'parameters': {\n",
    "             'learning_rate': {\n",
    "                'distribution': 'log_uniform_values',\n",
    "                'min': 1e-4,\n",
    "                'max': 1e-2\n",
    "            },\n",
    "            'regularizer': {\n",
    "                'distribution': 'log_uniform_values',\n",
    "                'min': 1e-4,\n",
    "                'max': 1e-1\n",
    "            },\n",
    "            'dp': {\n",
    "                'values': [0.1, 0.3, 0.5]\n",
    "            },\n",
    "            'start_filters': {\n",
    "                'values': [4, 8, 16]\n",
    "            },\n",
    "            'kernel_size': {\n",
    "                'values': [13, 27, 51]\n",
    "            },\n",
    "            'batch_size': {\n",
    "                'values': [256]\n",
    "            }\n",
    "            \n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a06f8b-3ac8-4baa-aabf-48295fc8d5f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: mv0u3xpn\n",
      "Sweep URL: https://wandb.ai/lana-caldarevic1/fantasia-hp-tuning/sweeps/mv0u3xpn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 3eq9gdf6 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdp: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tkernel_size: 27\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.00023118241530099864\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tregularizer: 0.00019638536555924684\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tstart_filters: 8\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/lcaldarevic/workspace/ecg_derived_resp_dl/notebooks/wandb/run-20240708_143529-3eq9gdf6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/lana-caldarevic1/fantasia-hp-tuning/runs/3eq9gdf6' target=\"_blank\">confused-sweep-1</a></strong> to <a href='https://wandb.ai/lana-caldarevic1/fantasia-hp-tuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/lana-caldarevic1/fantasia-hp-tuning/sweeps/mv0u3xpn' target=\"_blank\">https://wandb.ai/lana-caldarevic1/fantasia-hp-tuning/sweeps/mv0u3xpn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/lana-caldarevic1/fantasia-hp-tuning' target=\"_blank\">https://wandb.ai/lana-caldarevic1/fantasia-hp-tuning</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/lana-caldarevic1/fantasia-hp-tuning/sweeps/mv0u3xpn' target=\"_blank\">https://wandb.ai/lana-caldarevic1/fantasia-hp-tuning/sweeps/mv0u3xpn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/lana-caldarevic1/fantasia-hp-tuning/runs/3eq9gdf6' target=\"_blank\">https://wandb.ai/lana-caldarevic1/fantasia-hp-tuning/runs/3eq9gdf6</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-08 14:35:35.103330: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1015 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "2024-07-08 14:35:35.104057: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 22198 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:21:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"font-weight: bold\"> Layer (type)        </span><span style=\"font-weight: bold\"> Output Shape      </span><span style=\"font-weight: bold\">    Param # </span><span style=\"font-weight: bold\"> Connected to      </span>\n",
       "\n",
       " input_layer          (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                                                          \n",
       "\n",
       " conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)      (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)           <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>  input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
       "\n",
       " batch_normalization  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)            <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>  conv1d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio</span>                                                   \n",
       "\n",
       " conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,736</span>  batch_normalizat \n",
       "\n",
       " batch_normalizatio  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)            <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>  conv1d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio</span>                                                   \n",
       "\n",
       " max_pooling1d        (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  batch_normalizat \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)                                                        \n",
       "\n",
       " conv1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,472</span>  max_pooling1d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
       "\n",
       " batch_normalizatio  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>  conv1d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio</span>                                                   \n",
       "\n",
       " conv1d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,928</span>  batch_normalizat \n",
       "\n",
       " batch_normalizatio  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>  conv1d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio</span>                                                   \n",
       "\n",
       " dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  batch_normalizat \n",
       "\n",
       " max_pooling1d_1      (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)                                                        \n",
       "\n",
       " conv1d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        <span style=\"color: #00af00; text-decoration-color: #00af00\">13,856</span>  max_pooling1d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\"></span> \n",
       "\n",
       " batch_normalizatio  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>  conv1d_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio</span>                                                   \n",
       "\n",
       " conv1d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        <span style=\"color: #00af00; text-decoration-color: #00af00\">27,680</span>  batch_normalizat \n",
       "\n",
       " batch_normalizatio  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>  conv1d_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio</span>                                                   \n",
       "\n",
       " up_sampling1d        (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  batch_normalizat \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">UpSampling1D</span>)                                                        \n",
       "\n",
       " conv1d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span>  up_sampling1d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
       "\n",
       " batch_normalizatio  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>  conv1d_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio</span>                                                   \n",
       "\n",
       " concatenate          (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)                                       batch_normalizat \n",
       "\n",
       " conv1d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        <span style=\"color: #00af00; text-decoration-color: #00af00\">20,752</span>  concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
       "\n",
       " batch_normalizatio  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>  conv1d_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio</span>                                                   \n",
       "\n",
       " conv1d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,928</span>  batch_normalizat \n",
       "\n",
       " batch_normalizatio  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>  conv1d_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio</span>                                                   \n",
       "\n",
       " dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  batch_normalizat \n",
       "\n",
       " up_sampling1d_1      (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)            <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">UpSampling1D</span>)                                                        \n",
       "\n",
       " conv1d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)          <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span>  up_sampling1d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\"></span> \n",
       "\n",
       " batch_normalizatio  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)           <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>  conv1d_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio</span>                                                   \n",
       "\n",
       " concatenate_1        (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)            <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  batch_normalizat \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)                                       batch_normalizat \n",
       "\n",
       " conv1d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,192</span>  concatenate_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
       "\n",
       " batch_normalizatio  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)            <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>  conv1d_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio</span>                                                   \n",
       "\n",
       " conv1d_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,736</span>  batch_normalizat \n",
       "\n",
       " batch_normalizatio  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)            <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>  conv1d_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio</span>                                                   \n",
       "\n",
       " conv1d_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)           <span style=\"color: #00af00; text-decoration-color: #00af00\">217</span>  batch_normalizat \n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m\n",
       "\n",
       " input_layer          (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m, \u001b[38;5;34m1\u001b[0m)             \u001b[38;5;34m0\u001b[0m  -                 \n",
       " (\u001b[38;5;33mInputLayer\u001b[0m)                                                          \n",
       "\n",
       " conv1d (\u001b[38;5;33mConv1D\u001b[0m)      (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m, \u001b[38;5;34m8\u001b[0m)           \u001b[38;5;34m224\u001b[0m  input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] \n",
       "\n",
       " batch_normalization  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m, \u001b[38;5;34m8\u001b[0m)            \u001b[38;5;34m32\u001b[0m  conv1d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      \n",
       " (\u001b[38;5;33mBatchNormalizatio\u001b[0m                                                   \n",
       "\n",
       " conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m, \u001b[38;5;34m8\u001b[0m)         \u001b[38;5;34m1,736\u001b[0m  batch_normalizat \n",
       "\n",
       " batch_normalizatio  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m, \u001b[38;5;34m8\u001b[0m)            \u001b[38;5;34m32\u001b[0m  conv1d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    \n",
       " (\u001b[38;5;33mBatchNormalizatio\u001b[0m                                                   \n",
       "\n",
       " max_pooling1d        (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m8\u001b[0m)              \u001b[38;5;34m0\u001b[0m  batch_normalizat \n",
       " (\u001b[38;5;33mMaxPooling1D\u001b[0m)                                                        \n",
       "\n",
       " conv1d_2 (\u001b[38;5;33mConv1D\u001b[0m)    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m16\u001b[0m)         \u001b[38;5;34m3,472\u001b[0m  max_pooling1d[\u001b[38;5;34m0\u001b[0m] \n",
       "\n",
       " batch_normalizatio  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m16\u001b[0m)            \u001b[38;5;34m64\u001b[0m  conv1d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    \n",
       " (\u001b[38;5;33mBatchNormalizatio\u001b[0m                                                   \n",
       "\n",
       " conv1d_3 (\u001b[38;5;33mConv1D\u001b[0m)    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m16\u001b[0m)         \u001b[38;5;34m6,928\u001b[0m  batch_normalizat \n",
       "\n",
       " batch_normalizatio  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m16\u001b[0m)            \u001b[38;5;34m64\u001b[0m  conv1d_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    \n",
       " (\u001b[38;5;33mBatchNormalizatio\u001b[0m                                                   \n",
       "\n",
       " dropout (\u001b[38;5;33mDropout\u001b[0m)    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m16\u001b[0m)             \u001b[38;5;34m0\u001b[0m  batch_normalizat \n",
       "\n",
       " max_pooling1d_1      (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m16\u001b[0m)             \u001b[38;5;34m0\u001b[0m  dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     \n",
       " (\u001b[38;5;33mMaxPooling1D\u001b[0m)                                                        \n",
       "\n",
       " conv1d_4 (\u001b[38;5;33mConv1D\u001b[0m)    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m32\u001b[0m)        \u001b[38;5;34m13,856\u001b[0m  max_pooling1d_1[\u001b[38;5;34m\u001b[0m \n",
       "\n",
       " batch_normalizatio  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m32\u001b[0m)           \u001b[38;5;34m128\u001b[0m  conv1d_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    \n",
       " (\u001b[38;5;33mBatchNormalizatio\u001b[0m                                                   \n",
       "\n",
       " conv1d_5 (\u001b[38;5;33mConv1D\u001b[0m)    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m32\u001b[0m)        \u001b[38;5;34m27,680\u001b[0m  batch_normalizat \n",
       "\n",
       " batch_normalizatio  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m32\u001b[0m)           \u001b[38;5;34m128\u001b[0m  conv1d_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    \n",
       " (\u001b[38;5;33mBatchNormalizatio\u001b[0m                                                   \n",
       "\n",
       " up_sampling1d        (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m32\u001b[0m)             \u001b[38;5;34m0\u001b[0m  batch_normalizat \n",
       " (\u001b[38;5;33mUpSampling1D\u001b[0m)                                                        \n",
       "\n",
       " conv1d_6 (\u001b[38;5;33mConv1D\u001b[0m)    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m32\u001b[0m)         \u001b[38;5;34m2,080\u001b[0m  up_sampling1d[\u001b[38;5;34m0\u001b[0m] \n",
       "\n",
       " batch_normalizatio  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m32\u001b[0m)           \u001b[38;5;34m128\u001b[0m  conv1d_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    \n",
       " (\u001b[38;5;33mBatchNormalizatio\u001b[0m                                                   \n",
       "\n",
       " concatenate          (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m48\u001b[0m)             \u001b[38;5;34m0\u001b[0m  dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    \n",
       " (\u001b[38;5;33mConcatenate\u001b[0m)                                       batch_normalizat \n",
       "\n",
       " conv1d_7 (\u001b[38;5;33mConv1D\u001b[0m)    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m16\u001b[0m)        \u001b[38;5;34m20,752\u001b[0m  concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] \n",
       "\n",
       " batch_normalizatio  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m16\u001b[0m)            \u001b[38;5;34m64\u001b[0m  conv1d_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    \n",
       " (\u001b[38;5;33mBatchNormalizatio\u001b[0m                                                   \n",
       "\n",
       " conv1d_8 (\u001b[38;5;33mConv1D\u001b[0m)    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m16\u001b[0m)         \u001b[38;5;34m6,928\u001b[0m  batch_normalizat \n",
       "\n",
       " batch_normalizatio  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m16\u001b[0m)            \u001b[38;5;34m64\u001b[0m  conv1d_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    \n",
       " (\u001b[38;5;33mBatchNormalizatio\u001b[0m                                                   \n",
       "\n",
       " dropout_1 (\u001b[38;5;33mDropout\u001b[0m)  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m16\u001b[0m)             \u001b[38;5;34m0\u001b[0m  batch_normalizat \n",
       "\n",
       " up_sampling1d_1      (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m, \u001b[38;5;34m16\u001b[0m)            \u001b[38;5;34m0\u001b[0m  dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   \n",
       " (\u001b[38;5;33mUpSampling1D\u001b[0m)                                                        \n",
       "\n",
       " conv1d_9 (\u001b[38;5;33mConv1D\u001b[0m)    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m, \u001b[38;5;34m16\u001b[0m)          \u001b[38;5;34m528\u001b[0m  up_sampling1d_1[\u001b[38;5;34m\u001b[0m \n",
       "\n",
       " batch_normalizatio  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m, \u001b[38;5;34m16\u001b[0m)           \u001b[38;5;34m64\u001b[0m  conv1d_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    \n",
       " (\u001b[38;5;33mBatchNormalizatio\u001b[0m                                                   \n",
       "\n",
       " concatenate_1        (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m, \u001b[38;5;34m24\u001b[0m)            \u001b[38;5;34m0\u001b[0m  batch_normalizat \n",
       " (\u001b[38;5;33mConcatenate\u001b[0m)                                       batch_normalizat \n",
       "\n",
       " conv1d_10 (\u001b[38;5;33mConv1D\u001b[0m)   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m, \u001b[38;5;34m8\u001b[0m)         \u001b[38;5;34m5,192\u001b[0m  concatenate_1[\u001b[38;5;34m0\u001b[0m] \n",
       "\n",
       " batch_normalizatio  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m, \u001b[38;5;34m8\u001b[0m)            \u001b[38;5;34m32\u001b[0m  conv1d_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   \n",
       " (\u001b[38;5;33mBatchNormalizatio\u001b[0m                                                   \n",
       "\n",
       " conv1d_11 (\u001b[38;5;33mConv1D\u001b[0m)   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m, \u001b[38;5;34m8\u001b[0m)         \u001b[38;5;34m1,736\u001b[0m  batch_normalizat \n",
       "\n",
       " batch_normalizatio  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m, \u001b[38;5;34m8\u001b[0m)            \u001b[38;5;34m32\u001b[0m  conv1d_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   \n",
       " (\u001b[38;5;33mBatchNormalizatio\u001b[0m                                                   \n",
       "\n",
       " conv1d_12 (\u001b[38;5;33mConv1D\u001b[0m)   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m, \u001b[38;5;34m1\u001b[0m)           \u001b[38;5;34m217\u001b[0m  batch_normalizat \n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">92,161</span> (360.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m92,161\u001b[0m (360.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">91,745</span> (358.38 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m91,745\u001b[0m (358.38 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">416</span> (1.62 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m416\u001b[0m (1.62 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model training starting\n",
      "(11930, 1024, 1)\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1720442139.515845 3857417 service.cc:145] XLA service 0x7946f002ded0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1720442139.515898 3857417 service.cc:153]   StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6\n",
      "I0000 00:00:1720442139.515902 3857417 service.cc:153]   StreamExecutor device (1): NVIDIA GeForce RTX 3090, Compute Capability 8.6\n",
      "2024-07-08 14:35:39.665259: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-07-08 14:35:40.154410: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 5/47\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - correlation: 1.0036 - loss: 0.1958 - mse: 0.1324"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1720442151.499125 3857417 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 745ms/stepep - correlation: 0.9899 - loss: 0.1820 - mse: 0.11\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.13592, saving model to /home/lcaldarevic/workspace/ecg_derived_resp_dl/notebooks/models/confused-sweep-1.weights.h5\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 332ms/step - correlation: 0.9897 - loss: 0.1817 - mse: 0.1191 - val_correlation: 0.9846 - val_loss: 0.1359 - val_mse: 0.0759\n",
      "Epoch 2/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/stepep - correlation: 0.9623 - loss: 0.1377 - mse: 0.078\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\n",
      "Epoch 2: val_loss improved from 0.13592 to 0.12611, saving model to /home/lcaldarevic/workspace/ecg_derived_resp_dl/notebooks/models/confused-sweep-1.weights.h5\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - correlation: 0.9621 - loss: 0.1376 - mse: 0.0787 - val_correlation: 0.9669 - val_loss: 0.1261 - val_mse: 0.0709\n",
      "Epoch 3/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/stepep - correlation: 0.9008 - loss: 0.1241 - mse: 0.070\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\n",
      "Epoch 3: val_loss improved from 0.12611 to 0.11697, saving model to /home/lcaldarevic/workspace/ecg_derived_resp_dl/notebooks/models/confused-sweep-1.weights.h5\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 53ms/step - correlation: 0.9001 - loss: 0.1240 - mse: 0.0701 - val_correlation: 0.9480 - val_loss: 0.1170 - val_mse: 0.0671\n",
      "Epoch 4/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/stepep - correlation: 0.7235 - loss: 0.1106 - mse: 0.061\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\n",
      "Epoch 4: val_loss improved from 0.11697 to 0.10485, saving model to /home/lcaldarevic/workspace/ecg_derived_resp_dl/notebooks/models/confused-sweep-1.weights.h5\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - correlation: 0.7228 - loss: 0.1105 - mse: 0.0619 - val_correlation: 0.8488 - val_loss: 0.1048 - val_mse: 0.0600\n",
      "Epoch 5/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/stepep - correlation: 0.6041 - loss: 0.0978 - mse: 0.054\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\n",
      "Epoch 5: val_loss improved from 0.10485 to 0.09698, saving model to /home/lcaldarevic/workspace/ecg_derived_resp_dl/notebooks/models/confused-sweep-1.weights.h5\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - correlation: 0.6037 - loss: 0.0978 - mse: 0.0540 - val_correlation: 0.7633 - val_loss: 0.0970 - val_mse: 0.0566\n",
      "Epoch 6/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/stepep - correlation: 0.5186 - loss: 0.0871 - mse: 0.047\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\n",
      "Epoch 6: val_loss improved from 0.09698 to 0.08850, saving model to /home/lcaldarevic/workspace/ecg_derived_resp_dl/notebooks/models/confused-sweep-1.weights.h5\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - correlation: 0.5177 - loss: 0.0870 - mse: 0.0476 - val_correlation: 0.6639 - val_loss: 0.0885 - val_mse: 0.0519\n",
      "Epoch 7/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/stepep - correlation: 0.4600 - loss: 0.0791 - mse: 0.043\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\n",
      "Epoch 7: val_loss improved from 0.08850 to 0.08282, saving model to /home/lcaldarevic/workspace/ecg_derived_resp_dl/notebooks/models/confused-sweep-1.weights.h5\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - correlation: 0.4590 - loss: 0.0790 - mse: 0.0433 - val_correlation: 0.5843 - val_loss: 0.0828 - val_mse: 0.0494\n",
      "Epoch 8/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/stepep - correlation: 0.4085 - loss: 0.0724 - mse: 0.039\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\n",
      "Epoch 8: val_loss improved from 0.08282 to 0.08002, saving model to /home/lcaldarevic/workspace/ecg_derived_resp_dl/notebooks/models/confused-sweep-1.weights.h5\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - correlation: 0.4080 - loss: 0.0723 - mse: 0.0396 - val_correlation: 0.5434 - val_loss: 0.0800 - val_mse: 0.0493\n",
      "Epoch 9/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/stepep - correlation: 0.3771 - loss: 0.0674 - mse: 0.037\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\n",
      "Epoch 9: val_loss improved from 0.08002 to 0.07680, saving model to /home/lcaldarevic/workspace/ecg_derived_resp_dl/notebooks/models/confused-sweep-1.weights.h5\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - correlation: 0.3767 - loss: 0.0674 - mse: 0.0373 - val_correlation: 0.5228 - val_loss: 0.0768 - val_mse: 0.0484\n",
      "Epoch 10/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/stepep - correlation: 0.3536 - loss: 0.0633 - mse: 0.035\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\n",
      "Epoch 10: val_loss improved from 0.07680 to 0.07514, saving model to /home/lcaldarevic/workspace/ecg_derived_resp_dl/notebooks/models/confused-sweep-1.weights.h5\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - correlation: 0.3532 - loss: 0.0633 - mse: 0.0354 - val_correlation: 0.5191 - val_loss: 0.0751 - val_mse: 0.0487\n",
      "Epoch 11/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/stepep - correlation: 0.3322 - loss: 0.0598 - mse: 0.033\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\n",
      "Epoch 11: val_loss improved from 0.07514 to 0.07061, saving model to /home/lcaldarevic/workspace/ecg_derived_resp_dl/notebooks/models/confused-sweep-1.weights.h5\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - correlation: 0.3320 - loss: 0.0597 - mse: 0.0337 - val_correlation: 0.4948 - val_loss: 0.0706 - val_mse: 0.0458\n",
      "Epoch 12/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/stepep - correlation: 0.3174 - loss: 0.0570 - mse: 0.032\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\n",
      "Epoch 12: val_loss improved from 0.07061 to 0.06892, saving model to /home/lcaldarevic/workspace/ecg_derived_resp_dl/notebooks/models/confused-sweep-1.weights.h5\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - correlation: 0.3172 - loss: 0.0570 - mse: 0.0326 - val_correlation: 0.4982 - val_loss: 0.0689 - val_mse: 0.0456\n",
      "Epoch 13/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/stepep - correlation: 0.3033 - loss: 0.0542 - mse: 0.031\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\n",
      "Epoch 13: val_loss improved from 0.06892 to 0.06790, saving model to /home/lcaldarevic/workspace/ecg_derived_resp_dl/notebooks/models/confused-sweep-1.weights.h5\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - correlation: 0.3032 - loss: 0.0542 - mse: 0.0313 - val_correlation: 0.5085 - val_loss: 0.0679 - val_mse: 0.0459\n",
      "Epoch 14/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/stepep - correlation: 0.2948 - loss: 0.0523 - mse: 0.030\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\n",
      "Epoch 14: val_loss improved from 0.06790 to 0.06397, saving model to /home/lcaldarevic/workspace/ecg_derived_resp_dl/notebooks/models/confused-sweep-1.weights.h5\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - correlation: 0.2947 - loss: 0.0523 - mse: 0.0307 - val_correlation: 0.4945 - val_loss: 0.0640 - val_mse: 0.0432\n",
      "Epoch 15/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/stepep - correlation: 0.2829 - loss: 0.0502 - mse: 0.029\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\n",
      "Epoch 15: val_loss did not improve from 0.06397\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - correlation: 0.2829 - loss: 0.0502 - mse: 0.0297 - val_correlation: 0.5112 - val_loss: 0.0640 - val_mse: 0.0443\n",
      "Epoch 16/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/stepep - correlation: 0.2772 - loss: 0.0485 - mse: 0.029\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\n",
      "Epoch 16: val_loss improved from 0.06397 to 0.06253, saving model to /home/lcaldarevic/workspace/ecg_derived_resp_dl/notebooks/models/confused-sweep-1.weights.h5\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 55ms/step - correlation: 0.2772 - loss: 0.0485 - mse: 0.0290 - val_correlation: 0.4992 - val_loss: 0.0625 - val_mse: 0.0437\n",
      "Epoch 17/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/stepep - correlation: 0.2712 - loss: 0.0472 - mse: 0.028\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\n",
      "Epoch 17: val_loss improved from 0.06253 to 0.06163, saving model to /home/lcaldarevic/workspace/ecg_derived_resp_dl/notebooks/models/confused-sweep-1.weights.h5\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - correlation: 0.2712 - loss: 0.0472 - mse: 0.0286 - val_correlation: 0.4930 - val_loss: 0.0616 - val_mse: 0.0437\n",
      "Epoch 18/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/stepep - correlation: 0.2635 - loss: 0.0458 - mse: 0.028\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\n",
      "Epoch 18: val_loss improved from 0.06163 to 0.06096, saving model to /home/lcaldarevic/workspace/ecg_derived_resp_dl/notebooks/models/confused-sweep-1.weights.h5\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - correlation: 0.2635 - loss: 0.0458 - mse: 0.0281 - val_correlation: 0.4843 - val_loss: 0.0610 - val_mse: 0.0438\n",
      "Epoch 19/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/stepep - correlation: 0.2613 - loss: 0.0447 - mse: 0.027\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\n",
      "Epoch 19: val_loss improved from 0.06096 to 0.06051, saving model to /home/lcaldarevic/workspace/ecg_derived_resp_dl/notebooks/models/confused-sweep-1.weights.h5\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - correlation: 0.2612 - loss: 0.0447 - mse: 0.0278 - val_correlation: 0.4991 - val_loss: 0.0605 - val_mse: 0.0441\n",
      "Epoch 20/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/stepep - correlation: 0.2561 - loss: 0.0434 - mse: 0.027\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\n",
      "Epoch 20: val_loss improved from 0.06051 to 0.05928, saving model to /home/lcaldarevic/workspace/ecg_derived_resp_dl/notebooks/models/confused-sweep-1.weights.h5\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - correlation: 0.2560 - loss: 0.0434 - mse: 0.0272 - val_correlation: 0.4872 - val_loss: 0.0593 - val_mse: 0.0436\n",
      "Epoch 21/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/stepep - correlation: 0.2495 - loss: 0.0423 - mse: 0.026\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\n",
      "Epoch 21: val_loss improved from 0.05928 to 0.05907, saving model to /home/lcaldarevic/workspace/ecg_derived_resp_dl/notebooks/models/confused-sweep-1.weights.h5\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - correlation: 0.2496 - loss: 0.0423 - mse: 0.0267 - val_correlation: 0.4981 - val_loss: 0.0591 - val_mse: 0.0440\n",
      "Epoch 22/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/stepep - correlation: 0.2450 - loss: 0.0412 - mse: 0.026\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\n",
      "Epoch 22: val_loss did not improve from 0.05907\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - correlation: 0.2451 - loss: 0.0412 - mse: 0.0263 - val_correlation: 0.4921 - val_loss: 0.0593 - val_mse: 0.0448\n",
      "Epoch 23/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/stepep - correlation: 0.2418 - loss: 0.0404 - mse: 0.026\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\n",
      "Epoch 23: val_loss improved from 0.05907 to 0.05867, saving model to /home/lcaldarevic/workspace/ecg_derived_resp_dl/notebooks/models/confused-sweep-1.weights.h5\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - correlation: 0.2420 - loss: 0.0404 - mse: 0.0260 - val_correlation: 0.5075 - val_loss: 0.0587 - val_mse: 0.0447\n",
      "Epoch 24/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/stepep - correlation: 0.2383 - loss: 0.0396 - mse: 0.025\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\n",
      "Epoch 24: val_loss did not improve from 0.05867\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 55ms/step - correlation: 0.2383 - loss: 0.0396 - mse: 0.0258 - val_correlation: 0.4932 - val_loss: 0.0588 - val_mse: 0.0453\n",
      "Epoch 25/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/stepep - correlation: 0.2404 - loss: 0.0391 - mse: 0.025\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\n",
      "Epoch 25: val_loss improved from 0.05867 to 0.05797, saving model to /home/lcaldarevic/workspace/ecg_derived_resp_dl/notebooks/models/confused-sweep-1.weights.h5\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - correlation: 0.2403 - loss: 0.0391 - mse: 0.0258 - val_correlation: 0.4964 - val_loss: 0.0580 - val_mse: 0.0450\n",
      "Epoch 26/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/stepep - correlation: 0.2351 - loss: 0.0382 - mse: 0.025\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\n",
      "Epoch 26: val_loss improved from 0.05797 to 0.05629, saving model to /home/lcaldarevic/workspace/ecg_derived_resp_dl/notebooks/models/confused-sweep-1.weights.h5\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - correlation: 0.2350 - loss: 0.0382 - mse: 0.0253 - val_correlation: 0.4881 - val_loss: 0.0563 - val_mse: 0.0437\n",
      "Epoch 27/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/stepep - correlation: 0.2295 - loss: 0.0373 - mse: 0.024\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\n",
      "Epoch 27: val_loss did not improve from 0.05629\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - correlation: 0.2296 - loss: 0.0373 - mse: 0.0248 - val_correlation: 0.5022 - val_loss: 0.0572 - val_mse: 0.0450\n",
      "Epoch 28/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/stepep - correlation: 0.2298 - loss: 0.0369 - mse: 0.024\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\n",
      "Epoch 28: val_loss did not improve from 0.05629\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - correlation: 0.2296 - loss: 0.0369 - mse: 0.0248 - val_correlation: 0.4975 - val_loss: 0.0565 - val_mse: 0.0448\n",
      "Epoch 29/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/stepep - correlation: 0.2272 - loss: 0.0362 - mse: 0.024\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\n",
      "Epoch 29: val_loss did not improve from 0.05629\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - correlation: 0.2272 - loss: 0.0362 - mse: 0.0245 - val_correlation: 0.5069 - val_loss: 0.0570 - val_mse: 0.0456\n",
      "Epoch 30/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/stepep - correlation: 0.2225 - loss: 0.0354 - mse: 0.024\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\n",
      "Epoch 30: val_loss did not improve from 0.05629\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - correlation: 0.2225 - loss: 0.0354 - mse: 0.0241 - val_correlation: 0.5054 - val_loss: 0.0563 - val_mse: 0.0452\n",
      "Epoch 31/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/stepep - correlation: 0.2196 - loss: 0.0348 - mse: 0.023\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\n",
      "Epoch 31: val_loss improved from 0.05629 to 0.05600, saving model to /home/lcaldarevic/workspace/ecg_derived_resp_dl/notebooks/models/confused-sweep-1.weights.h5\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step - correlation: 0.2197 - loss: 0.0348 - mse: 0.0239 - val_correlation: 0.5018 - val_loss: 0.0560 - val_mse: 0.0453\n",
      "Epoch 32/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/stepep - correlation: 0.2213 - loss: 0.0348 - mse: 0.024\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\n",
      "Epoch 32: val_loss did not improve from 0.05600\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - correlation: 0.2213 - loss: 0.0348 - mse: 0.0241 - val_correlation: 0.5168 - val_loss: 0.0566 - val_mse: 0.0461\n",
      "Epoch 33/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/stepep - correlation: 0.2166 - loss: 0.0339 - mse: 0.023\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\n",
      "Epoch 33: val_loss did not improve from 0.05600\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - correlation: 0.2166 - loss: 0.0339 - mse: 0.0235 - val_correlation: 0.5213 - val_loss: 0.0565 - val_mse: 0.0463\n",
      "Epoch 34/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/stepep - correlation: 0.2138 - loss: 0.0334 - mse: 0.023\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\n",
      "Epoch 34: val_loss improved from 0.05600 to 0.05542, saving model to /home/lcaldarevic/workspace/ecg_derived_resp_dl/notebooks/models/confused-sweep-1.weights.h5\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - correlation: 0.2138 - loss: 0.0334 - mse: 0.0234 - val_correlation: 0.5168 - val_loss: 0.0554 - val_mse: 0.0455\n",
      "Epoch 35/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/stepep - correlation: 0.2121 - loss: 0.0330 - mse: 0.023\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\n",
      "Epoch 35: val_loss did not improve from 0.05542\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - correlation: 0.2121 - loss: 0.0330 - mse: 0.0232 - val_correlation: 0.5223 - val_loss: 0.0574 - val_mse: 0.0477\n",
      "Epoch 36/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/stepep - correlation: 0.2130 - loss: 0.0329 - mse: 0.023\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\n",
      "Epoch 36: val_loss did not improve from 0.05542\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - correlation: 0.2130 - loss: 0.0329 - mse: 0.0234 - val_correlation: 0.5122 - val_loss: 0.0559 - val_mse: 0.0465\n",
      "Epoch 37/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/stepep - correlation: 0.2096 - loss: 0.0322 - mse: 0.022\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\n",
      "Epoch 37: val_loss improved from 0.05542 to 0.05470, saving model to /home/lcaldarevic/workspace/ecg_derived_resp_dl/notebooks/models/confused-sweep-1.weights.h5\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - correlation: 0.2097 - loss: 0.0323 - mse: 0.0229 - val_correlation: 0.5107 - val_loss: 0.0547 - val_mse: 0.0455\n",
      "Epoch 38/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/stepep - correlation: 0.2120 - loss: 0.0323 - mse: 0.023\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\n",
      "Epoch 38: val_loss improved from 0.05470 to 0.05444, saving model to /home/lcaldarevic/workspace/ecg_derived_resp_dl/notebooks/models/confused-sweep-1.weights.h5\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - correlation: 0.2120 - loss: 0.0323 - mse: 0.0232 - val_correlation: 0.5142 - val_loss: 0.0544 - val_mse: 0.0455\n",
      "Epoch 39/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/stepep - correlation: 0.2062 - loss: 0.0314 - mse: 0.022\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\n",
      "Epoch 39: val_loss did not improve from 0.05444\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - correlation: 0.2063 - loss: 0.0315 - mse: 0.0226 - val_correlation: 0.5121 - val_loss: 0.0548 - val_mse: 0.0461\n",
      "Epoch 40/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/stepep - correlation: 0.2079 - loss: 0.0314 - mse: 0.022\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\n",
      "Epoch 40: val_loss did not improve from 0.05444\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - correlation: 0.2079 - loss: 0.0314 - mse: 0.0228 - val_correlation: 0.5150 - val_loss: 0.0550 - val_mse: 0.0465\n",
      "Epoch 41/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/stepep - correlation: 0.2073 - loss: 0.0311 - mse: 0.022\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\n",
      "Epoch 41: val_loss improved from 0.05444 to 0.05390, saving model to /home/lcaldarevic/workspace/ecg_derived_resp_dl/notebooks/models/confused-sweep-1.weights.h5\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - correlation: 0.2073 - loss: 0.0311 - mse: 0.0226 - val_correlation: 0.5093 - val_loss: 0.0539 - val_mse: 0.0456\n",
      "Epoch 42/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/stepep - correlation: 0.2050 - loss: 0.0308 - mse: 0.022\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\n",
      "Epoch 42: val_loss did not improve from 0.05390\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - correlation: 0.2051 - loss: 0.0308 - mse: 0.0225 - val_correlation: 0.5167 - val_loss: 0.0548 - val_mse: 0.0467\n",
      "Epoch 43/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/stepep - correlation: 0.2040 - loss: 0.0305 - mse: 0.022\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\n",
      "Epoch 43: val_loss improved from 0.05390 to 0.05350, saving model to /home/lcaldarevic/workspace/ecg_derived_resp_dl/notebooks/models/confused-sweep-1.weights.h5\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - correlation: 0.2040 - loss: 0.0305 - mse: 0.0224 - val_correlation: 0.5052 - val_loss: 0.0535 - val_mse: 0.0455\n",
      "Epoch 44/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/stepep - correlation: 0.2022 - loss: 0.0301 - mse: 0.022\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\n",
      "Epoch 44: val_loss improved from 0.05350 to 0.05317, saving model to /home/lcaldarevic/workspace/ecg_derived_resp_dl/notebooks/models/confused-sweep-1.weights.h5\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - correlation: 0.2022 - loss: 0.0301 - mse: 0.0222 - val_correlation: 0.5039 - val_loss: 0.0532 - val_mse: 0.0453\n",
      "Epoch 45/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/stepep - correlation: 0.1995 - loss: 0.0297 - mse: 0.021\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\n",
      "Epoch 45: val_loss did not improve from 0.05317\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - correlation: 0.1996 - loss: 0.0298 - mse: 0.0220 - val_correlation: 0.5054 - val_loss: 0.0534 - val_mse: 0.0457\n",
      "Epoch 46/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/stepep - correlation: 0.2033 - loss: 0.0300 - mse: 0.022\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\n",
      "Epoch 46: val_loss did not improve from 0.05317\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - correlation: 0.2033 - loss: 0.0300 - mse: 0.0223 - val_correlation: 0.5237 - val_loss: 0.0549 - val_mse: 0.0474\n",
      "Epoch 47/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/stepep - correlation: 0.1993 - loss: 0.0294 - mse: 0.021\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\n",
      "Epoch 47: val_loss did not improve from 0.05317\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - correlation: 0.1993 - loss: 0.0294 - mse: 0.0219 - val_correlation: 0.5335 - val_loss: 0.0541 - val_mse: 0.0467\n",
      "Epoch 48/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/stepep - correlation: 0.2002 - loss: 0.0294 - mse: 0.022\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\n",
      "Epoch 48: val_loss did not improve from 0.05317\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - correlation: 0.2002 - loss: 0.0294 - mse: 0.0221 - val_correlation: 0.5327 - val_loss: 0.0545 - val_mse: 0.0473\n",
      "Epoch 49/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/stepep - correlation: 0.1960 - loss: 0.0288 - mse: 0.021\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\n",
      "Epoch 49: val_loss did not improve from 0.05317\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - correlation: 0.1961 - loss: 0.0288 - mse: 0.0216 - val_correlation: 0.5461 - val_loss: 0.0551 - val_mse: 0.0480\n",
      "Epoch 50/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/stepep - correlation: 0.2001 - loss: 0.0290 - mse: 0.021\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\n",
      "Epoch 50: val_loss did not improve from 0.05317\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - correlation: 0.2000 - loss: 0.0290 - mse: 0.0219 - val_correlation: 0.5141 - val_loss: 0.0544 - val_mse: 0.0474\n",
      "Epoch 51/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/stepep - correlation: 0.1946 - loss: 0.0284 - mse: 0.021\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\n",
      "Epoch 51: val_loss did not improve from 0.05317\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 56ms/step - correlation: 0.1946 - loss: 0.0284 - mse: 0.0214 - val_correlation: 0.5362 - val_loss: 0.0553 - val_mse: 0.0484\n",
      "Epoch 52/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/stepep - correlation: 0.1978 - loss: 0.0286 - mse: 0.021\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\n",
      "Epoch 52: val_loss did not improve from 0.05317\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - correlation: 0.1977 - loss: 0.0286 - mse: 0.0217 - val_correlation: 0.5510 - val_loss: 0.0571 - val_mse: 0.0503\n",
      "Epoch 53/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/stepep - correlation: 0.1960 - loss: 0.0283 - mse: 0.021\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\n",
      "Epoch 53: val_loss did not improve from 0.05317\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - correlation: 0.1959 - loss: 0.0283 - mse: 0.0216 - val_correlation: 0.5377 - val_loss: 0.0549 - val_mse: 0.0483\n",
      "Epoch 54/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/stepep - correlation: 0.1923 - loss: 0.0278 - mse: 0.021\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\n",
      "Epoch 54: val_loss did not improve from 0.05317\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - correlation: 0.1924 - loss: 0.0278 - mse: 0.0212 - val_correlation: 0.5393 - val_loss: 0.0554 - val_mse: 0.0488\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>CC</td><td></td></tr><tr><td>loss</td><td></td></tr><tr><td>mse</td><td></td></tr><tr><td>val_CC</td><td></td></tr><tr><td>val_loss</td><td></td></tr><tr><td>val_mse</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>CC</td><td>0.19367</td></tr><tr><td>loss</td><td>0.02798</td></tr><tr><td>mse</td><td>0.02137</td></tr><tr><td>val_CC</td><td>0.53931</td></tr><tr><td>val_loss</td><td>0.05536</td></tr><tr><td>val_mse</td><td>0.04881</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">confused-sweep-1</strong> at: <a href='https://wandb.ai/lana-caldarevic1/fantasia-hp-tuning/runs/3eq9gdf6' target=\"_blank\">https://wandb.ai/lana-caldarevic1/fantasia-hp-tuning/runs/3eq9gdf6</a><br/> View project at: <a href='https://wandb.ai/lana-caldarevic1/fantasia-hp-tuning' target=\"_blank\">https://wandb.ai/lana-caldarevic1/fantasia-hp-tuning</a><br/>Synced 6 W&B file(s), 54 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240708_143529-3eq9gdf6/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: drg9ef1k with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdp: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tkernel_size: 13\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0002361082458322824\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tregularizer: 0.00027733895760762955\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tstart_filters: 8\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/lcaldarevic/workspace/ecg_derived_resp_dl/notebooks/wandb/run-20240708_143820-drg9ef1k</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/lana-caldarevic1/fantasia-hp-tuning/runs/drg9ef1k' target=\"_blank\">gentle-sweep-2</a></strong> to <a href='https://wandb.ai/lana-caldarevic1/fantasia-hp-tuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/lana-caldarevic1/fantasia-hp-tuning/sweeps/mv0u3xpn' target=\"_blank\">https://wandb.ai/lana-caldarevic1/fantasia-hp-tuning/sweeps/mv0u3xpn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/lana-caldarevic1/fantasia-hp-tuning' target=\"_blank\">https://wandb.ai/lana-caldarevic1/fantasia-hp-tuning</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/lana-caldarevic1/fantasia-hp-tuning/sweeps/mv0u3xpn' target=\"_blank\">https://wandb.ai/lana-caldarevic1/fantasia-hp-tuning/sweeps/mv0u3xpn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/lana-caldarevic1/fantasia-hp-tuning/runs/drg9ef1k' target=\"_blank\">https://wandb.ai/lana-caldarevic1/fantasia-hp-tuning/runs/drg9ef1k</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"font-weight: bold\"> Layer (type)        </span><span style=\"font-weight: bold\"> Output Shape      </span><span style=\"font-weight: bold\">    Param # </span><span style=\"font-weight: bold\"> Connected to      </span>\n",
       "\n",
       " input_layer          (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                                                          \n",
       "\n",
       " conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)      (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)           <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>  input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
       "\n",
       " batch_normalization  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)            <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>  conv1d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio</span>                                                   \n",
       "\n",
       " conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)           <span style=\"color: #00af00; text-decoration-color: #00af00\">840</span>  batch_normalizat \n",
       "\n",
       " batch_normalizatio  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)            <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>  conv1d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio</span>                                                   \n",
       "\n",
       " max_pooling1d        (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  batch_normalizat \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)                                                        \n",
       "\n",
       " conv1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,680</span>  max_pooling1d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
       "\n",
       " batch_normalizatio  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>  conv1d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio</span>                                                   \n",
       "\n",
       " conv1d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,344</span>  batch_normalizat \n",
       "\n",
       " batch_normalizatio  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>  conv1d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio</span>                                                   \n",
       "\n",
       " dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  batch_normalizat \n",
       "\n",
       " max_pooling1d_1      (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)                                                        \n",
       "\n",
       " conv1d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,688</span>  max_pooling1d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\"></span> \n",
       "\n",
       " batch_normalizatio  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>  conv1d_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio</span>                                                   \n",
       "\n",
       " conv1d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        <span style=\"color: #00af00; text-decoration-color: #00af00\">13,344</span>  batch_normalizat \n",
       "\n",
       " batch_normalizatio  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>  conv1d_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio</span>                                                   \n",
       "\n",
       " up_sampling1d        (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  batch_normalizat \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">UpSampling1D</span>)                                                        \n",
       "\n",
       " conv1d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span>  up_sampling1d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
       "\n",
       " batch_normalizatio  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>  conv1d_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio</span>                                                   \n",
       "\n",
       " concatenate          (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)                                       batch_normalizat \n",
       "\n",
       " conv1d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,000</span>  concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
       "\n",
       " batch_normalizatio  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>  conv1d_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio</span>                                                   \n",
       "\n",
       " conv1d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,344</span>  batch_normalizat \n",
       "\n",
       " batch_normalizatio  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>  conv1d_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio</span>                                                   \n",
       "\n",
       " dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  batch_normalizat \n",
       "\n",
       " up_sampling1d_1      (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)            <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">UpSampling1D</span>)                                                        \n",
       "\n",
       " conv1d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)          <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span>  up_sampling1d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\"></span> \n",
       "\n",
       " batch_normalizatio  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)           <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>  conv1d_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio</span>                                                   \n",
       "\n",
       " concatenate_1        (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)            <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  batch_normalizat \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)                                       batch_normalizat \n",
       "\n",
       " conv1d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,504</span>  concatenate_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
       "\n",
       " batch_normalizatio  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)            <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>  conv1d_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio</span>                                                   \n",
       "\n",
       " conv1d_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)           <span style=\"color: #00af00; text-decoration-color: #00af00\">840</span>  batch_normalizat \n",
       "\n",
       " batch_normalizatio  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)            <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>  conv1d_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio</span>                                                   \n",
       "\n",
       " conv1d_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)           <span style=\"color: #00af00; text-decoration-color: #00af00\">105</span>  batch_normalizat \n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m\n",
       "\n",
       " input_layer          (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m, \u001b[38;5;34m1\u001b[0m)             \u001b[38;5;34m0\u001b[0m  -                 \n",
       " (\u001b[38;5;33mInputLayer\u001b[0m)                                                          \n",
       "\n",
       " conv1d (\u001b[38;5;33mConv1D\u001b[0m)      (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m, \u001b[38;5;34m8\u001b[0m)           \u001b[38;5;34m112\u001b[0m  input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] \n",
       "\n",
       " batch_normalization  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m, \u001b[38;5;34m8\u001b[0m)            \u001b[38;5;34m32\u001b[0m  conv1d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      \n",
       " (\u001b[38;5;33mBatchNormalizatio\u001b[0m                                                   \n",
       "\n",
       " conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m, \u001b[38;5;34m8\u001b[0m)           \u001b[38;5;34m840\u001b[0m  batch_normalizat \n",
       "\n",
       " batch_normalizatio  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m, \u001b[38;5;34m8\u001b[0m)            \u001b[38;5;34m32\u001b[0m  conv1d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    \n",
       " (\u001b[38;5;33mBatchNormalizatio\u001b[0m                                                   \n",
       "\n",
       " max_pooling1d        (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m8\u001b[0m)              \u001b[38;5;34m0\u001b[0m  batch_normalizat \n",
       " (\u001b[38;5;33mMaxPooling1D\u001b[0m)                                                        \n",
       "\n",
       " conv1d_2 (\u001b[38;5;33mConv1D\u001b[0m)    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m16\u001b[0m)         \u001b[38;5;34m1,680\u001b[0m  max_pooling1d[\u001b[38;5;34m0\u001b[0m] \n",
       "\n",
       " batch_normalizatio  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m16\u001b[0m)            \u001b[38;5;34m64\u001b[0m  conv1d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    \n",
       " (\u001b[38;5;33mBatchNormalizatio\u001b[0m                                                   \n",
       "\n",
       " conv1d_3 (\u001b[38;5;33mConv1D\u001b[0m)    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m16\u001b[0m)         \u001b[38;5;34m3,344\u001b[0m  batch_normalizat \n",
       "\n",
       " batch_normalizatio  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m16\u001b[0m)            \u001b[38;5;34m64\u001b[0m  conv1d_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    \n",
       " (\u001b[38;5;33mBatchNormalizatio\u001b[0m                                                   \n",
       "\n",
       " dropout (\u001b[38;5;33mDropout\u001b[0m)    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m16\u001b[0m)             \u001b[38;5;34m0\u001b[0m  batch_normalizat \n",
       "\n",
       " max_pooling1d_1      (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m16\u001b[0m)             \u001b[38;5;34m0\u001b[0m  dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     \n",
       " (\u001b[38;5;33mMaxPooling1D\u001b[0m)                                                        \n",
       "\n",
       " conv1d_4 (\u001b[38;5;33mConv1D\u001b[0m)    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m32\u001b[0m)         \u001b[38;5;34m6,688\u001b[0m  max_pooling1d_1[\u001b[38;5;34m\u001b[0m \n",
       "\n",
       " batch_normalizatio  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m32\u001b[0m)           \u001b[38;5;34m128\u001b[0m  conv1d_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    \n",
       " (\u001b[38;5;33mBatchNormalizatio\u001b[0m                                                   \n",
       "\n",
       " conv1d_5 (\u001b[38;5;33mConv1D\u001b[0m)    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m32\u001b[0m)        \u001b[38;5;34m13,344\u001b[0m  batch_normalizat \n",
       "\n",
       " batch_normalizatio  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m32\u001b[0m)           \u001b[38;5;34m128\u001b[0m  conv1d_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    \n",
       " (\u001b[38;5;33mBatchNormalizatio\u001b[0m                                                   \n",
       "\n",
       " up_sampling1d        (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m32\u001b[0m)             \u001b[38;5;34m0\u001b[0m  batch_normalizat \n",
       " (\u001b[38;5;33mUpSampling1D\u001b[0m)                                                        \n",
       "\n",
       " conv1d_6 (\u001b[38;5;33mConv1D\u001b[0m)    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m32\u001b[0m)         \u001b[38;5;34m2,080\u001b[0m  up_sampling1d[\u001b[38;5;34m0\u001b[0m] \n",
       "\n",
       " batch_normalizatio  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m32\u001b[0m)           \u001b[38;5;34m128\u001b[0m  conv1d_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    \n",
       " (\u001b[38;5;33mBatchNormalizatio\u001b[0m                                                   \n",
       "\n",
       " concatenate          (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m48\u001b[0m)             \u001b[38;5;34m0\u001b[0m  dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    \n",
       " (\u001b[38;5;33mConcatenate\u001b[0m)                                       batch_normalizat \n",
       "\n",
       " conv1d_7 (\u001b[38;5;33mConv1D\u001b[0m)    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m16\u001b[0m)        \u001b[38;5;34m10,000\u001b[0m  concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] \n",
       "\n",
       " batch_normalizatio  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m16\u001b[0m)            \u001b[38;5;34m64\u001b[0m  conv1d_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    \n",
       " (\u001b[38;5;33mBatchNormalizatio\u001b[0m                                                   \n",
       "\n",
       " conv1d_8 (\u001b[38;5;33mConv1D\u001b[0m)    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m16\u001b[0m)         \u001b[38;5;34m3,344\u001b[0m  batch_normalizat \n",
       "\n",
       " batch_normalizatio  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m16\u001b[0m)            \u001b[38;5;34m64\u001b[0m  conv1d_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    \n",
       " (\u001b[38;5;33mBatchNormalizatio\u001b[0m                                                   \n",
       "\n",
       " dropout_1 (\u001b[38;5;33mDropout\u001b[0m)  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m16\u001b[0m)             \u001b[38;5;34m0\u001b[0m  batch_normalizat \n",
       "\n",
       " up_sampling1d_1      (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m, \u001b[38;5;34m16\u001b[0m)            \u001b[38;5;34m0\u001b[0m  dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   \n",
       " (\u001b[38;5;33mUpSampling1D\u001b[0m)                                                        \n",
       "\n",
       " conv1d_9 (\u001b[38;5;33mConv1D\u001b[0m)    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m, \u001b[38;5;34m16\u001b[0m)          \u001b[38;5;34m528\u001b[0m  up_sampling1d_1[\u001b[38;5;34m\u001b[0m \n",
       "\n",
       " batch_normalizatio  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m, \u001b[38;5;34m16\u001b[0m)           \u001b[38;5;34m64\u001b[0m  conv1d_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    \n",
       " (\u001b[38;5;33mBatchNormalizatio\u001b[0m                                                   \n",
       "\n",
       " concatenate_1        (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m, \u001b[38;5;34m24\u001b[0m)            \u001b[38;5;34m0\u001b[0m  batch_normalizat \n",
       " (\u001b[38;5;33mConcatenate\u001b[0m)                                       batch_normalizat \n",
       "\n",
       " conv1d_10 (\u001b[38;5;33mConv1D\u001b[0m)   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m, \u001b[38;5;34m8\u001b[0m)         \u001b[38;5;34m2,504\u001b[0m  concatenate_1[\u001b[38;5;34m0\u001b[0m] \n",
       "\n",
       " batch_normalizatio  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m, \u001b[38;5;34m8\u001b[0m)            \u001b[38;5;34m32\u001b[0m  conv1d_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   \n",
       " (\u001b[38;5;33mBatchNormalizatio\u001b[0m                                                   \n",
       "\n",
       " conv1d_11 (\u001b[38;5;33mConv1D\u001b[0m)   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m, \u001b[38;5;34m8\u001b[0m)           \u001b[38;5;34m840\u001b[0m  batch_normalizat \n",
       "\n",
       " batch_normalizatio  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m, \u001b[38;5;34m8\u001b[0m)            \u001b[38;5;34m32\u001b[0m  conv1d_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   \n",
       " (\u001b[38;5;33mBatchNormalizatio\u001b[0m                                                   \n",
       "\n",
       " conv1d_12 (\u001b[38;5;33mConv1D\u001b[0m)   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m, \u001b[38;5;34m1\u001b[0m)           \u001b[38;5;34m105\u001b[0m  batch_normalizat \n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">46,241</span> (180.63 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m46,241\u001b[0m (180.63 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">45,825</span> (179.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m45,825\u001b[0m (179.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">416</span> (1.62 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m416\u001b[0m (1.62 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model training starting\n",
      "(11930, 1024, 1)\n",
      "Epoch 1/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 721ms/stepep - correlation: 0.9970 - loss: 0.2007 - mse: 0.11\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.15151, saving model to /home/lcaldarevic/workspace/ecg_derived_resp_dl/notebooks/models/gentle-sweep-2.weights.h5\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 308ms/step - correlation: 0.9969 - loss: 0.2005 - mse: 0.1135 - val_correlation: 0.9979 - val_loss: 0.1515 - val_mse: 0.0693\n",
      "Epoch 2/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/stepep - correlation: 0.9770 - loss: 0.1634 - mse: 0.083\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\n",
      "Epoch 2: val_loss improved from 0.15151 to 0.14129, saving model to /home/lcaldarevic/workspace/ecg_derived_resp_dl/notebooks/models/gentle-sweep-2.weights.h5\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - correlation: 0.9765 - loss: 0.1631 - mse: 0.0828 - val_correlation: 0.9964 - val_loss: 0.1413 - val_mse: 0.0668\n",
      "Epoch 3/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/stepep - correlation: 0.9129 - loss: 0.1451 - mse: 0.072\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\n",
      "Epoch 3: val_loss improved from 0.14129 to 0.12962, saving model to /home/lcaldarevic/workspace/ecg_derived_resp_dl/notebooks/models/gentle-sweep-2.weights.h5\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - correlation: 0.9102 - loss: 0.1448 - mse: 0.0723 - val_correlation: 0.9968 - val_loss: 0.1296 - val_mse: 0.0628\n",
      "Epoch 4/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/stepep - correlation: 0.7441 - loss: 0.1296 - mse: 0.064\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\n",
      "Epoch 4: val_loss improved from 0.12962 to 0.12124, saving model to /home/lcaldarevic/workspace/ecg_derived_resp_dl/notebooks/models/gentle-sweep-2.weights.h5\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - correlation: 0.7421 - loss: 0.1294 - mse: 0.0642 - val_correlation: 0.9446 - val_loss: 0.1212 - val_mse: 0.0610\n",
      "Epoch 5/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/stepep - correlation: 0.6410 - loss: 0.1172 - mse: 0.058\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\n",
      "Epoch 5: val_loss improved from 0.12124 to 0.11396, saving model to /home/lcaldarevic/workspace/ecg_derived_resp_dl/notebooks/models/gentle-sweep-2.weights.h5\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - correlation: 0.6399 - loss: 0.1170 - mse: 0.0583 - val_correlation: 0.9019 - val_loss: 0.1140 - val_mse: 0.0596\n",
      "Epoch 6/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/stepep - correlation: 0.5723 - loss: 0.1059 - mse: 0.052\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\n",
      "Epoch 6: val_loss improved from 0.11396 to 0.10722, saving model to /home/lcaldarevic/workspace/ecg_derived_resp_dl/notebooks/models/gentle-sweep-2.weights.h5\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - correlation: 0.5715 - loss: 0.1058 - mse: 0.0527 - val_correlation: 0.7487 - val_loss: 0.1072 - val_mse: 0.0578\n",
      "Epoch 7/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/stepep - correlation: 0.5235 - loss: 0.0973 - mse: 0.048\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.10722\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - correlation: 0.5227 - loss: 0.0972 - mse: 0.0488 - val_correlation: 0.7640 - val_loss: 0.1135 - val_mse: 0.0682\n",
      "Epoch 8/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/stepep - correlation: 0.4846 - loss: 0.0898 - mse: 0.045\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\n",
      "Epoch 8: val_loss improved from 0.10722 to 0.10577, saving model to /home/lcaldarevic/workspace/ecg_derived_resp_dl/notebooks/models/gentle-sweep-2.weights.h5\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - correlation: 0.4840 - loss: 0.0897 - mse: 0.0454 - val_correlation: 0.6519 - val_loss: 0.1058 - val_mse: 0.0641\n",
      "Epoch 9/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/stepep - correlation: 0.4485 - loss: 0.0837 - mse: 0.042\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\n",
      "Epoch 9: val_loss improved from 0.10577 to 0.09447, saving model to /home/lcaldarevic/workspace/ecg_derived_resp_dl/notebooks/models/gentle-sweep-2.weights.h5\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - correlation: 0.4482 - loss: 0.0836 - mse: 0.0427 - val_correlation: 0.5581 - val_loss: 0.0945 - val_mse: 0.0559\n",
      "Epoch 10/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/stepep - correlation: 0.4284 - loss: 0.0791 - mse: 0.041\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\n",
      "Epoch 10: val_loss improved from 0.09447 to 0.08894, saving model to /home/lcaldarevic/workspace/ecg_derived_resp_dl/notebooks/models/gentle-sweep-2.weights.h5\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - correlation: 0.4281 - loss: 0.0790 - mse: 0.0412 - val_correlation: 0.5300 - val_loss: 0.0889 - val_mse: 0.0531\n",
      "Epoch 11/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/stepep - correlation: 0.4089 - loss: 0.0749 - mse: 0.039\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\n",
      "Epoch 11: val_loss improved from 0.08894 to 0.08048, saving model to /home/lcaldarevic/workspace/ecg_derived_resp_dl/notebooks/models/gentle-sweep-2.weights.h5\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - correlation: 0.4088 - loss: 0.0749 - mse: 0.0397 - val_correlation: 0.5006 - val_loss: 0.0805 - val_mse: 0.0471\n",
      "Epoch 12/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/stepep - correlation: 0.3956 - loss: 0.0717 - mse: 0.038\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\n",
      "Epoch 12: val_loss improved from 0.08048 to 0.07589, saving model to /home/lcaldarevic/workspace/ecg_derived_resp_dl/notebooks/models/gentle-sweep-2.weights.h5\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - correlation: 0.3954 - loss: 0.0716 - mse: 0.0388 - val_correlation: 0.4903 - val_loss: 0.0759 - val_mse: 0.0446\n",
      "Epoch 13/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/stepep - correlation: 0.3824 - loss: 0.0687 - mse: 0.037\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\n",
      "Epoch 13: val_loss improved from 0.07589 to 0.07370, saving model to /home/lcaldarevic/workspace/ecg_derived_resp_dl/notebooks/models/gentle-sweep-2.weights.h5\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 59ms/step - correlation: 0.3822 - loss: 0.0687 - mse: 0.0379 - val_correlation: 0.4879 - val_loss: 0.0737 - val_mse: 0.0443\n",
      "Epoch 14/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/stepep - correlation: 0.3704 - loss: 0.0657 - mse: 0.036\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\n",
      "Epoch 14: val_loss improved from 0.07370 to 0.07193, saving model to /home/lcaldarevic/workspace/ecg_derived_resp_dl/notebooks/models/gentle-sweep-2.weights.h5\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - correlation: 0.3702 - loss: 0.0656 - mse: 0.0367 - val_correlation: 0.4895 - val_loss: 0.0719 - val_mse: 0.0443\n",
      "Epoch 15/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/stepep - correlation: 0.3532 - loss: 0.0626 - mse: 0.035\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\n",
      "Epoch 15: val_loss improved from 0.07193 to 0.07050, saving model to /home/lcaldarevic/workspace/ecg_derived_resp_dl/notebooks/models/gentle-sweep-2.weights.h5\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - correlation: 0.3531 - loss: 0.0626 - mse: 0.0353 - val_correlation: 0.4894 - val_loss: 0.0705 - val_mse: 0.0444\n",
      "Epoch 16/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/stepep - correlation: 0.3342 - loss: 0.0597 - mse: 0.033\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\n",
      "Epoch 16: val_loss improved from 0.07050 to 0.06925, saving model to /home/lcaldarevic/workspace/ecg_derived_resp_dl/notebooks/models/gentle-sweep-2.weights.h5\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - correlation: 0.3342 - loss: 0.0597 - mse: 0.0339 - val_correlation: 0.4987 - val_loss: 0.0693 - val_mse: 0.0445\n",
      "Epoch 17/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/stepep - correlation: 0.3253 - loss: 0.0579 - mse: 0.033\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\n",
      "Epoch 17: val_loss improved from 0.06925 to 0.06858, saving model to /home/lcaldarevic/workspace/ecg_derived_resp_dl/notebooks/models/gentle-sweep-2.weights.h5\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - correlation: 0.3251 - loss: 0.0579 - mse: 0.0334 - val_correlation: 0.4992 - val_loss: 0.0686 - val_mse: 0.0450\n",
      "Epoch 18/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/stepep - correlation: 0.3163 - loss: 0.0559 - mse: 0.032\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\n",
      "Epoch 18: val_loss improved from 0.06858 to 0.06733, saving model to /home/lcaldarevic/workspace/ecg_derived_resp_dl/notebooks/models/gentle-sweep-2.weights.h5\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - correlation: 0.3162 - loss: 0.0558 - mse: 0.0325 - val_correlation: 0.4989 - val_loss: 0.0673 - val_mse: 0.0448\n",
      "Epoch 19/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/stepep - correlation: 0.3089 - loss: 0.0540 - mse: 0.031\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\n",
      "Epoch 19: val_loss improved from 0.06733 to 0.06559, saving model to /home/lcaldarevic/workspace/ecg_derived_resp_dl/notebooks/models/gentle-sweep-2.weights.h5\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - correlation: 0.3086 - loss: 0.0539 - mse: 0.0317 - val_correlation: 0.4948 - val_loss: 0.0656 - val_mse: 0.0441\n",
      "Epoch 20/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/stepep - correlation: 0.2995 - loss: 0.0522 - mse: 0.030\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\n",
      "Epoch 20: val_loss improved from 0.06559 to 0.06478, saving model to /home/lcaldarevic/workspace/ecg_derived_resp_dl/notebooks/models/gentle-sweep-2.weights.h5\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - correlation: 0.2994 - loss: 0.0522 - mse: 0.0309 - val_correlation: 0.4844 - val_loss: 0.0648 - val_mse: 0.0442\n",
      "Epoch 21/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/stepep - correlation: 0.2920 - loss: 0.0508 - mse: 0.030\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\n",
      "Epoch 21: val_loss improved from 0.06478 to 0.06470, saving model to /home/lcaldarevic/workspace/ecg_derived_resp_dl/notebooks/models/gentle-sweep-2.weights.h5\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - correlation: 0.2919 - loss: 0.0508 - mse: 0.0304 - val_correlation: 0.5056 - val_loss: 0.0647 - val_mse: 0.0450\n",
      "Epoch 22/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/stepep - correlation: 0.2867 - loss: 0.0494 - mse: 0.029\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\n",
      "Epoch 22: val_loss improved from 0.06470 to 0.06322, saving model to /home/lcaldarevic/workspace/ecg_derived_resp_dl/notebooks/models/gentle-sweep-2.weights.h5\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - correlation: 0.2866 - loss: 0.0494 - mse: 0.0299 - val_correlation: 0.4872 - val_loss: 0.0632 - val_mse: 0.0443\n",
      "Epoch 23/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/stepep - correlation: 0.2819 - loss: 0.0484 - mse: 0.029\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\n",
      "Epoch 23: val_loss improved from 0.06322 to 0.06305, saving model to /home/lcaldarevic/workspace/ecg_derived_resp_dl/notebooks/models/gentle-sweep-2.weights.h5\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - correlation: 0.2819 - loss: 0.0483 - mse: 0.0296 - val_correlation: 0.5012 - val_loss: 0.0630 - val_mse: 0.0448\n",
      "Epoch 24/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/stepep - correlation: 0.2774 - loss: 0.0472 - mse: 0.029\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\n",
      "Epoch 24: val_loss improved from 0.06305 to 0.06189, saving model to /home/lcaldarevic/workspace/ecg_derived_resp_dl/notebooks/models/gentle-sweep-2.weights.h5\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - correlation: 0.2773 - loss: 0.0472 - mse: 0.0291 - val_correlation: 0.4905 - val_loss: 0.0619 - val_mse: 0.0443\n",
      "Epoch 25/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/stepep - correlation: 0.2712 - loss: 0.0461 - mse: 0.028\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\n",
      "Epoch 25: val_loss improved from 0.06189 to 0.06122, saving model to /home/lcaldarevic/workspace/ecg_derived_resp_dl/notebooks/models/gentle-sweep-2.weights.h5\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - correlation: 0.2713 - loss: 0.0461 - mse: 0.0286 - val_correlation: 0.4892 - val_loss: 0.0612 - val_mse: 0.0443\n",
      "Epoch 26/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/stepep - correlation: 0.2690 - loss: 0.0452 - mse: 0.028\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\n",
      "Epoch 26: val_loss improved from 0.06122 to 0.06097, saving model to /home/lcaldarevic/workspace/ecg_derived_resp_dl/notebooks/models/gentle-sweep-2.weights.h5\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - correlation: 0.2690 - loss: 0.0452 - mse: 0.0284 - val_correlation: 0.4963 - val_loss: 0.0610 - val_mse: 0.0446\n",
      "Epoch 27/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/stepep - correlation: 0.2651 - loss: 0.0443 - mse: 0.028\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\n",
      "Epoch 27: val_loss did not improve from 0.06097\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - correlation: 0.2650 - loss: 0.0443 - mse: 0.0280 - val_correlation: 0.5125 - val_loss: 0.0613 - val_mse: 0.0455\n",
      "Epoch 28/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/stepep - correlation: 0.2639 - loss: 0.0437 - mse: 0.028\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\n",
      "Epoch 28: val_loss improved from 0.06097 to 0.05909, saving model to /home/lcaldarevic/workspace/ecg_derived_resp_dl/notebooks/models/gentle-sweep-2.weights.h5\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - correlation: 0.2638 - loss: 0.0437 - mse: 0.0280 - val_correlation: 0.4842 - val_loss: 0.0591 - val_mse: 0.0438\n",
      "Epoch 29/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/stepep - correlation: 0.2562 - loss: 0.0426 - mse: 0.027\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\n",
      "Epoch 29: val_loss did not improve from 0.05909\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - correlation: 0.2563 - loss: 0.0426 - mse: 0.0274 - val_correlation: 0.4935 - val_loss: 0.0593 - val_mse: 0.0445\n",
      "Epoch 30/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/stepep - correlation: 0.2543 - loss: 0.0418 - mse: 0.027\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\n",
      "Epoch 30: val_loss improved from 0.05909 to 0.05796, saving model to /home/lcaldarevic/workspace/ecg_derived_resp_dl/notebooks/models/gentle-sweep-2.weights.h5\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - correlation: 0.2544 - loss: 0.0418 - mse: 0.0271 - val_correlation: 0.4876 - val_loss: 0.0580 - val_mse: 0.0436\n",
      "Epoch 31/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/stepep - correlation: 0.2553 - loss: 0.0414 - mse: 0.027\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\n",
      "Epoch 31: val_loss did not improve from 0.05796\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - correlation: 0.2552 - loss: 0.0414 - mse: 0.0272 - val_correlation: 0.5017 - val_loss: 0.0587 - val_mse: 0.0448\n",
      "Epoch 32/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/stepep - correlation: 0.2527 - loss: 0.0407 - mse: 0.026\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\n",
      "Epoch 32: val_loss improved from 0.05796 to 0.05778, saving model to /home/lcaldarevic/workspace/ecg_derived_resp_dl/notebooks/models/gentle-sweep-2.weights.h5\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - correlation: 0.2526 - loss: 0.0407 - mse: 0.0269 - val_correlation: 0.4934 - val_loss: 0.0578 - val_mse: 0.0443\n",
      "Epoch 33/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/stepep - correlation: 0.2503 - loss: 0.0401 - mse: 0.026\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\n",
      "Epoch 33: val_loss improved from 0.05778 to 0.05752, saving model to /home/lcaldarevic/workspace/ecg_derived_resp_dl/notebooks/models/gentle-sweep-2.weights.h5\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - correlation: 0.2502 - loss: 0.0401 - mse: 0.0267 - val_correlation: 0.4891 - val_loss: 0.0575 - val_mse: 0.0444\n",
      "Epoch 34/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/stepep - correlation: 0.2480 - loss: 0.0395 - mse: 0.026\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\n",
      "Epoch 34: val_loss did not improve from 0.05752\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - correlation: 0.2480 - loss: 0.0395 - mse: 0.0265 - val_correlation: 0.5178 - val_loss: 0.0584 - val_mse: 0.0457\n",
      "Epoch 35/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/stepep - correlation: 0.2412 - loss: 0.0385 - mse: 0.025\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\n",
      "Epoch 35: val_loss improved from 0.05752 to 0.05632, saving model to /home/lcaldarevic/workspace/ecg_derived_resp_dl/notebooks/models/gentle-sweep-2.weights.h5\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - correlation: 0.2413 - loss: 0.0385 - mse: 0.0259 - val_correlation: 0.4786 - val_loss: 0.0563 - val_mse: 0.0439\n",
      "Epoch 36/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/stepep - correlation: 0.2380 - loss: 0.0378 - mse: 0.025\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\n",
      "Epoch 36: val_loss did not improve from 0.05632\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - correlation: 0.2382 - loss: 0.0378 - mse: 0.0255 - val_correlation: 0.4985 - val_loss: 0.0572 - val_mse: 0.0451\n",
      "Epoch 37/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/stepep - correlation: 0.2405 - loss: 0.0379 - mse: 0.025\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\n",
      "Epoch 37: val_loss did not improve from 0.05632\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - correlation: 0.2406 - loss: 0.0379 - mse: 0.0259 - val_correlation: 0.4875 - val_loss: 0.0567 - val_mse: 0.0449\n",
      "Epoch 38/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/stepep - correlation: 0.2362 - loss: 0.0373 - mse: 0.025\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\n",
      "Epoch 38: val_loss did not improve from 0.05632\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - correlation: 0.2363 - loss: 0.0373 - mse: 0.0256 - val_correlation: 0.4915 - val_loss: 0.0565 - val_mse: 0.0450\n",
      "Epoch 39/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/stepep - correlation: 0.2413 - loss: 0.0373 - mse: 0.025\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\n",
      "Epoch 39: val_loss did not improve from 0.05632\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - correlation: 0.2410 - loss: 0.0372 - mse: 0.0258 - val_correlation: 0.5080 - val_loss: 0.0565 - val_mse: 0.0453\n",
      "Epoch 40/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/stepep - correlation: 0.2367 - loss: 0.0364 - mse: 0.025\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\n",
      "Epoch 40: val_loss did not improve from 0.05632\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - correlation: 0.2366 - loss: 0.0364 - mse: 0.0253 - val_correlation: 0.4991 - val_loss: 0.0564 - val_mse: 0.0455\n",
      "Epoch 41/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/stepep - correlation: 0.2322 - loss: 0.0359 - mse: 0.025\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\n",
      "Epoch 41: val_loss improved from 0.05632 to 0.05538, saving model to /home/lcaldarevic/workspace/ecg_derived_resp_dl/notebooks/models/gentle-sweep-2.weights.h5\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - correlation: 0.2323 - loss: 0.0359 - mse: 0.0251 - val_correlation: 0.5009 - val_loss: 0.0554 - val_mse: 0.0447\n",
      "Epoch 42/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/stepep - correlation: 0.2316 - loss: 0.0357 - mse: 0.025\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\n",
      "Epoch 42: val_loss did not improve from 0.05538\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 59ms/step - correlation: 0.2316 - loss: 0.0357 - mse: 0.0251 - val_correlation: 0.5020 - val_loss: 0.0561 - val_mse: 0.0457\n",
      "Epoch 43/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/stepep - correlation: 0.2289 - loss: 0.0351 - mse: 0.024\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\n",
      "Epoch 43: val_loss did not improve from 0.05538\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - correlation: 0.2290 - loss: 0.0351 - mse: 0.0248 - val_correlation: 0.5053 - val_loss: 0.0565 - val_mse: 0.0463\n",
      "Epoch 44/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/stepep - correlation: 0.2273 - loss: 0.0347 - mse: 0.024\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\n",
      "Epoch 44: val_loss did not improve from 0.05538\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - correlation: 0.2274 - loss: 0.0347 - mse: 0.0246 - val_correlation: 0.5263 - val_loss: 0.0566 - val_mse: 0.0467\n",
      "Epoch 45/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/stepep - correlation: 0.2264 - loss: 0.0345 - mse: 0.024\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\n",
      "Epoch 45: val_loss did not improve from 0.05538\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - correlation: 0.2265 - loss: 0.0345 - mse: 0.0246 - val_correlation: 0.5186 - val_loss: 0.0564 - val_mse: 0.0467\n",
      "Epoch 46/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/stepep - correlation: 0.2277 - loss: 0.0343 - mse: 0.024\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\n",
      "Epoch 46: val_loss did not improve from 0.05538\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - correlation: 0.2276 - loss: 0.0343 - mse: 0.0246 - val_correlation: 0.5155 - val_loss: 0.0557 - val_mse: 0.0462\n",
      "Epoch 47/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/stepep - correlation: 0.2257 - loss: 0.0340 - mse: 0.024\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\n",
      "Epoch 47: val_loss did not improve from 0.05538\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - correlation: 0.2258 - loss: 0.0340 - mse: 0.0245 - val_correlation: 0.5085 - val_loss: 0.0559 - val_mse: 0.0465\n",
      "Epoch 48/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/stepep - correlation: 0.2217 - loss: 0.0334 - mse: 0.024\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\n",
      "Epoch 48: val_loss improved from 0.05538 to 0.05521, saving model to /home/lcaldarevic/workspace/ecg_derived_resp_dl/notebooks/models/gentle-sweep-2.weights.h5\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - correlation: 0.2218 - loss: 0.0334 - mse: 0.0241 - val_correlation: 0.5026 - val_loss: 0.0552 - val_mse: 0.0461\n",
      "Epoch 49/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/stepep - correlation: 0.2191 - loss: 0.0329 - mse: 0.023\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\n",
      "Epoch 49: val_loss improved from 0.05521 to 0.05371, saving model to /home/lcaldarevic/workspace/ecg_derived_resp_dl/notebooks/models/gentle-sweep-2.weights.h5\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - correlation: 0.2193 - loss: 0.0329 - mse: 0.0238 - val_correlation: 0.4920 - val_loss: 0.0537 - val_mse: 0.0447\n",
      "Epoch 50/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/stepep - correlation: 0.2201 - loss: 0.0328 - mse: 0.023\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\n",
      "Epoch 50: val_loss did not improve from 0.05371\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - correlation: 0.2202 - loss: 0.0328 - mse: 0.0238 - val_correlation: 0.5330 - val_loss: 0.0562 - val_mse: 0.0474\n",
      "Epoch 51/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/stepep - correlation: 0.2223 - loss: 0.0329 - mse: 0.024\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\n",
      "Epoch 51: val_loss did not improve from 0.05371\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - correlation: 0.2223 - loss: 0.0329 - mse: 0.0241 - val_correlation: 0.5034 - val_loss: 0.0553 - val_mse: 0.0467\n",
      "Epoch 52/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/stepep - correlation: 0.2220 - loss: 0.0328 - mse: 0.024\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\n",
      "Epoch 52: val_loss did not improve from 0.05371\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - correlation: 0.2219 - loss: 0.0327 - mse: 0.0241 - val_correlation: 0.5008 - val_loss: 0.0538 - val_mse: 0.0454\n",
      "Epoch 53/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/stepep - correlation: 0.2185 - loss: 0.0322 - mse: 0.023\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\n",
      "Epoch 53: val_loss did not improve from 0.05371\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - correlation: 0.2185 - loss: 0.0322 - mse: 0.0238 - val_correlation: 0.5058 - val_loss: 0.0543 - val_mse: 0.0459\n",
      "Epoch 54/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/stepep - correlation: 0.2180 - loss: 0.0319 - mse: 0.023\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\n",
      "Epoch 54: val_loss did not improve from 0.05371\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - correlation: 0.2180 - loss: 0.0319 - mse: 0.0237 - val_correlation: 0.5258 - val_loss: 0.0555 - val_mse: 0.0473\n",
      "Epoch 55/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/stepep - correlation: 0.2156 - loss: 0.0316 - mse: 0.023\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\n",
      "Epoch 55: val_loss did not improve from 0.05371\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - correlation: 0.2157 - loss: 0.0316 - mse: 0.0235 - val_correlation: 0.5075 - val_loss: 0.0543 - val_mse: 0.0463\n",
      "Epoch 56/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/stepep - correlation: 0.2181 - loss: 0.0317 - mse: 0.023\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\n",
      "Epoch 56: val_loss did not improve from 0.05371\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - correlation: 0.2180 - loss: 0.0317 - mse: 0.0237 - val_correlation: 0.4977 - val_loss: 0.0540 - val_mse: 0.0461\n",
      "Epoch 57/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/stepep - correlation: 0.2164 - loss: 0.0314 - mse: 0.023\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\n",
      "Epoch 57: val_loss did not improve from 0.05371\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - correlation: 0.2163 - loss: 0.0314 - mse: 0.0235 - val_correlation: 0.5103 - val_loss: 0.0546 - val_mse: 0.0468\n",
      "Epoch 58/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/stepep - correlation: 0.2166 - loss: 0.0313 - mse: 0.023\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\n",
      "Epoch 58: val_loss improved from 0.05371 to 0.05320, saving model to /home/lcaldarevic/workspace/ecg_derived_resp_dl/notebooks/models/gentle-sweep-2.weights.h5\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - correlation: 0.2165 - loss: 0.0313 - mse: 0.0236 - val_correlation: 0.5043 - val_loss: 0.0532 - val_mse: 0.0456\n",
      "Epoch 59/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/stepep - correlation: 0.2170 - loss: 0.0312 - mse: 0.023\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\n",
      "Epoch 59: val_loss improved from 0.05320 to 0.05310, saving model to /home/lcaldarevic/workspace/ecg_derived_resp_dl/notebooks/models/gentle-sweep-2.weights.h5\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - correlation: 0.2170 - loss: 0.0312 - mse: 0.0236 - val_correlation: 0.5008 - val_loss: 0.0531 - val_mse: 0.0456\n",
      "Epoch 60/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/stepep - correlation: 0.2137 - loss: 0.0309 - mse: 0.023\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\n",
      "Epoch 60: val_loss did not improve from 0.05310\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - correlation: 0.2137 - loss: 0.0309 - mse: 0.0234 - val_correlation: 0.5202 - val_loss: 0.0551 - val_mse: 0.0477\n",
      "Epoch 61/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/stepep - correlation: 0.2108 - loss: 0.0304 - mse: 0.023\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\n",
      "Epoch 61: val_loss did not improve from 0.05310\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - correlation: 0.2110 - loss: 0.0304 - mse: 0.0231 - val_correlation: 0.5228 - val_loss: 0.0544 - val_mse: 0.0471\n",
      "Epoch 62/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/stepep - correlation: 0.2111 - loss: 0.0305 - mse: 0.023\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\n",
      "Epoch 62: val_loss did not improve from 0.05310\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - correlation: 0.2112 - loss: 0.0305 - mse: 0.0232 - val_correlation: 0.5164 - val_loss: 0.0545 - val_mse: 0.0473\n",
      "Epoch 63/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/stepep - correlation: 0.2115 - loss: 0.0302 - mse: 0.023\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\n",
      "Epoch 63: val_loss improved from 0.05310 to 0.05309, saving model to /home/lcaldarevic/workspace/ecg_derived_resp_dl/notebooks/models/gentle-sweep-2.weights.h5\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - correlation: 0.2115 - loss: 0.0302 - mse: 0.0231 - val_correlation: 0.5160 - val_loss: 0.0531 - val_mse: 0.0460\n",
      "Epoch 64/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/stepep - correlation: 0.2090 - loss: 0.0299 - mse: 0.022\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\n",
      "Epoch 64: val_loss improved from 0.05309 to 0.05252, saving model to /home/lcaldarevic/workspace/ecg_derived_resp_dl/notebooks/models/gentle-sweep-2.weights.h5\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - correlation: 0.2091 - loss: 0.0299 - mse: 0.0228 - val_correlation: 0.5020 - val_loss: 0.0525 - val_mse: 0.0456\n",
      "Epoch 65/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/stepep - correlation: 0.2122 - loss: 0.0301 - mse: 0.023\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\n",
      "Epoch 65: val_loss improved from 0.05252 to 0.05217, saving model to /home/lcaldarevic/workspace/ecg_derived_resp_dl/notebooks/models/gentle-sweep-2.weights.h5\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - correlation: 0.2121 - loss: 0.0301 - mse: 0.0231 - val_correlation: 0.4966 - val_loss: 0.0522 - val_mse: 0.0453\n",
      "Epoch 66/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/stepep - correlation: 0.2106 - loss: 0.0298 - mse: 0.023\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\n",
      "Epoch 66: val_loss improved from 0.05217 to 0.05184, saving model to /home/lcaldarevic/workspace/ecg_derived_resp_dl/notebooks/models/gentle-sweep-2.weights.h5\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - correlation: 0.2106 - loss: 0.0298 - mse: 0.0230 - val_correlation: 0.4972 - val_loss: 0.0518 - val_mse: 0.0451\n",
      "Epoch 67/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/stepep - correlation: 0.2071 - loss: 0.0294 - mse: 0.022\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\n",
      "Epoch 67: val_loss did not improve from 0.05184\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - correlation: 0.2073 - loss: 0.0294 - mse: 0.0227 - val_correlation: 0.5452 - val_loss: 0.0549 - val_mse: 0.0483\n",
      "Epoch 68/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/stepep - correlation: 0.2089 - loss: 0.0296 - mse: 0.022\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\n",
      "Epoch 68: val_loss did not improve from 0.05184\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - correlation: 0.2089 - loss: 0.0296 - mse: 0.0229 - val_correlation: 0.5174 - val_loss: 0.0536 - val_mse: 0.0470\n",
      "Epoch 69/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/stepep - correlation: 0.2077 - loss: 0.0292 - mse: 0.022\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\n",
      "Epoch 69: val_loss did not improve from 0.05184\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - correlation: 0.2078 - loss: 0.0292 - mse: 0.0227 - val_correlation: 0.5182 - val_loss: 0.0530 - val_mse: 0.0466\n",
      "Epoch 70/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/stepep - correlation: 0.2077 - loss: 0.0292 - mse: 0.022\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\n",
      "Epoch 70: val_loss did not improve from 0.05184\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - correlation: 0.2076 - loss: 0.0292 - mse: 0.0227 - val_correlation: 0.5164 - val_loss: 0.0526 - val_mse: 0.0462\n",
      "Epoch 71/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/stepep - correlation: 0.2045 - loss: 0.0288 - mse: 0.022\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\n",
      "Epoch 71: val_loss did not improve from 0.05184\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - correlation: 0.2046 - loss: 0.0289 - mse: 0.0225 - val_correlation: 0.5232 - val_loss: 0.0527 - val_mse: 0.0463\n",
      "Epoch 72/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/stepep - correlation: 0.2071 - loss: 0.0289 - mse: 0.022\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\n",
      "Epoch 72: val_loss did not improve from 0.05184\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - correlation: 0.2071 - loss: 0.0289 - mse: 0.0226 - val_correlation: 0.5239 - val_loss: 0.0528 - val_mse: 0.0466\n",
      "Epoch 73/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/stepep - correlation: 0.2068 - loss: 0.0289 - mse: 0.022\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\n",
      "Epoch 73: val_loss did not improve from 0.05184\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - correlation: 0.2068 - loss: 0.0288 - mse: 0.0226 - val_correlation: 0.5113 - val_loss: 0.0524 - val_mse: 0.0463\n",
      "Epoch 74/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/stepep - correlation: 0.2038 - loss: 0.0286 - mse: 0.022\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\n",
      "Epoch 74: val_loss improved from 0.05184 to 0.05173, saving model to /home/lcaldarevic/workspace/ecg_derived_resp_dl/notebooks/models/gentle-sweep-2.weights.h5\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - correlation: 0.2039 - loss: 0.0286 - mse: 0.0225 - val_correlation: 0.5059 - val_loss: 0.0517 - val_mse: 0.0456\n",
      "Epoch 75/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/stepep - correlation: 0.2053 - loss: 0.0286 - mse: 0.022\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\n",
      "Epoch 75: val_loss did not improve from 0.05173\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - correlation: 0.2052 - loss: 0.0286 - mse: 0.0225 - val_correlation: 0.5361 - val_loss: 0.0538 - val_mse: 0.0478\n",
      "Epoch 76/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/stepep - correlation: 0.2044 - loss: 0.0285 - mse: 0.022\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\n",
      "Epoch 76: val_loss did not improve from 0.05173\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - correlation: 0.2044 - loss: 0.0285 - mse: 0.0225 - val_correlation: 0.5506 - val_loss: 0.0538 - val_mse: 0.0478\n",
      "Epoch 77/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/stepep - correlation: 0.2061 - loss: 0.0285 - mse: 0.022\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\n",
      "Epoch 77: val_loss did not improve from 0.05173\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - correlation: 0.2059 - loss: 0.0285 - mse: 0.0225 - val_correlation: 0.5354 - val_loss: 0.0537 - val_mse: 0.0478\n",
      "Epoch 78/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/stepep - correlation: 0.2033 - loss: 0.0282 - mse: 0.022\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\n",
      "Epoch 78: val_loss did not improve from 0.05173\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 61ms/step - correlation: 0.2032 - loss: 0.0282 - mse: 0.0223 - val_correlation: 0.5202 - val_loss: 0.0522 - val_mse: 0.0464\n",
      "Epoch 79/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/stepep - correlation: 0.2056 - loss: 0.0282 - mse: 0.022\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\n",
      "Epoch 79: val_loss did not improve from 0.05173\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - correlation: 0.2055 - loss: 0.0282 - mse: 0.0224 - val_correlation: 0.5247 - val_loss: 0.0527 - val_mse: 0.0469\n",
      "Epoch 80/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/stepep - correlation: 0.1974 - loss: 0.0275 - mse: 0.021\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\n",
      "Epoch 80: val_loss did not improve from 0.05173\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - correlation: 0.1977 - loss: 0.0275 - mse: 0.0218 - val_correlation: 0.5518 - val_loss: 0.0541 - val_mse: 0.0485\n",
      "Epoch 81/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/stepep - correlation: 0.2020 - loss: 0.0278 - mse: 0.022\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\n",
      "Epoch 81: val_loss did not improve from 0.05173\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - correlation: 0.2020 - loss: 0.0278 - mse: 0.0221 - val_correlation: 0.5261 - val_loss: 0.0521 - val_mse: 0.0465\n",
      "Epoch 82/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/stepep - correlation: 0.2003 - loss: 0.0276 - mse: 0.022\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\n",
      "Epoch 82: val_loss improved from 0.05173 to 0.05115, saving model to /home/lcaldarevic/workspace/ecg_derived_resp_dl/notebooks/models/gentle-sweep-2.weights.h5\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - correlation: 0.2003 - loss: 0.0276 - mse: 0.0220 - val_correlation: 0.5232 - val_loss: 0.0512 - val_mse: 0.0456\n",
      "Epoch 83/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/stepep - correlation: 0.2007 - loss: 0.0276 - mse: 0.022\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\n",
      "Epoch 83: val_loss improved from 0.05115 to 0.05068, saving model to /home/lcaldarevic/workspace/ecg_derived_resp_dl/notebooks/models/gentle-sweep-2.weights.h5\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - correlation: 0.2008 - loss: 0.0276 - mse: 0.0221 - val_correlation: 0.5089 - val_loss: 0.0507 - val_mse: 0.0452\n",
      "Epoch 84/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/stepep - correlation: 0.2002 - loss: 0.0275 - mse: 0.022\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\n",
      "Epoch 84: val_loss did not improve from 0.05068\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - correlation: 0.2001 - loss: 0.0275 - mse: 0.0220 - val_correlation: 0.5299 - val_loss: 0.0526 - val_mse: 0.0472\n",
      "Epoch 85/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/stepep - correlation: 0.1951 - loss: 0.0270 - mse: 0.021\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\n",
      "Epoch 85: val_loss did not improve from 0.05068\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - correlation: 0.1953 - loss: 0.0270 - mse: 0.0216 - val_correlation: 0.5311 - val_loss: 0.0522 - val_mse: 0.0468\n",
      "Epoch 86/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/stepep - correlation: 0.1963 - loss: 0.0271 - mse: 0.021\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\n",
      "Epoch 86: val_loss did not improve from 0.05068\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - correlation: 0.1964 - loss: 0.0271 - mse: 0.0217 - val_correlation: 0.5202 - val_loss: 0.0514 - val_mse: 0.0460\n",
      "Epoch 87/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/stepep - correlation: 0.1978 - loss: 0.0271 - mse: 0.021\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\n",
      "Epoch 87: val_loss did not improve from 0.05068\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - correlation: 0.1978 - loss: 0.0271 - mse: 0.0218 - val_correlation: 0.5309 - val_loss: 0.0518 - val_mse: 0.0465\n",
      "Epoch 88/200\n",
      "\u001b[1m17/47\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - correlation: 0.1980 - loss: 0.0270 - mse: 0.0217"
     ]
    }
   ],
   "source": [
    "sweep_config = create_sweep_config()\n",
    "sweep_id = wandb.sweep(sweep_config, project=\"fantasia-hp-tuning\")\n",
    "\n",
    "wandb.agent(sweep_id, train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263e2269-b301-4854-850f-56fc3105bbb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_signals_in_grid(predicted_signals, true_signals, labels=['Predicted', 'True']):\n",
    "    fig, axs = plt.subplots(len(predicted_signals)//2, 2, figsize=(20, 50))\n",
    "    axs = axs.flatten() \n",
    "\n",
    "    for i in range(len(predicted_signals)):  \n",
    "        ax = axs[i]\n",
    "        pred_signal = predicted_signals[i]\n",
    "        true_signal = true_signals[i]\n",
    "\n",
    "        #loss = tf.keras.losses.mse(pred_signal, true_signal)\n",
    "        #cc = correlation(pred_signal, true_signal)\n",
    "\n",
    "        # Plotting both signals in the same subplot\n",
    "        ax.plot(pred_signal, label=labels[0])\n",
    "        ax.plot(true_signal, label=labels[1], alpha=0.75)\n",
    "        ax.legend()\n",
    "        #ax.set_title(f'cc:  {cc}')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ddd4a9-28fa-4eba-9242-0fedd1edea40",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_signals_in_grid(windows_ecg_train[0:50], windows_resp_train[0:50], ['ecg', 'resp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2466995e-388f-4e3c-90cf-c485108e9f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "windows_ecg_train = ecg_scaler.inverse_transform(windows_ecg_train.squeeze(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c522184-e30a-4273-babf-4a643069e699",
   "metadata": {},
   "outputs": [],
   "source": [
    "windows_resp_train = resp_scaler.inverse_transform(windows_resp_train.squeeze(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acdbd322-d184-47d7-9c14-60e7167819ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_signals_in_grid(windows_ecg_train[0:50], windows_resp_train[0:50], ['ecg', 'resp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7c3976-7e68-4633-b23c-6c809c4295a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b55ba4-842d-4b68-b8b0-f90656813c82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d3696196-b9fa-4f54-8842-520d62c98388",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.signal import resample\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import wfdb\n",
    "import pandas as pd\n",
    "import os\n",
    "import neurokit2 as nk\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to load the signals\n",
    "def load_fantasia():\n",
    "    files = os.listdir(\"/home/lcaldarevic/workspace/fantasia-database-1.0.0/\")\n",
    "    files = [s.replace('.dat', '') for s in files if \".dat\" in s]\n",
    "    \n",
    "    data_fantasia = {}\n",
    "    patients_fantasia = []\n",
    "\n",
    "    for i, participant in enumerate(files):\n",
    "        patients_fantasia.append(participant)\n",
    "    \n",
    "        data, info = wfdb.rdsamp(\"/home/lcaldarevic/workspace/fantasia-database-1.0.0/\" + participant)\n",
    "    \n",
    "        # Get signal\n",
    "        data = pd.DataFrame(data, columns=info[\"sig_name\"])\n",
    "        ecg_signal = data[\"ECG\"].values\n",
    "        resp_signal = data[\"RESP\"].values\n",
    "        \n",
    "        data_fantasia[participant] = np.vstack((ecg_signal, resp_signal))\n",
    "    \n",
    "    return data_fantasia, patients_fantasia\n",
    "\n",
    "# Function to handle NaN values by interpolation\n",
    "def fill_nan_values(data):\n",
    "    filled_data = {}\n",
    "    for participant, signals in data.items():\n",
    "        ecg_data = signals[0, :]\n",
    "        resp_data = signals[1, :]\n",
    "\n",
    "        if np.isnan(ecg_data).all():\n",
    "            print(f\"All NaN values in ECG signal for participant {participant}. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        if np.isnan(resp_data).all():\n",
    "            print(f\"All NaN values in RESP signal for participant {participant}. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        ecg_filled = nk.signal_interpolate(ecg_data, method='linear')\n",
    "        resp_filled = nk.signal_interpolate(resp_data, method='linear')\n",
    "\n",
    "        filled_data[participant] = np.vstack((ecg_filled, resp_filled))\n",
    "    \n",
    "    return filled_data\n",
    "\n",
    "# Resample the signals from 250 Hz to 50 Hz\n",
    "def resample_signal(signal, original_rate, target_rate):\n",
    "    num_samples = len(signal)\n",
    "    duration = num_samples / original_rate\n",
    "    num_samples_resampled = int(duration * target_rate)\n",
    "    return resample(signal, num_samples_resampled)\n",
    "\n",
    "# Function to load, interpolate, and resample the signals\n",
    "def load_and_preprocess_fantasia(target_rate=50):\n",
    "    data_fantasia, patients_fantasia = load_fantasia()\n",
    "\n",
    "    # Handle NaN values before resampling\n",
    "    data_filled = fill_nan_values(data_fantasia)\n",
    "\n",
    "    processed_data = {}\n",
    "    for participant, signals in data_filled.items():\n",
    "        ecg_filled = signals[0, :]\n",
    "        resp_filled = signals[1, :]\n",
    "\n",
    "        # Resample signals\n",
    "        ecg_resampled = resample_signal(ecg_filled, original_rate=250, target_rate=target_rate)\n",
    "        resp_resampled = resample_signal(resp_filled, original_rate=250, target_rate=target_rate)\n",
    "\n",
    "        # Check for NaNs after resampling\n",
    "        if np.isnan(ecg_resampled).any() or np.isnan(resp_resampled).any():\n",
    "            print(f\"NaN values found after resampling for participant {participant}. Skipping.\")\n",
    "            continue\n",
    "        \n",
    "        processed_data[participant] = np.vstack((ecg_resampled, resp_resampled))\n",
    "    \n",
    "    return processed_data, patients_fantasia\n",
    "\n",
    "# Split the data by patients\n",
    "def split_data_by_patients(patients, seed=0):\n",
    "    train_val_patients, test_patients = train_test_split(patients, test_size=0.15, random_state=seed)\n",
    "    train_patients, val_patients = train_test_split(train_val_patients, test_size=0.20, random_state=seed)\n",
    "    return train_patients, val_patients, test_patients\n",
    "\n",
    "# Flatten the signals for Min-Max Scaling\n",
    "def flatten_signals(data, patients):\n",
    "    flattened_ecg = []\n",
    "    flattened_resp = []\n",
    "    \n",
    "    for patient in patients:\n",
    "        ecg_signal = data[patient][0]\n",
    "        resp_signal = data[patient][1]\n",
    "        flattened_ecg.extend(ecg_signal)\n",
    "        flattened_resp.extend(resp_signal)\n",
    "    \n",
    "    return np.array(flattened_ecg).reshape(-1, 1), np.array(flattened_resp).reshape(-1, 1)\n",
    "\n",
    "# Apply Min-Max Scaling using sklearn's MinMaxScaler\n",
    "def apply_min_max_scaling(data, patients, scaler_ecg, scaler_resp):\n",
    "    normalized_data = {}\n",
    "    \n",
    "    for patient, signals in data.items():\n",
    "        if patient not in patients:\n",
    "            continue\n",
    "        \n",
    "        ecg_signal = signals[0]\n",
    "        resp_signal = signals[1]\n",
    "        \n",
    "        ecg_normalized = scaler_ecg.transform(ecg_signal.reshape(-1, 1)).flatten()\n",
    "        resp_normalized = scaler_resp.transform(resp_signal.reshape(-1, 1)).flatten()\n",
    "        \n",
    "        normalized_data[patient] = np.vstack((ecg_normalized, resp_normalized))\n",
    "    \n",
    "    return normalized_data\n",
    "\n",
    "# Function to check for NaN values\n",
    "def check_for_nan(data, patients):\n",
    "    for patient in patients:\n",
    "        if np.isnan(data[patient]).any():\n",
    "            print(f\"NaN values found in patient data index: {patient}\")\n",
    "\n",
    "# Load and preprocess the data\n",
    "data, patients = load_and_preprocess_fantasia()\n",
    "\n",
    "# Check for NaN values after preprocessing\n",
    "check_for_nan(data, patients)\n",
    "\n",
    "# Split the data by patients\n",
    "train_patients, val_patients, test_patients = split_data_by_patients(patients)\n",
    "\n",
    "# Flatten the training signals to fit the scaler\n",
    "flattened_ecg_train, flattened_resp_train = flatten_signals(data, train_patients)\n",
    "\n",
    "# Fit Min-Max Scaler on training signals\n",
    "scaler_ecg = MinMaxScaler()\n",
    "scaler_resp = MinMaxScaler()\n",
    "\n",
    "scaler_ecg.fit(flattened_ecg_train)\n",
    "scaler_resp.fit(flattened_resp_train)\n",
    "\n",
    "# Apply Min-Max Scaling to training, validation, and test sets\n",
    "normalized_train_data = apply_min_max_scaling(data, train_patients, scaler_ecg, scaler_resp)\n",
    "normalized_val_data = apply_min_max_scaling(data, val_patients, scaler_ecg, scaler_resp)\n",
    "normalized_test_data = apply_min_max_scaling(data, test_patients, scaler_ecg, scaler_resp)\n",
    "\n",
    "# Extract ECG and RESP signals for plotting distributions\n",
    "windows_ecg_train = np.concatenate([normalized_train_data[patient][0] for patient in train_patients])\n",
    "windows_ecg_validation = np.concatenate([normalized_val_data[patient][0] for patient in val_patients])\n",
    "windows_ecg_test = np.concatenate([normalized_test_data[patient][0] for patient in test_patients])\n",
    "\n",
    "windows_resp_train = np.concatenate([normalized_train_data[patient][1] for patient in train_patients])\n",
    "windows_resp_validation = np.concatenate([normalized_val_data[patient][1] for patient in val_patients])\n",
    "windows_resp_test = np.concatenate([normalized_test_data[patient][1] for patient in test_patients])\n",
    "\n",
    "# Plot the distributions\n",
    "plt.hist(windows_ecg_train.flatten(), bins=100, alpha=0.7, label=\"ecg train\")\n",
    "plt.hist(windows_ecg_validation.flatten(), bins=100, alpha=0.7, label=\"ecg valid\")\n",
    "plt.hist(windows_ecg_test.flatten(), bins=100, alpha=0.7, label=\"ecg test\")\n",
    "plt.title('Distribution of ECG Values')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.hist(windows_resp_train.flatten(), bins=100, alpha=0.7, label=\"resp train\")\n",
    "plt.hist(windows_resp_validation.flatten(), bins=100, alpha=0.7, label=\"resp valid\")\n",
    "plt.hist(windows_resp_test.flatten(), bins=100, alpha=0.7, label=\"resp test\")\n",
    "plt.title('Distribution of RESP Values')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "76603b69-4dc7-4e9d-ba9d-2b8814bfa3e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.05059177],\n",
       "       [-0.00760027],\n",
       "       [-0.00258284],\n",
       "       ...,\n",
       "       [-0.2371808 ],\n",
       "       [-0.11333374],\n",
       "       [-0.11795426]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flattened_ecg_train"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfgpu2-env",
   "language": "python",
   "name": "tfgpu2-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
