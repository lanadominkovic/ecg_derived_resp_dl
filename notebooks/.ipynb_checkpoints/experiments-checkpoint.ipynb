{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5ec0a83-aa01-4efd-8baa-8edd5bad8cbf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-26T18:51:44.858395Z",
     "iopub.status.busy": "2024-04-26T18:51:44.857547Z",
     "iopub.status.idle": "2024-04-26T18:51:48.786745Z",
     "shell.execute_reply": "2024-04-26T18:51:48.786376Z",
     "shell.execute_reply.started": "2024-04-26T18:51:44.858310Z"
    }
   },
   "outputs": [],
   "source": [
    "import scipy.signal as signal\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, LambdaCallback, TensorBoard, EarlyStopping\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "\n",
    "from keras import layers, models, regularizers\n",
    "\n",
    "from tensorflow.keras import layers, models, regularizers\n",
    "\n",
    "def create_model(config):\n",
    "    kernel_size = config['kernel_size']\n",
    "    regularizer = regularizers.l2(config['reg'])\n",
    "    dropout_rate = config['dropout']\n",
    "    size_0 = config['start_filters']\n",
    "\n",
    "    # Input layer\n",
    "    in_data = layers.Input(shape=(config['input_size'], 1))\n",
    "\n",
    "    # Encoder part\n",
    "    conv0 = layers.Conv1D(size_0, kernel_size, kernel_regularizer=regularizer, activation='relu', padding='same', kernel_initializer='he_normal')(in_data)\n",
    "    conv0 = layers.BatchNormalization()(conv0)\n",
    "    conv0 = layers.Conv1D(size_0, kernel_size, kernel_regularizer=regularizer, activation='relu', padding='same', kernel_initializer='he_normal')(conv0)\n",
    "    conv0 = layers.BatchNormalization()(conv0)\n",
    "    pool0 = layers.MaxPooling1D(pool_size=2)(conv0)\n",
    "\n",
    "    size_1 = size_0 * 2\n",
    "    conv1 = layers.Conv1D(size_1, kernel_size, kernel_regularizer=regularizer, activation='relu', padding='same', kernel_initializer='he_normal')(pool0)\n",
    "    conv1 = layers.BatchNormalization()(conv1)\n",
    "    conv1 = layers.Conv1D(size_1, kernel_size, kernel_regularizer=regularizer, activation='relu', padding='same', kernel_initializer='he_normal')(conv1)\n",
    "    conv1 = layers.BatchNormalization()(conv1)\n",
    "    conv1 = layers.Dropout(dropout_rate)(conv1)\n",
    "    pool1 = layers.MaxPooling1D(pool_size=2)(conv1)\n",
    "\n",
    "    size_2 = size_1 * 2\n",
    "    conv2 = layers.Conv1D(size_2, kernel_size, kernel_regularizer=regularizer, activation='relu', padding='same', kernel_initializer='he_normal')(pool1)\n",
    "    conv2 = layers.BatchNormalization()(conv2)\n",
    "    conv2 = layers.Conv1D(size_2, kernel_size, kernel_regularizer=regularizer, activation='relu', padding='same', kernel_initializer='he_normal')(conv2)\n",
    "    conv2 = layers.BatchNormalization()(conv2)\n",
    "\n",
    "    # Decoder part\n",
    "    up1 = layers.UpSampling1D(size=2)(conv2)\n",
    "    up_conv1 = layers.Conv1D(size_2, 2, activation='relu', padding='same', kernel_initializer='he_normal')(up1)\n",
    "    up_conv1 = layers.BatchNormalization()(up_conv1)\n",
    "    merge1 = layers.concatenate([conv1, up_conv1], axis=2)\n",
    "    conv3 = layers.Conv1D(size_1, kernel_size, kernel_regularizer=regularizer, activation='relu', padding='same', kernel_initializer='he_normal')(merge1)\n",
    "    conv3 = layers.BatchNormalization()(conv3)\n",
    "    conv3 = layers.Conv1D(size_1, kernel_size, kernel_regularizer=regularizer, activation='relu', padding='same', kernel_initializer='he_normal')(conv3)\n",
    "    conv3 = layers.BatchNormalization()(conv3)\n",
    "    conv3 = layers.Dropout(dropout_rate)(conv3)\n",
    "\n",
    "    up2 = layers.UpSampling1D(size=2)(conv3)\n",
    "    up_conv2 = layers.Conv1D(size_1, 2, activation='relu', padding='same', kernel_initializer='he_normal')(up2)\n",
    "    up_conv2 = layers.BatchNormalization()(up_conv2)\n",
    "    merge2 = layers.concatenate([conv0, up_conv2], axis=2)\n",
    "    conv4 = layers.Conv1D(size_0, kernel_size, kernel_regularizer=regularizer, activation='relu', padding='same', kernel_initializer='he_normal')(merge2)\n",
    "    conv4 = layers.BatchNormalization()(conv4)\n",
    "    conv4 = layers.Conv1D(size_0, kernel_size, kernel_regularizer=regularizer, activation='relu', padding='same', kernel_initializer='he_normal')(conv4)\n",
    "    conv4 = layers.BatchNormalization()(conv4)\n",
    "\n",
    "    # Output layer\n",
    "    #out_data = layers.Conv1D(1, kernel_size, activation='sigmoid', padding='same')(conv4)\n",
    "    out_data = layers.Conv1D(1, kernel_size, activation=None, padding='same')(conv4)\n",
    "\n",
    "    model = models.Model(inputs=[in_data], outputs=[out_data])\n",
    "    model.summary()\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def sliding_window(data, window_size, downsampled_window_size, overlap, train_patients, validation_patients, test_patients):\n",
    "    windows_ecg_train = []\n",
    "    windows_resp_train = []\n",
    "\n",
    "    for train_patient in train_patients:\n",
    "    \n",
    "        N = len(data[train_patient][0])\n",
    "        max_step = int(N//(window_size*overlap))\n",
    "        for step in range(max_step):\n",
    "            ecg = data[train_patient][0][step * int(window_size*overlap):step * int(window_size*overlap) + window_size] \n",
    "            resp = data[train_patient][1][step * int(window_size*overlap):step * int(window_size*overlap) + window_size]\n",
    "            \n",
    "            if (ecg.min() < ecg.max()):\n",
    "                normalized_ecg = (ecg-ecg.min())/(ecg.max()-ecg.min())-0.5\n",
    "                #zero_centered_ecg = ecg - np.mean(ecg)\n",
    "                #normalized_ecg = zero_centered_ecg / np.std(zero_centered_ecg)\n",
    "                resampled_ecg = signal.resample(normalized_ecg, downsampled_window_size)\n",
    "                if resp.min() < resp.max():\n",
    "                    normalized_resp = (resp-resp.min())/(resp.max()-resp.min())\n",
    "                    #zero_centered_resp = resp - np.mean(resp)\n",
    "                    #normalized_resp = zero_centered_resp / np.std(zero_centered_resp)\n",
    "                    resampled_resp = signal.resample(normalized_resp, downsampled_window_size)\n",
    "                    windows_ecg_train.append(np.float32(resampled_ecg))\n",
    "                    windows_resp_train.append(np.float32(resampled_resp))\n",
    "            \n",
    "            \n",
    "    windows_ecg_validation = []\n",
    "    windows_resp_validation = []\n",
    "\n",
    "\n",
    "    for validation_patient in validation_patients:\n",
    "        N = len(data[validation_patient][0])\n",
    "        max_step = int(N//(window_size*overlap))\n",
    "        for step in range(max_step):\n",
    "            ecg = data[validation_patient][0][step * int(window_size*overlap):step * int(window_size*overlap) + window_size] \n",
    "            resp = data[validation_patient][1][step * int(window_size*overlap):step * int(window_size*overlap) + window_size]\n",
    "            \n",
    "            if (ecg.min() < ecg.max()):\n",
    "                normalized_ecg = (ecg-ecg.min())/(ecg.max()-ecg.min())-0.5\n",
    "                #zero_centered_ecg = ecg - np.mean(ecg)\n",
    "                #normalized_ecg = zero_centered_ecg / np.std(zero_centered_ecg)\n",
    "                resampled_ecg = signal.resample(normalized_ecg, downsampled_window_size)\n",
    "                if resp.min() < resp.max():\n",
    "                    normalized_resp = (resp-resp.min())/(resp.max()-resp.min())\n",
    "                    #zero_centered_resp = resp - np.mean(resp)\n",
    "                    #normalized_resp = zero_centered_resp / np.std(zero_centered_resp)\n",
    "                    resampled_resp = signal.resample(normalized_resp, downsampled_window_size)\n",
    "                    windows_ecg_validation.append(np.float32(resampled_ecg))\n",
    "                    windows_resp_validation.append(np.float32(resampled_resp))\n",
    "          \n",
    "    windows_ecg_test = []\n",
    "    windows_resp_test = []\n",
    "    \n",
    "    for test_patient in test_patients:\n",
    "        N = len(data[test_patient][0])\n",
    "        max_step = int(N//(window_size*overlap))\n",
    "        for step in range(max_step):\n",
    "            ecg = data[test_patient][0][step * int(window_size*overlap):step * int(window_size*overlap) + window_size] \n",
    "            resp = data[test_patient][1][step * int(window_size*overlap):step * int(window_size*overlap) + window_size]\n",
    "            \n",
    "            if (ecg.min() < ecg.max()):\n",
    "                normalized_ecg = (ecg-ecg.min())/(ecg.max()-ecg.min())-0.5\n",
    "                #zero_centered_ecg = ecg - np.mean(ecg)\n",
    "                #normalized_ecg = zero_centered_ecg / np.std(zero_centered_ecg)\n",
    "                resampled_ecg = signal.resample(normalized_ecg, downsampled_window_size)\n",
    "                if resp.min() < resp.max():\n",
    "                    normalized_resp = (resp-resp.min())/(resp.max()-resp.min())\n",
    "                    #zero_centered_resp = resp - np.mean(resp)\n",
    "                    #normalized_resp = zero_centered_resp / np.std(zero_centered_resp)\n",
    "                    resampled_resp = signal.resample(normalized_resp, downsampled_window_size)\n",
    "                    windows_ecg_test.append(np.float32(resampled_ecg))\n",
    "                    windows_resp_test.append(np.float32(resampled_resp))\n",
    "\n",
    "    windows_ecg_train = np.stack(windows_ecg_train, axis=0)\n",
    "    windows_resp_train = np.stack(windows_resp_train, axis=0)\n",
    "    windows_ecg_validation = np.stack(windows_ecg_validation, axis=0)\n",
    "    windows_resp_validation = np.stack(windows_resp_validation, axis=0)\n",
    "    windows_ecg_test = np.stack(windows_ecg_test, axis=0)\n",
    "    windows_resp_test = np.stack(windows_resp_test, axis=0)\n",
    "\n",
    "    windows_ecg_train = windows_ecg_train[:,:,np.newaxis]\n",
    "    windows_resp_train = windows_resp_train[:,:,np.newaxis]\n",
    "    windows_ecg_validation = windows_ecg_validation[:,:,np.newaxis]\n",
    "    windows_resp_validation = windows_resp_validation[:,:,np.newaxis]\n",
    "    windows_ecg_test = windows_ecg_test[:,:,np.newaxis]\n",
    "    windows_resp_test = windows_resp_test[:,:,np.newaxis]\n",
    "\n",
    "    return windows_ecg_train, windows_resp_train, windows_ecg_validation, windows_resp_validation, windows_ecg_test, windows_resp_test\n",
    "\n",
    "def moving_average(signal, window_size):\n",
    "    window = np.ones(int(window_size)) / float(window_size)\n",
    "    return np.convolve(signal, window, 'same')\n",
    "    \n",
    "def sliding_window(data, downsampled_window_size, train_patients, validation_patients, test_patients=None):\n",
    "\t#window_size=3600\n",
    "\twindow_size=int(downsampled_window_size*1.953125)\n",
    "\toverlap=1/2\n",
    "\n",
    "\twindows_ecg_train=[]\n",
    "\twindows_resp_train=[]\n",
    "\t\t\n",
    "\twindows_ecg_validation=[]\n",
    "\twindows_resp_validation=[]\n",
    "\n",
    "\tfor record_index in train_patients:\n",
    "\t\tN=len(data[record_index][0,:])\n",
    "\t\tmax_step=int(N//(window_size*overlap))\n",
    "\t\tfor step in range(1,max_step-1):\n",
    "\t\t\trecrd=data[record_index][0,int(step)*int(window_size*overlap):int(step)*int(window_size*overlap) + window_size]\n",
    "\t\t\tif recrd.min()<recrd.max():\n",
    "\t\t\t\tnormalized=(recrd-recrd.min())/(recrd.max()-recrd.min())\n",
    "\t\t\t\tnormalized_ecg=signal.resample(normalized, downsampled_window_size)\n",
    "\t\t\t\trecrd=data[record_index][1,int(step)*int(window_size*overlap):int(step)*int(window_size*overlap) + window_size]\n",
    "\t\t\t\tif recrd.min()<recrd.max():\n",
    "\t\t\t\t\tnormalized=(recrd-recrd.min())/(recrd.max()-recrd.min())\n",
    "\t\t\t\t\tnormalized_resp=signal.resample(normalized, downsampled_window_size)\n",
    "\t\t\t\t\twindows_resp_train.append(np.float16(normalized_resp))\n",
    "\t\t\t\t\twindows_ecg_train.append(np.float16(normalized_ecg))\n",
    "\t\t\t\t\tif np.isnan(normalized.max()):\n",
    "\t\t\t\t\t\tprint('True')\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tprint(\"skipped\")\n",
    "\t\n",
    "\t\n",
    "\t\t\t\tif np.isnan(normalized.max()):\n",
    "\t\t\t\t\tprint('True')\n",
    "\t\t\telse:\n",
    "\t\t\t\tprint(\"skipped\")\n",
    "\n",
    "\tfor record_index in validation_patients:\n",
    "\t\tN=len(data[record_index][0,:])\n",
    "\t\tmax_step=int(N//(window_size*overlap))\n",
    "\t\tfor step in range(1,max_step-1):\n",
    "\t\t\trecrd=data[record_index][0,int(step)*int(window_size*overlap):int(step)*int(window_size*overlap) + window_size]\n",
    "\t\t\tif recrd.min()<recrd.max():\n",
    "\t\t\t\tnormalized=(recrd-recrd.min())/(recrd.max()-recrd.min())\n",
    "\t\t\t\tnormalized_ecg=signal.resample(normalized, downsampled_window_size)\n",
    "\t\t\t\trecrd=data[record_index][1,int(step)*int(window_size*overlap):int(step)*int(window_size*overlap) + window_size]\n",
    "\t\t\t\tif recrd.min()<recrd.max():\n",
    "\t\t\t\t\tnormalized=(recrd-recrd.min())/(recrd.max()-recrd.min())\n",
    "\t\t\t\t\tnormalized_resp=signal.resample(normalized, downsampled_window_size)\n",
    "\t\t\t\t\twindows_resp_validation.append(np.float16(normalized_resp))\n",
    "\t\t\t\t\twindows_ecg_validation.append(np.float16(normalized_ecg))  \n",
    "\t\t\t\t\tif np.isnan(normalized.max()):\n",
    "\t\t\t\t\t\tprint('True')\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tprint(\"skipped\")\n",
    "\t\n",
    "\t\n",
    "\t\t\t\tif np.isnan(normalized.max()):\n",
    "\t\t\t\t\tprint('True')\n",
    "\t\t\telse:\n",
    "\t\t\t\tprint(\"skipped\")\n",
    "\t\n",
    "\twindows_ecg_train=np.stack(windows_ecg_train, axis=0)\n",
    "\twindows_resp_train=np.stack(windows_resp_train, axis=0)\n",
    "\t\n",
    "\twindows_ecg_validation=np.stack(windows_ecg_validation, axis=0)\n",
    "\twindows_resp_validation=np.stack(windows_resp_validation, axis=0)\n",
    "\n",
    "\twindows_ecg_train=windows_ecg_train[:,:,np.newaxis]\n",
    "\twindows_resp_train=windows_resp_train[:,:,np.newaxis]\n",
    "\t\n",
    "\t\n",
    "\twindows_ecg_validation=windows_ecg_validation[:,:,np.newaxis]\n",
    "\twindows_resp_validation=windows_resp_validation[:,:,np.newaxis]\n",
    "\t\n",
    "\t\n",
    "\tprint(windows_ecg_train.shape)\n",
    "\tprint(windows_resp_train.shape)\n",
    "\t\n",
    "\tprint(windows_ecg_validation.shape)\n",
    "\tprint(windows_resp_validation.shape)\n",
    "\t\n",
    "\twindows_ecg_train=windows_ecg_train[:,:,:]\n",
    "\twindows_ecg_validation=windows_ecg_validation[:,:,:]\n",
    "\twindows_resp_train=windows_resp_train[:,:,:]\n",
    "\twindows_resp_validation=windows_resp_validation[:,:,:]\n",
    "\treturn windows_ecg_train, windows_resp_train, windows_ecg_validation, windows_resp_validation\n",
    "\n",
    "\n",
    "def load_data():\n",
    "     # bidmc\n",
    "    path = \"/Users/lanacaldarevic/workspace/phd/ecg_derived_resp_dl/data/bidmc-ppg-and-respiration-dataset-1.0.0\"\n",
    "    EXT = \"*Signals.csv\"\n",
    "    all_csv_files = [file for path, subdir, files in os.walk(path) for file in glob(os.path.join(path, EXT))]\n",
    "    patients = []\n",
    "    data = {}\n",
    "    no_errors = 0\n",
    "    for file in all_csv_files:\n",
    "        try:\n",
    "            df = pd.read_csv(file)\n",
    "            X1, X2, X3, X4 = df[' PLETH'].values, df[' V'].values, df[' AVR'].values, df[' II'].values\n",
    "            # X = np.concatenate([X1.reshape(len(X1),1),X2.reshape(len(X1),1),X3.reshape(len(X1),1),X4.reshape(len(X1),1)], axis=1)\n",
    "            \n",
    "            Y = df[' RESP'].values\n",
    "            \n",
    "            patient = int(file.split('/')[-1].split('_')[1])\n",
    "            patients.append(patient)\n",
    "            #data[patient] = [X4, Y]\n",
    "            data[patient] = np.array([X4, Y])\n",
    "        except:\n",
    "            no_errors += 1\n",
    "\n",
    "    return data, patients\n",
    "\n",
    "def load_fantasia():\n",
    "    files = os.listdir(\"/Users/lanacaldarevic/workspace/phd/biosignal_deeplearning/fantasia-database-1.0.0/\")\n",
    "    files = [s.replace('.dat', '') for s in files if \".dat\" in s]\n",
    "    \n",
    "    data_fantasia = {}\n",
    "    patients_fantasia = []\n",
    "    \n",
    "    for i, participant in enumerate(files):\n",
    "        patients_fantasia.append(participant)\n",
    "    \n",
    "        data, info = wfdb.rdsamp(\"/Users/lanacaldarevic/workspace/phd/biosignal_deeplearning/fantasia-database-1.0.0/\" + participant)\n",
    "    \n",
    "        # Get signal\n",
    "        data = pd.DataFrame(data, columns=info[\"sig_name\"])\n",
    "        data_fantasia[participant] = np.array([data[\"ECG\"], data[\"RESP\"]])\n",
    "\n",
    "    return data_fantasia, patients_fantasia\n",
    "\n",
    "import io\n",
    "class VisualiseCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, log_dir, frequency=20):\n",
    "        super(VisualiseCallback1, self).__init__()\n",
    "        self.log_dir = log_dir\n",
    "        self.writer = tf.summary.create_file_writer(log_dir)\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if epoch % self.frequency == 0:\n",
    "            fig, ax = plt.subplots(2, 2, figsize=(12, 8))\n",
    "            fig.suptitle('Ground truth vs. Prediction')\n",
    "    \n",
    "            for row in range(2):\n",
    "                train_idx = np.random.randint(0, windows_ecg_train.shape[0])\n",
    "                val_idx = np.random.randint(0, windows_ecg_validation.shape[0])\n",
    "    \n",
    "                to_predict_train = np.array([windows_ecg_train[train_idx]])\n",
    "                ground_truth_train = windows_resp_train[train_idx]\n",
    "                prediction_train = self.model.predict(to_predict_train)[0]\n",
    "                prediction_train_score = self.model.evaluate(to_predict_train, np.array([ground_truth_train]), verbose=0)\n",
    "    \n",
    "                to_predict_validation = np.array([windows_ecg_validation[val_idx]])\n",
    "                ground_truth_validation = windows_resp_validation[val_idx]\n",
    "                prediction_validation = self.model.predict(to_predict_validation)[0]\n",
    "                prediction_validation_score = self.model.evaluate(to_predict_validation, np.array([ground_truth_validation]), verbose=0)\n",
    "    \n",
    "                ax[row, 0].plot(ground_truth_train, label='Ground Truth')\n",
    "                ax[row, 0].plot(prediction_train, label='Prediction')\n",
    "                ax[row, 0].set_title(f\"Train Loss: {prediction_train_score[0]:.4f} CC: {prediction_train_score[1]:.4f}\")\n",
    "                ax[row, 0].legend()\n",
    "    \n",
    "                ax[row, 1].plot(ground_truth_validation, label='Ground Truth')\n",
    "                ax[row, 1].plot(prediction_validation, label='Prediction')\n",
    "                ax[row, 1].set_title(f\"Valid Loss: {prediction_validation_score[0]:.4f} CC: {prediction_validation_score[1]:.4f}\")\n",
    "                ax[row, 1].legend()\n",
    "    \n",
    "            plt.tight_layout()\n",
    "            # Convert the matplotlib plot to a PNG image and then to a Tensor\n",
    "            buf = io.BytesIO()\n",
    "            plt.savefig(buf, format='png')\n",
    "            plt.close(fig)\n",
    "            buf.seek(0)\n",
    "            image = tf.image.decode_png(buf.getvalue(), channels=4)\n",
    "            image = tf.expand_dims(image, 0)\n",
    "    \n",
    "            # Log the image to TensorBoard\n",
    "            with self.writer.as_default():\n",
    "                tf.summary.image(\"Predictions vs. Ground Truth\", image, step=epoch)\n",
    "    \n",
    "            self.writer.flush()\n",
    "\n",
    "\n",
    "def correlation(x, y): #todo: check this and see in papers what cross correlation is\n",
    "    # Normalize y to the [0, 1] range\n",
    "    min_y = tf.math.reduce_min(y)\n",
    "    max_y = tf.math.reduce_max(y)\n",
    "    r_up = tf.math.subtract(y, min_y)\n",
    "    r_down = max_y - min_y\n",
    "    new_y = r_up / r_down\n",
    "    \n",
    "    # Compute means\n",
    "    mx = tf.math.reduce_mean(x)\n",
    "    my = tf.math.reduce_mean(new_y)\n",
    "    \n",
    "    # Compute centered values\n",
    "    xm, ym = x - mx, new_y - my\n",
    "    \n",
    "    # Compute correlation coefficient\n",
    "    r_num = tf.reduce_sum(tf.multiply(xm, ym))\n",
    "    r_den = tf.sqrt(tf.multiply(tf.reduce_sum(tf.square(xm)), tf.reduce_sum(tf.square(ym))))\n",
    "    r = r_num / r_den\n",
    "    \n",
    "    # Ensure the result is between -1 and 1\n",
    "    r = tf.maximum(tf.minimum(r, 1.0), -1.0)\n",
    "    \n",
    "    return 1 - r\n",
    "\n",
    "\n",
    "def cross_correlation(y_true, y_pred):\n",
    "    \"\"\" Compute cross-correlation between true and predicted signals. \"\"\"\n",
    "    y_true_mean = tf.reduce_mean(y_true, axis=1, keepdims=True)\n",
    "    y_pred_mean = tf.reduce_mean(y_pred, axis=1, keepdims=True)\n",
    "    \n",
    "    y_true_std = tf.math.reduce_std(y_true, axis=1, keepdims=True)\n",
    "    y_pred_std = tf.math.reduce_std(y_pred, axis=1, keepdims=True)\n",
    "\n",
    "    norm_y_true = (y_true - y_true_mean) / y_true_std\n",
    "    norm_y_pred = (y_pred - y_pred_mean) / y_pred_std\n",
    "\n",
    "    correlation = tf.reduce_mean(norm_y_true * norm_y_pred, axis=1)\n",
    "    return tf.reduce_mean(correlation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7be39bf-1dde-4b57-bf49-800e6671fb7d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-26T18:51:48.787651Z",
     "iopub.status.busy": "2024-04-26T18:51:48.787469Z",
     "iopub.status.idle": "2024-04-26T18:51:51.479671Z",
     "shell.execute_reply": "2024-04-26T18:51:51.479346Z",
     "shell.execute_reply.started": "2024-04-26T18:51:48.787640Z"
    }
   },
   "outputs": [],
   "source": [
    "import wfdb\n",
    "data, patients = load_fantasia()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e4c3764-1bfb-4d2f-b058-6b9817700f81",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-26T18:51:51.480557Z",
     "iopub.status.busy": "2024-04-26T18:51:51.480448Z",
     "iopub.status.idle": "2024-04-26T18:51:51.485796Z",
     "shell.execute_reply": "2024-04-26T18:51:51.485461Z",
     "shell.execute_reply.started": "2024-04-26T18:51:51.480547Z"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "unique_patients = list(set(patients))\n",
    "np.random.shuffle(unique_patients)\n",
    "\n",
    "train_val_patients, test_patients = train_test_split(unique_patients, test_size=0.20, random_state=42)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Convert your list to a NumPy array if it's not already one\n",
    "train_val_patients_array = np.array(train_val_patients)\n",
    "\n",
    "train_ind = []\n",
    "val_ind = []\n",
    "\n",
    "k = 5\n",
    "kf = KFold(n_splits=k)\n",
    "\n",
    "# Now you can perform indexing\n",
    "for train_index, val_index in kf.split(train_val_patients_array):\n",
    "    train_ind.append(train_index)\n",
    "    val_ind.append(val_index)\n",
    "\n",
    "split_ind = 0\n",
    "train_index, val_index = train_ind[split_ind], val_ind[split_ind]\n",
    "train_patients = [patients[i] for i in train_index]\n",
    "validation_patients = [patients[i] for i in val_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9104ab6-13aa-484a-b9eb-f14c20895061",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-26T18:51:51.486994Z",
     "iopub.status.busy": "2024-04-26T18:51:51.486858Z",
     "iopub.status.idle": "2024-04-26T18:51:59.585140Z",
     "shell.execute_reply": "2024-04-26T18:51:59.584841Z",
     "shell.execute_reply.started": "2024-04-26T18:51:51.486984Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "(44274, 1024, 1)\n",
      "(44274, 1024, 1)\n",
      "(12430, 1024, 1)\n",
      "(12430, 1024, 1)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "in_size=int(8*250/1.953125)\n",
    "windows_ecg_train, windows_resp_train, windows_ecg_validation, windows_resp_validation = sliding_window(data, in_size, train_patients, validation_patients, test_patients)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot the distribution\n",
    "plt.hist(windows_ecg_train.flatten(), bins=100, alpha=0.7, label=\"ecg train\")\n",
    "plt.hist(windows_resp_train.flatten(), bins=100, alpha=0.7, label=\"resp train\")\n",
    "plt.hist(windows_ecg_validation.flatten(), bins=100, alpha=0.7, label=\"ecg valid\")\n",
    "plt.hist(windows_resp_validation.flatten(), bins=100, alpha=0.7, label=\"resp valid\")\n",
    "plt.title('Distribution of Flattened Array Values')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34285d8e-3d0c-4438-b850-9c0f9850f997",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-26T18:51:59.585964Z",
     "iopub.status.busy": "2024-04-26T18:51:59.585859Z",
     "iopub.status.idle": "2024-04-26T18:51:59.596401Z",
     "shell.execute_reply": "2024-04-26T18:51:59.596061Z",
     "shell.execute_reply.started": "2024-04-26T18:51:59.585952Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "sampling_rate = 125\n",
    "input_size_seconds = 16 # //2, *2\n",
    "downsampled_window_size = 1024 #? power of 2\n",
    "window_size = input_size_seconds * sampling_rate\n",
    "overlap = 0.5 #25%\n",
    "\n",
    "data, patients = load_data()\n",
    "\n",
    "np.random.seed(42)\n",
    "unique_patients = list(set(patients))\n",
    "np.random.shuffle(unique_patients)\n",
    "\n",
    "train_val_patients, test_patients = train_test_split(unique_patients, test_size=0.20, random_state=42)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Convert your list to a NumPy array if it's not already one\n",
    "train_val_patients_array = np.array(train_val_patients)\n",
    "\n",
    "train_ind = []\n",
    "val_ind = []\n",
    "# Now you can perform indexing\n",
    "for train_index, val_index in kf.split(train_val_patients_array):\n",
    "    train_ind.append(train_index)\n",
    "    val_ind.append(val_index)\n",
    "\n",
    "split_ind = 0\n",
    "train_index, val_index = train_ind[split_ind], val_ind[split_ind]\n",
    "train_patients = [patients[i] for i in train_index]\n",
    "validation_patients = [patients[i] for i in val_index]\n",
    "\n",
    "print(train_patients)\n",
    "print(validation_patients)\n",
    "print(test_patients)\n",
    "# k-folds for CV\n",
    "train_patients = []\n",
    "test_patients = []\n",
    "validation_patients = []\n",
    "k = 5\n",
    "kf = KFold(n_splits=k)\n",
    "train_ind = []\n",
    "test_ind = []\n",
    "\n",
    "for tr_ind, te_ind in kf.split(patients):\n",
    "    train_ind.append(tr_ind)\n",
    "    test_ind.append(te_ind)\n",
    "\n",
    "split_ind = 0\n",
    "train_index, test_index = train_ind[split_ind], test_ind[split_ind]\n",
    "test_index, validation_index = train_test_split(test_index, test_size=0.5, random_state=42)\n",
    "train_patients = [patients[i] for i in train_index]\n",
    "validation_patients = [patients[i] for i in validation_index]\n",
    "test_patients = [patients[i] for i in test_index]\n",
    "\n",
    "windows_ecg_train, windows_resp_train, windows_ecg_validation, windows_resp_validation, windows_ecg_test, windows_resp_test = sliding_window(data, window_size, downsampled_window_size, overlap, train_patients, validation_patients, test_patients)\n",
    "print(windows_ecg_train.shape)\n",
    "print(windows_resp_train.shape)\n",
    "print(windows_ecg_validation.shape)\n",
    "print(windows_resp_validation.shape)\n",
    "print(windows_ecg_test.shape)\n",
    "print(windows_resp_test.shape)\n",
    "\n",
    "\n",
    "in_size=int(8*125/0.9765625)\n",
    "windows_ecg_train, windows_resp_train, windows_ecg_validation, windows_resp_validation = sliding_window(data, in_size, train_patients, validation_patients, test_patients)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot the distribution\n",
    "plt.hist(windows_ecg_train.flatten(), bins=100, alpha=0.7, label=\"ecg train\")\n",
    "plt.hist(windows_resp_train.flatten(), bins=100, alpha=0.7, label=\"resp train\")\n",
    "plt.hist(windows_ecg_validation.flatten(), bins=100, alpha=0.7, label=\"ecg valid\")\n",
    "plt.hist(windows_resp_validation.flatten(), bins=100, alpha=0.7, label=\"resp valid\")\n",
    "plt.title('Distribution of Flattened Array Values')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "if tf.config.list_physical_devices('GPU'):\n",
    "    print(\"GPU enabled\")\n",
    "    with tf.device('/GPU:0'):\n",
    "        windows_ecg_train = tf.convert_to_tensor(windows_ecg_train, dtype=tf.float32)\n",
    "        windows_resp_train = tf.convert_to_tensor(windows_resp_train, dtype=tf.float32)\n",
    "        windows_ecg_validation = tf.convert_to_tensor(windows_ecg_validation, dtype=tf.float32)\n",
    "        windows_resp_validation = tf.convert_to_tensor(windows_resp_validation, dtype=tf.float32)\n",
    "        #windows_ecg_test = tf.convert_to_tensor(windows_ecg_test, dtype=tf.float32)\n",
    "        #windows_resp_test = tf.convert_to_tensor(windows_resp_test, dtype=tf.float32)\n",
    "\"\"\"\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "import uuid\n",
    "import datetime\n",
    "# Define your hyperparameters\n",
    "learning_rate = hp.HParam('learning_rate', hp.RealInterval(0.001, 0.1))\n",
    "start_filters = hp.HParam('start_filters', hp.Discrete([8, 16, 32, 64]))\n",
    "input_size = hp.HParam('input_size', hp.Discrete([1024]))\n",
    "kernel_size = hp.HParam('kernel_size', hp.Discrete([3, 5, 7, 27]))\n",
    "reg = hp.HParam('reg', hp.RealInterval(0.00001, 0.01))\n",
    "dropout = hp.HParam('dropout', hp.RealInterval(0.1, 0.9))\n",
    "batch_size = hp.HParam('batch_size', hp.Discrete([32, 64, 128, 256]))\n",
    "split_ind = hp.HParam('split_ind', hp.Discrete([0, 1, 2, 3, 4]))\n",
    "\n",
    "# Initialize your training function\n",
    "def train(config):\n",
    "    # Configure the logging directory for TensorBoard\n",
    "    run_id = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    log_dir = f\"logs/hparam_tuning/{run_id}\"\n",
    "    tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1, write_graph=True, update_freq='epoch', profile_batch=2)\n",
    "\n",
    "    # Log the hyperparameters using TensorBoard\n",
    "    with tf.summary.create_file_writer(log_dir).as_default():\n",
    "        hp.hparams(config)  # log the values of the hyperparameters\n",
    "        # Continue with training after this\n",
    "\n",
    "    # Your optimizer, model creation, and callbacks configuration\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=config['learning_rate'])\n",
    "\n",
    "    # Assuming you have a function to create your model\n",
    "    model = create_model(config)\n",
    "    model.compile(loss='mse', metrics=[cross_correlation], optimizer=optimizer)\n",
    "\n",
    "    filepath = os.path.join('models', f'model_crossval{config[\"split_ind\"]}-size{config[\"start_filters\"]}-input{config[\"input_size\"]}-lr{config[\"learning_rate\"]}-kernel{config[\"kernel_size\"]}-reg{config[\"reg\"]}-dropout{config[\"dropout\"]}.h5')\n",
    "\n",
    "    visualize_callback = VisualiseCallback1(log_dir=log_dir)\n",
    "    callbacks = [\n",
    "        ModelCheckpoint(filepath, monitor='val_loss', save_best_only=True),\n",
    "        EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
    "        tensorboard_callback,\n",
    "        visualize_callback\n",
    "    ]\n",
    "\n",
    "    # Start training\n",
    "    model.fit(\n",
    "        windows_ecg_train, windows_resp_train,\n",
    "        epochs=200,\n",
    "        batch_size=config['batch_size'],\n",
    "        validation_data=(windows_ecg_validation, windows_resp_validation),\n",
    "        callbacks=callbacks\n",
    "    )\n",
    "\n",
    "    model.save(os.path.join('models',\n",
    "                            f'combined_model{config[\"split_ind\"]}-size{config[\"start_filters\"]}-input{config[\"input_size\"]}-lr{config[\"learning_rate\"]}-kernel{config[\"kernel_size\"]}-reg{config[\"reg\"]}-dropout{config[\"dropout\"]}.h5'))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d7d99a0-3adf-4159-957d-556b99f582f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-26T18:51:59.597484Z",
     "iopub.status.busy": "2024-04-26T18:51:59.597351Z",
     "iopub.status.idle": "2024-04-26T18:51:59.602820Z",
     "shell.execute_reply": "2024-04-26T18:51:59.602192Z",
     "shell.execute_reply.started": "2024-04-26T18:51:59.597473Z"
    }
   },
   "outputs": [],
   "source": [
    "def process_data_segment(data, window_size, downsampled_window_size, patient_indices):\n",
    "    overlap = 1 / 2\n",
    "\n",
    "    windows_ecg = []\n",
    "    windows_resp = []\n",
    "\n",
    "    for record_index in patient_indices:\n",
    "        N = len(data[record_index][0, :])\n",
    "        max_step = int(N // (window_size * overlap))\n",
    "        for step in range(1, max_step - 1):\n",
    "            start_idx = int(step) * int(window_size * overlap)\n",
    "            end_idx = start_idx + window_size\n",
    "            recrd_ecg = data[record_index][0, start_idx:end_idx]\n",
    "            recrd_resp = data[record_index][1, start_idx:end_idx]\n",
    "\n",
    "            if recrd_ecg.min() < recrd_ecg.max():\n",
    "                normalized_ecg = (recrd_ecg - recrd_ecg.min()) / (recrd_ecg.max() - recrd_ecg.min())\n",
    "                normalized_ecg = signal.resample(normalized_ecg, downsampled_window_size)\n",
    "\n",
    "                if recrd_resp.min() < recrd_resp.max():\n",
    "                    normalized_resp = (recrd_resp - recrd_resp.min()) / (recrd_resp.max() - recrd_resp.min())\n",
    "                    normalized_resp = signal.resample(normalized_resp, downsampled_window_size)\n",
    "                    \n",
    "                    windows_ecg.append(np.float32(normalized_ecg))\n",
    "                    windows_resp.append(np.float32(normalized_resp))\n",
    "\n",
    "    windows_ecg = np.array(windows_ecg)[:, :, np.newaxis]\n",
    "    windows_resp = np.array(windows_resp)[:, :, np.newaxis]\n",
    "\n",
    "    print(windows_ecg.shape)\n",
    "    print(windows_resp.shape)\n",
    "\n",
    "    return windows_ecg, windows_resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f22f52-9d39-4107-a00d-a493be6d55c4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-26T18:51:59.604587Z",
     "iopub.status.busy": "2024-04-26T18:51:59.604194Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(44274, 1024, 1)\n",
      "(44274, 1024, 1)\n",
      "(12430, 1024, 1)\n",
      "(12430, 1024, 1)\n",
      "GPU enabled\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-26 20:52:03.282770: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M1\n",
      "2024-04-26 20:52:03.282796: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 16.00 GB\n",
      "2024-04-26 20:52:03.282810: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 5.33 GB\n",
      "2024-04-26 20:52:03.283172: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:303] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-04-26 20:52:03.283363: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:269] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2024-04-26 20:52:03.396651: I tensorflow/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2024-04-26 20:52:03.396665: I tensorflow/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n",
      "2024-04-26 20:52:03.397335: I tensorflow/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 1024, 1)]            0         []                            \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)             (None, 1024, 8)              224       ['input_1[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization (Batch  (None, 1024, 8)              32        ['conv1d[0][0]']              \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)           (None, 1024, 8)              1736      ['batch_normalization[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_1 (Bat  (None, 1024, 8)              32        ['conv1d_1[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " max_pooling1d (MaxPooling1  (None, 512, 8)               0         ['batch_normalization_1[0][0]'\n",
      " D)                                                                 ]                             \n",
      "                                                                                                  \n",
      " conv1d_2 (Conv1D)           (None, 512, 16)              3472      ['max_pooling1d[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_2 (Bat  (None, 512, 16)              64        ['conv1d_2[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " conv1d_3 (Conv1D)           (None, 512, 16)              6928      ['batch_normalization_2[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " batch_normalization_3 (Bat  (None, 512, 16)              64        ['conv1d_3[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " dropout (Dropout)           (None, 512, 16)              0         ['batch_normalization_3[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " max_pooling1d_1 (MaxPoolin  (None, 256, 16)              0         ['dropout[0][0]']             \n",
      " g1D)                                                                                             \n",
      "                                                                                                  \n",
      " conv1d_4 (Conv1D)           (None, 256, 32)              13856     ['max_pooling1d_1[0][0]']     \n",
      "                                                                                                  \n",
      " batch_normalization_4 (Bat  (None, 256, 32)              128       ['conv1d_4[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " conv1d_5 (Conv1D)           (None, 256, 32)              27680     ['batch_normalization_4[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " batch_normalization_5 (Bat  (None, 256, 32)              128       ['conv1d_5[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " up_sampling1d (UpSampling1  (None, 512, 32)              0         ['batch_normalization_5[0][0]'\n",
      " D)                                                                 ]                             \n",
      "                                                                                                  \n",
      " conv1d_6 (Conv1D)           (None, 512, 32)              2080      ['up_sampling1d[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_6 (Bat  (None, 512, 32)              128       ['conv1d_6[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)   (None, 512, 48)              0         ['dropout[0][0]',             \n",
      "                                                                     'batch_normalization_6[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv1d_7 (Conv1D)           (None, 512, 16)              20752     ['concatenate[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_7 (Bat  (None, 512, 16)              64        ['conv1d_7[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " conv1d_8 (Conv1D)           (None, 512, 16)              6928      ['batch_normalization_7[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " batch_normalization_8 (Bat  (None, 512, 16)              64        ['conv1d_8[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)         (None, 512, 16)              0         ['batch_normalization_8[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " up_sampling1d_1 (UpSamplin  (None, 1024, 16)             0         ['dropout_1[0][0]']           \n",
      " g1D)                                                                                             \n",
      "                                                                                                  \n",
      " conv1d_9 (Conv1D)           (None, 1024, 16)             528       ['up_sampling1d_1[0][0]']     \n",
      "                                                                                                  \n",
      " batch_normalization_9 (Bat  (None, 1024, 16)             64        ['conv1d_9[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate  (None, 1024, 24)             0         ['batch_normalization_1[0][0]'\n",
      " )                                                                  , 'batch_normalization_9[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv1d_10 (Conv1D)          (None, 1024, 8)              5192      ['concatenate_1[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_10 (Ba  (None, 1024, 8)              32        ['conv1d_10[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv1d_11 (Conv1D)          (None, 1024, 8)              1736      ['batch_normalization_10[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " batch_normalization_11 (Ba  (None, 1024, 8)              32        ['conv1d_11[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv1d_12 (Conv1D)          (None, 1024, 1)              217       ['batch_normalization_11[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 92161 (360.00 KB)\n",
      "Trainable params: 91745 (358.38 KB)\n",
      "Non-trainable params: 416 (1.62 KB)\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-26 20:52:05.965954: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-04-26 20:52:07.146967: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node Adam/AssignAddVariableOp.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1/173 [..............................] - ETA: 28:16 - loss: 2.0859 - cross_correlation: -0.0193"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-26 20:52:13.817840: I tensorflow/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2024-04-26 20:52:13.817853: I tensorflow/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2/173 [..............................] - ETA: 1:27 - loss: 2.0147 - cross_correlation: -0.0193 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-26 20:52:14.316346: I tensorflow/tsl/profiler/lib/profiler_session.cc:70] Profiler session collecting data.\n",
      "2024-04-26 20:52:14.322175: I tensorflow/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n",
      "2024-04-26 20:52:14.324300: I tensorflow/tsl/profiler/rpc/client/save_profile.cc:144] Collecting XSpace to repository: logs/hparam_tuning/20240426-205203/plugins/profile/2024_04_26_20_52_14/Lanas-iMac.fritz.box.xplane.pb\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "173/173 [==============================] - ETA: 0s - loss: 0.5154 - cross_correlation: 0.0082"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-26 20:53:03.298367: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "/Users/lanacaldarevic/miniforge3/envs/tf_m1/lib/python3.9/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "173/173 [==============================] - 67s 333ms/step - loss: 0.5154 - cross_correlation: 0.0082 - val_loss: 0.3084 - val_cross_correlation: 0.0032\n",
      "Epoch 2/200\n",
      "173/173 [==============================] - 51s 293ms/step - loss: 0.2405 - cross_correlation: 0.0172 - val_loss: 0.2164 - val_cross_correlation: -0.0014\n",
      "Epoch 3/200\n",
      "173/173 [==============================] - 51s 296ms/step - loss: 0.2020 - cross_correlation: 0.0256 - val_loss: 0.1928 - val_cross_correlation: 0.0187\n",
      "Epoch 4/200\n",
      "173/173 [==============================] - 90s 518ms/step - loss: 0.1785 - cross_correlation: 0.0460 - val_loss: 0.1740 - val_cross_correlation: 0.0134\n",
      "Epoch 5/200\n",
      "173/173 [==============================] - 86s 498ms/step - loss: 0.1579 - cross_correlation: 0.1023 - val_loss: 0.1567 - val_cross_correlation: 0.0357\n",
      "Epoch 6/200\n",
      "173/173 [==============================] - 51s 294ms/step - loss: 0.1383 - cross_correlation: 0.2261 - val_loss: 0.1503 - val_cross_correlation: 0.2273\n",
      "Epoch 7/200\n",
      "173/173 [==============================] - 49s 282ms/step - loss: 0.1181 - cross_correlation: 0.4074 - val_loss: 0.1466 - val_cross_correlation: 0.3291\n",
      "Epoch 8/200\n",
      "173/173 [==============================] - 47s 273ms/step - loss: 0.1008 - cross_correlation: 0.5375 - val_loss: 0.1281 - val_cross_correlation: 0.3147\n",
      "Epoch 9/200\n",
      "173/173 [==============================] - 52s 303ms/step - loss: 0.0899 - cross_correlation: 0.5925 - val_loss: 0.1177 - val_cross_correlation: 0.3641\n",
      "Epoch 10/200\n",
      "173/173 [==============================] - 49s 280ms/step - loss: 0.0818 - cross_correlation: 0.6275 - val_loss: 0.1283 - val_cross_correlation: 0.3175\n",
      "Epoch 11/200\n",
      "173/173 [==============================] - 55s 316ms/step - loss: 0.0756 - cross_correlation: 0.6517 - val_loss: 0.1169 - val_cross_correlation: 0.3564\n",
      "Epoch 12/200\n",
      "173/173 [==============================] - 52s 299ms/step - loss: 0.0703 - cross_correlation: 0.6715 - val_loss: 0.1223 - val_cross_correlation: 0.2843\n",
      "Epoch 13/200\n",
      "173/173 [==============================] - 51s 295ms/step - loss: 0.0661 - cross_correlation: 0.6865 - val_loss: 0.1094 - val_cross_correlation: 0.3274\n",
      "Epoch 14/200\n",
      "173/173 [==============================] - 52s 300ms/step - loss: 0.0628 - cross_correlation: 0.6976 - val_loss: 0.1114 - val_cross_correlation: 0.3183\n",
      "Epoch 15/200\n",
      "173/173 [==============================] - 50s 288ms/step - loss: 0.0596 - cross_correlation: 0.7084 - val_loss: 0.1079 - val_cross_correlation: 0.3316\n",
      "Epoch 16/200\n",
      "173/173 [==============================] - 53s 306ms/step - loss: 0.0570 - cross_correlation: 0.7165 - val_loss: 0.1082 - val_cross_correlation: 0.3145\n",
      "Epoch 17/200\n",
      "173/173 [==============================] - 49s 283ms/step - loss: 0.0544 - cross_correlation: 0.7265 - val_loss: 0.1010 - val_cross_correlation: 0.3590\n",
      "Epoch 18/200\n",
      "173/173 [==============================] - 50s 288ms/step - loss: 0.0526 - cross_correlation: 0.7309 - val_loss: 0.0974 - val_cross_correlation: 0.3257\n",
      "Epoch 19/200\n",
      "173/173 [==============================] - 52s 300ms/step - loss: 0.0508 - cross_correlation: 0.7357 - val_loss: 0.1035 - val_cross_correlation: 0.3308\n",
      "Epoch 20/200\n",
      "173/173 [==============================] - 52s 299ms/step - loss: 0.0493 - cross_correlation: 0.7401 - val_loss: 0.1012 - val_cross_correlation: 0.3389\n",
      "Epoch 21/200\n",
      "173/173 [==============================] - 49s 283ms/step - loss: 0.0476 - cross_correlation: 0.7463 - val_loss: 0.1000 - val_cross_correlation: 0.3590\n",
      "Epoch 22/200\n",
      "173/173 [==============================] - 48s 277ms/step - loss: 0.0465 - cross_correlation: 0.7487 - val_loss: 0.0961 - val_cross_correlation: 0.3721\n",
      "Epoch 23/200\n",
      "173/173 [==============================] - 48s 275ms/step - loss: 0.0452 - cross_correlation: 0.7530 - val_loss: 0.1001 - val_cross_correlation: 0.3635\n",
      "Epoch 24/200\n",
      "173/173 [==============================] - 48s 276ms/step - loss: 0.0442 - cross_correlation: 0.7556 - val_loss: 0.0929 - val_cross_correlation: 0.3663\n",
      "Epoch 25/200\n",
      "173/173 [==============================] - 47s 271ms/step - loss: 0.0432 - cross_correlation: 0.7591 - val_loss: 0.0898 - val_cross_correlation: 0.3820\n",
      "Epoch 26/200\n",
      "173/173 [==============================] - 47s 269ms/step - loss: 0.0424 - cross_correlation: 0.7606 - val_loss: 0.0904 - val_cross_correlation: 0.3670\n",
      "Epoch 27/200\n",
      "173/173 [==============================] - 50s 289ms/step - loss: 0.0416 - cross_correlation: 0.7636 - val_loss: 0.0922 - val_cross_correlation: 0.3726\n",
      "Epoch 28/200\n",
      "173/173 [==============================] - 49s 283ms/step - loss: 0.0410 - cross_correlation: 0.7644 - val_loss: 0.0928 - val_cross_correlation: 0.3734\n",
      "Epoch 29/200\n",
      "173/173 [==============================] - 51s 292ms/step - loss: 0.0403 - cross_correlation: 0.7675 - val_loss: 0.0914 - val_cross_correlation: 0.3565\n",
      "Epoch 30/200\n",
      "173/173 [==============================] - 51s 295ms/step - loss: 0.0397 - cross_correlation: 0.7693 - val_loss: 0.0901 - val_cross_correlation: 0.3376\n",
      "Epoch 31/200\n",
      "173/173 [==============================] - 51s 294ms/step - loss: 0.0394 - cross_correlation: 0.7700 - val_loss: 0.0893 - val_cross_correlation: 0.3720\n",
      "Epoch 32/200\n",
      "173/173 [==============================] - 50s 288ms/step - loss: 0.0388 - cross_correlation: 0.7724 - val_loss: 0.0905 - val_cross_correlation: 0.3778\n",
      "Epoch 33/200\n",
      "173/173 [==============================] - 50s 288ms/step - loss: 0.0384 - cross_correlation: 0.7732 - val_loss: 0.0906 - val_cross_correlation: 0.3765\n",
      "Epoch 34/200\n",
      "173/173 [==============================] - 52s 299ms/step - loss: 0.0381 - cross_correlation: 0.7744 - val_loss: 0.0869 - val_cross_correlation: 0.3561\n",
      "Epoch 35/200\n",
      "173/173 [==============================] - 65s 378ms/step - loss: 0.0377 - cross_correlation: 0.7758 - val_loss: 0.0855 - val_cross_correlation: 0.3992\n",
      "Epoch 36/200\n",
      "173/173 [==============================] - 131s 757ms/step - loss: 0.0372 - cross_correlation: 0.7780 - val_loss: 0.0806 - val_cross_correlation: 0.4056\n",
      "Epoch 37/200\n",
      "173/173 [==============================] - 66s 381ms/step - loss: 0.0368 - cross_correlation: 0.7798 - val_loss: 0.0823 - val_cross_correlation: 0.4225\n",
      "Epoch 38/200\n",
      "173/173 [==============================] - 83s 482ms/step - loss: 0.0367 - cross_correlation: 0.7808 - val_loss: 0.0853 - val_cross_correlation: 0.4061\n",
      "Epoch 39/200\n",
      "173/173 [==============================] - 171s 991ms/step - loss: 0.0364 - cross_correlation: 0.7817 - val_loss: 0.0858 - val_cross_correlation: 0.4044\n",
      "Epoch 40/200\n",
      "173/173 [==============================] - 950s 6s/step - loss: 0.0360 - cross_correlation: 0.7833 - val_loss: 0.0871 - val_cross_correlation: 0.3493\n",
      "Epoch 41/200\n",
      "173/173 [==============================] - 50s 289ms/step - loss: 0.0359 - cross_correlation: 0.7838 - val_loss: 0.0802 - val_cross_correlation: 0.4002\n",
      "Epoch 42/200\n",
      "173/173 [==============================] - 47s 272ms/step - loss: 0.0355 - cross_correlation: 0.7852 - val_loss: 0.0814 - val_cross_correlation: 0.4070\n",
      "Epoch 43/200\n",
      "173/173 [==============================] - 85s 491ms/step - loss: 0.0353 - cross_correlation: 0.7865 - val_loss: 0.0805 - val_cross_correlation: 0.4320\n",
      "Epoch 44/200\n",
      "173/173 [==============================] - 49s 285ms/step - loss: 0.0351 - cross_correlation: 0.7874 - val_loss: 0.0830 - val_cross_correlation: 0.4037\n",
      "Epoch 45/200\n",
      "173/173 [==============================] - 50s 288ms/step - loss: 0.0348 - cross_correlation: 0.7895 - val_loss: 0.0869 - val_cross_correlation: 0.3818\n",
      "Epoch 46/200\n",
      "173/173 [==============================] - 48s 279ms/step - loss: 0.0345 - cross_correlation: 0.7903 - val_loss: 0.0808 - val_cross_correlation: 0.3859\n",
      "Epoch 47/200\n",
      "173/173 [==============================] - 306s 2s/step - loss: 0.0344 - cross_correlation: 0.7910 - val_loss: 0.0834 - val_cross_correlation: 0.3940\n",
      "Epoch 48/200\n",
      "173/173 [==============================] - 946s 6s/step - loss: 0.0343 - cross_correlation: 0.7914 - val_loss: 0.0824 - val_cross_correlation: 0.4168\n",
      "Epoch 49/200\n",
      "173/173 [==============================] - 48s 276ms/step - loss: 0.0342 - cross_correlation: 0.7917 - val_loss: 0.0894 - val_cross_correlation: 0.3757\n",
      "Epoch 50/200\n",
      "173/173 [==============================] - 48s 278ms/step - loss: 0.0340 - cross_correlation: 0.7927 - val_loss: 0.0830 - val_cross_correlation: 0.4241\n",
      "Epoch 51/200\n",
      "173/173 [==============================] - 49s 282ms/step - loss: 0.0337 - cross_correlation: 0.7941 - val_loss: 0.0749 - val_cross_correlation: 0.4668\n",
      "Epoch 52/200\n",
      "173/173 [==============================] - 948s 6s/step - loss: 0.0337 - cross_correlation: 0.7950 - val_loss: 0.0829 - val_cross_correlation: 0.4362\n",
      "Epoch 53/200\n",
      "173/173 [==============================] - 47s 271ms/step - loss: 0.0335 - cross_correlation: 0.7952 - val_loss: 0.0849 - val_cross_correlation: 0.4005\n",
      "Epoch 54/200\n",
      "173/173 [==============================] - 202s 1s/step - loss: 0.0333 - cross_correlation: 0.7971 - val_loss: 0.0874 - val_cross_correlation: 0.4086\n",
      "Epoch 55/200\n",
      "173/173 [==============================] - 96s 555ms/step - loss: 0.0333 - cross_correlation: 0.7967 - val_loss: 0.0824 - val_cross_correlation: 0.3735\n",
      "Epoch 56/200\n",
      "173/173 [==============================] - 58s 337ms/step - loss: 0.0331 - cross_correlation: 0.7976 - val_loss: 0.0801 - val_cross_correlation: 0.4105\n",
      "Epoch 57/200\n",
      "173/173 [==============================] - 119s 691ms/step - loss: 0.0328 - cross_correlation: 0.7990 - val_loss: 0.0836 - val_cross_correlation: 0.4442\n",
      "Epoch 58/200\n",
      "173/173 [==============================] - 323s 2s/step - loss: 0.0329 - cross_correlation: 0.7986 - val_loss: 0.0770 - val_cross_correlation: 0.4394\n",
      "Epoch 59/200\n",
      "173/173 [==============================] - 57s 326ms/step - loss: 0.0327 - cross_correlation: 0.7995 - val_loss: 0.0841 - val_cross_correlation: 0.3967\n",
      "Epoch 60/200\n",
      "173/173 [==============================] - 47s 269ms/step - loss: 0.0325 - cross_correlation: 0.8007 - val_loss: 0.0823 - val_cross_correlation: 0.4253\n",
      "Epoch 61/200\n",
      "173/173 [==============================] - 47s 272ms/step - loss: 0.0325 - cross_correlation: 0.8002 - val_loss: 0.0755 - val_cross_correlation: 0.4613\n",
      "389/389 [==============================] - 26s 66ms/step - loss: 0.0749 - cross_correlation: 0.4697\n",
      "(44144, 1024, 1)\n",
      "(44144, 1024, 1)\n",
      "(12560, 1024, 1)\n",
      "(12560, 1024, 1)\n",
      "GPU enabled\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-26 22:48:11.151796: I tensorflow/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2024-04-26 22:48:11.151827: I tensorflow/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n",
      "2024-04-26 22:48:11.154958: I tensorflow/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)        [(None, 1024, 1)]            0         []                            \n",
      "                                                                                                  \n",
      " conv1d_13 (Conv1D)          (None, 1024, 8)              224       ['input_2[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_12 (Ba  (None, 1024, 8)              32        ['conv1d_13[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv1d_14 (Conv1D)          (None, 1024, 8)              1736      ['batch_normalization_12[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " batch_normalization_13 (Ba  (None, 1024, 8)              32        ['conv1d_14[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " max_pooling1d_2 (MaxPoolin  (None, 512, 8)               0         ['batch_normalization_13[0][0]\n",
      " g1D)                                                               ']                            \n",
      "                                                                                                  \n",
      " conv1d_15 (Conv1D)          (None, 512, 16)              3472      ['max_pooling1d_2[0][0]']     \n",
      "                                                                                                  \n",
      " batch_normalization_14 (Ba  (None, 512, 16)              64        ['conv1d_15[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv1d_16 (Conv1D)          (None, 512, 16)              6928      ['batch_normalization_14[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " batch_normalization_15 (Ba  (None, 512, 16)              64        ['conv1d_16[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)         (None, 512, 16)              0         ['batch_normalization_15[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " max_pooling1d_3 (MaxPoolin  (None, 256, 16)              0         ['dropout_2[0][0]']           \n",
      " g1D)                                                                                             \n",
      "                                                                                                  \n",
      " conv1d_17 (Conv1D)          (None, 256, 32)              13856     ['max_pooling1d_3[0][0]']     \n",
      "                                                                                                  \n",
      " batch_normalization_16 (Ba  (None, 256, 32)              128       ['conv1d_17[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv1d_18 (Conv1D)          (None, 256, 32)              27680     ['batch_normalization_16[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " batch_normalization_17 (Ba  (None, 256, 32)              128       ['conv1d_18[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " up_sampling1d_2 (UpSamplin  (None, 512, 32)              0         ['batch_normalization_17[0][0]\n",
      " g1D)                                                               ']                            \n",
      "                                                                                                  \n",
      " conv1d_19 (Conv1D)          (None, 512, 32)              2080      ['up_sampling1d_2[0][0]']     \n",
      "                                                                                                  \n",
      " batch_normalization_18 (Ba  (None, 512, 32)              128       ['conv1d_19[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate  (None, 512, 48)              0         ['dropout_2[0][0]',           \n",
      " )                                                                   'batch_normalization_18[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv1d_20 (Conv1D)          (None, 512, 16)              20752     ['concatenate_2[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_19 (Ba  (None, 512, 16)              64        ['conv1d_20[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv1d_21 (Conv1D)          (None, 512, 16)              6928      ['batch_normalization_19[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " batch_normalization_20 (Ba  (None, 512, 16)              64        ['conv1d_21[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)         (None, 512, 16)              0         ['batch_normalization_20[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " up_sampling1d_3 (UpSamplin  (None, 1024, 16)             0         ['dropout_3[0][0]']           \n",
      " g1D)                                                                                             \n",
      "                                                                                                  \n",
      " conv1d_22 (Conv1D)          (None, 1024, 16)             528       ['up_sampling1d_3[0][0]']     \n",
      "                                                                                                  \n",
      " batch_normalization_21 (Ba  (None, 1024, 16)             64        ['conv1d_22[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate  (None, 1024, 24)             0         ['batch_normalization_13[0][0]\n",
      " )                                                                  ',                            \n",
      "                                                                     'batch_normalization_21[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv1d_23 (Conv1D)          (None, 1024, 8)              5192      ['concatenate_3[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_22 (Ba  (None, 1024, 8)              32        ['conv1d_23[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv1d_24 (Conv1D)          (None, 1024, 8)              1736      ['batch_normalization_22[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " batch_normalization_23 (Ba  (None, 1024, 8)              32        ['conv1d_24[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv1d_25 (Conv1D)          (None, 1024, 1)              217       ['batch_normalization_23[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 92161 (360.00 KB)\n",
      "Trainable params: 91745 (358.38 KB)\n",
      "Non-trainable params: 416 (1.62 KB)\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-26 22:48:13.510387: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-04-26 22:48:14.785606: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node Adam/AssignAddVariableOp.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1/173 [..............................] - ETA: 29:33 - loss: 2.3811 - cross_correlation: 0.0152"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-26 22:48:21.832654: I tensorflow/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2024-04-26 22:48:21.832663: I tensorflow/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2/173 [..............................] - ETA: 1:39 - loss: 2.3149 - cross_correlation: 0.0141 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-26 22:48:22.399044: I tensorflow/tsl/profiler/lib/profiler_session.cc:70] Profiler session collecting data.\n",
      "2024-04-26 22:48:22.404676: I tensorflow/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n",
      "2024-04-26 22:48:22.407253: I tensorflow/tsl/profiler/rpc/client/save_profile.cc:144] Collecting XSpace to repository: logs/hparam_tuning/20240426-224811/plugins/profile/2024_04_26_22_48_22/Lanas-iMac.fritz.box.xplane.pb\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "173/173 [==============================] - ETA: 0s - loss: 0.5802 - cross_correlation: 0.0093"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-26 22:49:13.555550: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "173/173 [==============================] - 69s 343ms/step - loss: 0.5802 - cross_correlation: 0.0093 - val_loss: 0.2834 - val_cross_correlation: 0.0173\n",
      "Epoch 2/200\n",
      "173/173 [==============================] - 52s 300ms/step - loss: 0.2383 - cross_correlation: 0.0192 - val_loss: 0.2190 - val_cross_correlation: 0.0261\n",
      "Epoch 3/200\n",
      "173/173 [==============================] - 52s 298ms/step - loss: 0.2070 - cross_correlation: 0.0320 - val_loss: 0.1923 - val_cross_correlation: 0.0213\n",
      "Epoch 4/200\n",
      "173/173 [==============================] - 52s 303ms/step - loss: 0.1844 - cross_correlation: 0.0511 - val_loss: 0.1684 - val_cross_correlation: 0.0439\n",
      "Epoch 5/200\n",
      "173/173 [==============================] - 51s 297ms/step - loss: 0.1643 - cross_correlation: 0.1061 - val_loss: 0.1508 - val_cross_correlation: 0.0673\n",
      "Epoch 6/200\n",
      "173/173 [==============================] - 49s 283ms/step - loss: 0.1449 - cross_correlation: 0.2313 - val_loss: 0.1373 - val_cross_correlation: 0.1092\n",
      "Epoch 7/200\n",
      "173/173 [==============================] - 53s 308ms/step - loss: 0.1251 - cross_correlation: 0.3790 - val_loss: 0.1377 - val_cross_correlation: 0.1044\n",
      "Epoch 8/200\n",
      "173/173 [==============================] - 53s 307ms/step - loss: 0.1074 - cross_correlation: 0.5065 - val_loss: 0.1241 - val_cross_correlation: 0.1674\n",
      "Epoch 9/200\n",
      "173/173 [==============================] - 53s 305ms/step - loss: 0.0937 - cross_correlation: 0.5923 - val_loss: 0.1184 - val_cross_correlation: 0.2093\n",
      "Epoch 10/200\n",
      "173/173 [==============================] - 188s 1s/step - loss: 0.0843 - cross_correlation: 0.6369 - val_loss: 0.1199 - val_cross_correlation: 0.2410\n",
      "Epoch 11/200\n",
      "173/173 [==============================] - 950s 6s/step - loss: 0.0778 - cross_correlation: 0.6630 - val_loss: 0.1151 - val_cross_correlation: 0.2526\n",
      "Epoch 12/200\n",
      "173/173 [==============================] - 51s 296ms/step - loss: 0.0724 - cross_correlation: 0.6826 - val_loss: 0.1081 - val_cross_correlation: 0.2627\n",
      "Epoch 13/200\n",
      "173/173 [==============================] - 949s 6s/step - loss: 0.0682 - cross_correlation: 0.6966 - val_loss: 0.1084 - val_cross_correlation: 0.2632\n",
      "Epoch 14/200\n",
      "173/173 [==============================] - 50s 289ms/step - loss: 0.0644 - cross_correlation: 0.7092 - val_loss: 0.1108 - val_cross_correlation: 0.2609\n",
      "Epoch 15/200\n",
      "173/173 [==============================] - 50s 286ms/step - loss: 0.0615 - cross_correlation: 0.7190 - val_loss: 0.1007 - val_cross_correlation: 0.2745\n",
      "Epoch 16/200\n",
      "173/173 [==============================] - 484s 3s/step - loss: 0.0589 - cross_correlation: 0.7274 - val_loss: 0.1052 - val_cross_correlation: 0.2220\n",
      "Epoch 17/200\n",
      "173/173 [==============================] - 53s 306ms/step - loss: 0.0567 - cross_correlation: 0.7329 - val_loss: 0.1070 - val_cross_correlation: 0.2225\n",
      "Epoch 18/200\n",
      "173/173 [==============================] - 51s 293ms/step - loss: 0.0547 - cross_correlation: 0.7398 - val_loss: 0.0971 - val_cross_correlation: 0.2081\n",
      "Epoch 19/200\n",
      "173/173 [==============================] - 52s 302ms/step - loss: 0.0529 - cross_correlation: 0.7445 - val_loss: 0.1125 - val_cross_correlation: 0.2204\n",
      "Epoch 20/200\n",
      "173/173 [==============================] - 50s 291ms/step - loss: 0.0513 - cross_correlation: 0.7502 - val_loss: 0.1116 - val_cross_correlation: 0.2131\n",
      "Epoch 21/200\n",
      "173/173 [==============================] - 51s 295ms/step - loss: 0.0498 - cross_correlation: 0.7550 - val_loss: 0.1053 - val_cross_correlation: 0.1619\n",
      "Epoch 22/200\n",
      "173/173 [==============================] - 49s 285ms/step - loss: 0.0484 - cross_correlation: 0.7587 - val_loss: 0.1030 - val_cross_correlation: 0.1970\n",
      "Epoch 23/200\n",
      "173/173 [==============================] - 50s 291ms/step - loss: 0.0470 - cross_correlation: 0.7650 - val_loss: 0.1064 - val_cross_correlation: 0.1478\n",
      "Epoch 24/200\n",
      "173/173 [==============================] - 54s 309ms/step - loss: 0.0462 - cross_correlation: 0.7655 - val_loss: 0.1044 - val_cross_correlation: 0.1609\n",
      "Epoch 25/200\n",
      "173/173 [==============================] - 54s 315ms/step - loss: 0.0451 - cross_correlation: 0.7694 - val_loss: 0.1076 - val_cross_correlation: 0.2168\n",
      "Epoch 26/200\n",
      "173/173 [==============================] - 67s 388ms/step - loss: 0.0442 - cross_correlation: 0.7733 - val_loss: 0.1030 - val_cross_correlation: 0.2068\n",
      "Epoch 27/200\n",
      "173/173 [==============================] - 52s 298ms/step - loss: 0.0435 - cross_correlation: 0.7744 - val_loss: 0.1030 - val_cross_correlation: 0.1813\n",
      "Epoch 28/200\n",
      "173/173 [==============================] - 57s 327ms/step - loss: 0.0427 - cross_correlation: 0.7771 - val_loss: 0.1171 - val_cross_correlation: 0.1840\n",
      "393/393 [==============================] - 35s 88ms/step - loss: 0.0971 - cross_correlation: 0.2059\n",
      "(46121, 1024, 1)\n",
      "(46121, 1024, 1)\n",
      "(10583, 1024, 1)\n",
      "(10583, 1024, 1)\n",
      "GPU enabled\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-26 23:53:02.123842: I tensorflow/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2024-04-26 23:53:02.123855: I tensorflow/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n",
      "2024-04-26 23:53:02.124607: I tensorflow/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)        [(None, 1024, 1)]            0         []                            \n",
      "                                                                                                  \n",
      " conv1d_26 (Conv1D)          (None, 1024, 8)              224       ['input_3[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_24 (Ba  (None, 1024, 8)              32        ['conv1d_26[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv1d_27 (Conv1D)          (None, 1024, 8)              1736      ['batch_normalization_24[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " batch_normalization_25 (Ba  (None, 1024, 8)              32        ['conv1d_27[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " max_pooling1d_4 (MaxPoolin  (None, 512, 8)               0         ['batch_normalization_25[0][0]\n",
      " g1D)                                                               ']                            \n",
      "                                                                                                  \n",
      " conv1d_28 (Conv1D)          (None, 512, 16)              3472      ['max_pooling1d_4[0][0]']     \n",
      "                                                                                                  \n",
      " batch_normalization_26 (Ba  (None, 512, 16)              64        ['conv1d_28[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv1d_29 (Conv1D)          (None, 512, 16)              6928      ['batch_normalization_26[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " batch_normalization_27 (Ba  (None, 512, 16)              64        ['conv1d_29[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)         (None, 512, 16)              0         ['batch_normalization_27[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " max_pooling1d_5 (MaxPoolin  (None, 256, 16)              0         ['dropout_4[0][0]']           \n",
      " g1D)                                                                                             \n",
      "                                                                                                  \n",
      " conv1d_30 (Conv1D)          (None, 256, 32)              13856     ['max_pooling1d_5[0][0]']     \n",
      "                                                                                                  \n",
      " batch_normalization_28 (Ba  (None, 256, 32)              128       ['conv1d_30[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv1d_31 (Conv1D)          (None, 256, 32)              27680     ['batch_normalization_28[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " batch_normalization_29 (Ba  (None, 256, 32)              128       ['conv1d_31[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " up_sampling1d_4 (UpSamplin  (None, 512, 32)              0         ['batch_normalization_29[0][0]\n",
      " g1D)                                                               ']                            \n",
      "                                                                                                  \n",
      " conv1d_32 (Conv1D)          (None, 512, 32)              2080      ['up_sampling1d_4[0][0]']     \n",
      "                                                                                                  \n",
      " batch_normalization_30 (Ba  (None, 512, 32)              128       ['conv1d_32[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " concatenate_4 (Concatenate  (None, 512, 48)              0         ['dropout_4[0][0]',           \n",
      " )                                                                   'batch_normalization_30[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv1d_33 (Conv1D)          (None, 512, 16)              20752     ['concatenate_4[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_31 (Ba  (None, 512, 16)              64        ['conv1d_33[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv1d_34 (Conv1D)          (None, 512, 16)              6928      ['batch_normalization_31[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " batch_normalization_32 (Ba  (None, 512, 16)              64        ['conv1d_34[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " dropout_5 (Dropout)         (None, 512, 16)              0         ['batch_normalization_32[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " up_sampling1d_5 (UpSamplin  (None, 1024, 16)             0         ['dropout_5[0][0]']           \n",
      " g1D)                                                                                             \n",
      "                                                                                                  \n",
      " conv1d_35 (Conv1D)          (None, 1024, 16)             528       ['up_sampling1d_5[0][0]']     \n",
      "                                                                                                  \n",
      " batch_normalization_33 (Ba  (None, 1024, 16)             64        ['conv1d_35[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " concatenate_5 (Concatenate  (None, 1024, 24)             0         ['batch_normalization_25[0][0]\n",
      " )                                                                  ',                            \n",
      "                                                                     'batch_normalization_33[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv1d_36 (Conv1D)          (None, 1024, 8)              5192      ['concatenate_5[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_34 (Ba  (None, 1024, 8)              32        ['conv1d_36[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv1d_37 (Conv1D)          (None, 1024, 8)              1736      ['batch_normalization_34[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " batch_normalization_35 (Ba  (None, 1024, 8)              32        ['conv1d_37[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv1d_38 (Conv1D)          (None, 1024, 1)              217       ['batch_normalization_35[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 92161 (360.00 KB)\n",
      "Trainable params: 91745 (358.38 KB)\n",
      "Non-trainable params: 416 (1.62 KB)\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-26 23:53:04.127994: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-04-26 23:53:05.315732: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node Adam/AssignAddVariableOp.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1/181 [..............................] - ETA: 42:55 - loss: 2.2275 - cross_correlation: -0.0013"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-26 23:53:16.754194: I tensorflow/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2024-04-26 23:53:16.754206: I tensorflow/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2/181 [..............................] - ETA: 2:04 - loss: 2.1610 - cross_correlation: -0.0047 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-26 23:53:17.438574: I tensorflow/tsl/profiler/lib/profiler_session.cc:70] Profiler session collecting data.\n",
      "2024-04-26 23:53:17.443173: I tensorflow/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n",
      "2024-04-26 23:53:17.445250: I tensorflow/tsl/profiler/rpc/client/save_profile.cc:144] Collecting XSpace to repository: logs/hparam_tuning/20240426-235302/plugins/profile/2024_04_26_23_53_17/Lanas-iMac.fritz.box.xplane.pb\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "181/181 [==============================] - ETA: 0s - loss: 0.4826 - cross_correlation: 0.0049"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-26 23:54:15.010247: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "181/181 [==============================] - 80s 365ms/step - loss: 0.4826 - cross_correlation: 0.0049 - val_loss: 0.2689 - val_cross_correlation: 0.0072\n",
      "Epoch 2/200\n",
      "181/181 [==============================] - 57s 317ms/step - loss: 0.2274 - cross_correlation: 0.0132 - val_loss: 0.2090 - val_cross_correlation: -5.3242e-04\n",
      "Epoch 3/200\n",
      "181/181 [==============================] - 58s 323ms/step - loss: 0.1998 - cross_correlation: 0.0580 - val_loss: 0.1858 - val_cross_correlation: 0.0152\n",
      "Epoch 4/200\n",
      "181/181 [==============================] - 1029s 6s/step - loss: 0.1751 - cross_correlation: 0.1448 - val_loss: 0.1680 - val_cross_correlation: 0.0384\n",
      "Epoch 5/200\n",
      "181/181 [==============================] - 954s 5s/step - loss: 0.1520 - cross_correlation: 0.2522 - val_loss: 0.1495 - val_cross_correlation: 0.1098\n",
      "Epoch 6/200\n",
      "181/181 [==============================] - 58s 318ms/step - loss: 0.1322 - cross_correlation: 0.3515 - val_loss: 0.1332 - val_cross_correlation: 0.1846\n",
      "Epoch 7/200\n",
      "181/181 [==============================] - 1104s 6s/step - loss: 0.1158 - cross_correlation: 0.4311 - val_loss: 0.1214 - val_cross_correlation: 0.2442\n",
      "Epoch 8/200\n",
      "181/181 [==============================] - 56s 309ms/step - loss: 0.1022 - cross_correlation: 0.5063 - val_loss: 0.1094 - val_cross_correlation: 0.3479\n",
      "Epoch 9/200\n",
      "181/181 [==============================] - 55s 305ms/step - loss: 0.0919 - cross_correlation: 0.5558 - val_loss: 0.1057 - val_cross_correlation: 0.3285\n",
      "Epoch 10/200\n",
      "181/181 [==============================] - 145s 802ms/step - loss: 0.0841 - cross_correlation: 0.5889 - val_loss: 0.1048 - val_cross_correlation: 0.3260\n",
      "Epoch 11/200\n",
      "181/181 [==============================] - 54s 300ms/step - loss: 0.0782 - cross_correlation: 0.6110 - val_loss: 0.0900 - val_cross_correlation: 0.4343\n",
      "Epoch 12/200\n",
      "181/181 [==============================] - 955s 5s/step - loss: 0.0731 - cross_correlation: 0.6391 - val_loss: 0.0888 - val_cross_correlation: 0.4363\n",
      "Epoch 13/200\n",
      "181/181 [==============================] - 55s 303ms/step - loss: 0.0683 - cross_correlation: 0.6728 - val_loss: 0.0850 - val_cross_correlation: 0.4254\n",
      "Epoch 14/200\n",
      "181/181 [==============================] - 53s 294ms/step - loss: 0.0646 - cross_correlation: 0.6892 - val_loss: 0.0839 - val_cross_correlation: 0.4349\n",
      "Epoch 15/200\n",
      "181/181 [==============================] - 1034s 6s/step - loss: 0.0613 - cross_correlation: 0.7029 - val_loss: 0.0826 - val_cross_correlation: 0.4369\n",
      "Epoch 16/200\n",
      "181/181 [==============================] - 54s 296ms/step - loss: 0.0586 - cross_correlation: 0.7138 - val_loss: 0.0811 - val_cross_correlation: 0.4140\n",
      "Epoch 17/200\n",
      "181/181 [==============================] - 57s 314ms/step - loss: 0.0561 - cross_correlation: 0.7232 - val_loss: 0.0775 - val_cross_correlation: 0.4538\n",
      "Epoch 18/200\n",
      "181/181 [==============================] - 954s 5s/step - loss: 0.0541 - cross_correlation: 0.7303 - val_loss: 0.0805 - val_cross_correlation: 0.4384\n",
      "Epoch 19/200\n",
      "181/181 [==============================] - 52s 289ms/step - loss: 0.0520 - cross_correlation: 0.7386 - val_loss: 0.0762 - val_cross_correlation: 0.4373\n",
      "Epoch 20/200\n",
      "181/181 [==============================] - 52s 286ms/step - loss: 0.0501 - cross_correlation: 0.7464 - val_loss: 0.0810 - val_cross_correlation: 0.3802\n",
      "Epoch 21/200\n",
      "181/181 [==============================] - 951s 5s/step - loss: 0.0483 - cross_correlation: 0.7530 - val_loss: 0.0769 - val_cross_correlation: 0.4187\n",
      "Epoch 22/200\n",
      "181/181 [==============================] - 51s 280ms/step - loss: 0.0469 - cross_correlation: 0.7583 - val_loss: 0.0789 - val_cross_correlation: 0.4057\n",
      "Epoch 23/200\n",
      "181/181 [==============================] - 52s 286ms/step - loss: 0.0457 - cross_correlation: 0.7622 - val_loss: 0.0830 - val_cross_correlation: 0.4111\n",
      "Epoch 24/200\n",
      "181/181 [==============================] - 952s 5s/step - loss: 0.0445 - cross_correlation: 0.7673 - val_loss: 0.0819 - val_cross_correlation: 0.4178\n",
      "Epoch 25/200\n",
      "181/181 [==============================] - 52s 285ms/step - loss: 0.0434 - cross_correlation: 0.7712 - val_loss: 0.0738 - val_cross_correlation: 0.4437\n",
      "Epoch 26/200\n",
      "181/181 [==============================] - 52s 287ms/step - loss: 0.0425 - cross_correlation: 0.7742 - val_loss: 0.0797 - val_cross_correlation: 0.4042\n",
      "Epoch 27/200\n",
      "181/181 [==============================] - 952s 5s/step - loss: 0.0416 - cross_correlation: 0.7778 - val_loss: 0.0810 - val_cross_correlation: 0.3830\n",
      "Epoch 28/200\n",
      "181/181 [==============================] - 51s 285ms/step - loss: 0.0407 - cross_correlation: 0.7815 - val_loss: 0.0819 - val_cross_correlation: 0.3815\n",
      "Epoch 29/200\n",
      "181/181 [==============================] - 953s 5s/step - loss: 0.0401 - cross_correlation: 0.7837 - val_loss: 0.0831 - val_cross_correlation: 0.3455\n",
      "Epoch 30/200\n",
      "181/181 [==============================] - 53s 291ms/step - loss: 0.0395 - cross_correlation: 0.7859 - val_loss: 0.0887 - val_cross_correlation: 0.3515\n",
      "Epoch 31/200\n",
      "181/181 [==============================] - 53s 291ms/step - loss: 0.0390 - cross_correlation: 0.7881 - val_loss: 0.0798 - val_cross_correlation: 0.3973\n",
      "Epoch 32/200\n",
      "181/181 [==============================] - 411s 2s/step - loss: 0.0385 - cross_correlation: 0.7895 - val_loss: 0.0820 - val_cross_correlation: 0.3504\n",
      "Epoch 33/200\n",
      "181/181 [==============================] - 53s 291ms/step - loss: 0.0380 - cross_correlation: 0.7913 - val_loss: 0.0795 - val_cross_correlation: 0.3617\n",
      "Epoch 34/200\n",
      "181/181 [==============================] - 52s 287ms/step - loss: 0.0376 - cross_correlation: 0.7936 - val_loss: 0.0772 - val_cross_correlation: 0.4112\n",
      "Epoch 35/200\n",
      "181/181 [==============================] - 953s 5s/step - loss: 0.0370 - cross_correlation: 0.7961 - val_loss: 0.0838 - val_cross_correlation: 0.3395\n",
      "331/331 [==============================] - 27s 81ms/step - loss: 0.0738 - cross_correlation: 0.4478\n",
      "(45955, 1024, 1)\n",
      "(45955, 1024, 1)\n",
      "(10749, 1024, 1)\n",
      "(10749, 1024, 1)\n",
      "GPU enabled\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-27 03:22:49.552379: I tensorflow/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2024-04-27 03:22:49.552390: I tensorflow/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n",
      "2024-04-27 03:22:49.553164: I tensorflow/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_4 (InputLayer)        [(None, 1024, 1)]            0         []                            \n",
      "                                                                                                  \n",
      " conv1d_39 (Conv1D)          (None, 1024, 8)              224       ['input_4[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_36 (Ba  (None, 1024, 8)              32        ['conv1d_39[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv1d_40 (Conv1D)          (None, 1024, 8)              1736      ['batch_normalization_36[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " batch_normalization_37 (Ba  (None, 1024, 8)              32        ['conv1d_40[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " max_pooling1d_6 (MaxPoolin  (None, 512, 8)               0         ['batch_normalization_37[0][0]\n",
      " g1D)                                                               ']                            \n",
      "                                                                                                  \n",
      " conv1d_41 (Conv1D)          (None, 512, 16)              3472      ['max_pooling1d_6[0][0]']     \n",
      "                                                                                                  \n",
      " batch_normalization_38 (Ba  (None, 512, 16)              64        ['conv1d_41[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv1d_42 (Conv1D)          (None, 512, 16)              6928      ['batch_normalization_38[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " batch_normalization_39 (Ba  (None, 512, 16)              64        ['conv1d_42[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " dropout_6 (Dropout)         (None, 512, 16)              0         ['batch_normalization_39[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " max_pooling1d_7 (MaxPoolin  (None, 256, 16)              0         ['dropout_6[0][0]']           \n",
      " g1D)                                                                                             \n",
      "                                                                                                  \n",
      " conv1d_43 (Conv1D)          (None, 256, 32)              13856     ['max_pooling1d_7[0][0]']     \n",
      "                                                                                                  \n",
      " batch_normalization_40 (Ba  (None, 256, 32)              128       ['conv1d_43[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv1d_44 (Conv1D)          (None, 256, 32)              27680     ['batch_normalization_40[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " batch_normalization_41 (Ba  (None, 256, 32)              128       ['conv1d_44[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " up_sampling1d_6 (UpSamplin  (None, 512, 32)              0         ['batch_normalization_41[0][0]\n",
      " g1D)                                                               ']                            \n",
      "                                                                                                  \n",
      " conv1d_45 (Conv1D)          (None, 512, 32)              2080      ['up_sampling1d_6[0][0]']     \n",
      "                                                                                                  \n",
      " batch_normalization_42 (Ba  (None, 512, 32)              128       ['conv1d_45[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " concatenate_6 (Concatenate  (None, 512, 48)              0         ['dropout_6[0][0]',           \n",
      " )                                                                   'batch_normalization_42[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv1d_46 (Conv1D)          (None, 512, 16)              20752     ['concatenate_6[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_43 (Ba  (None, 512, 16)              64        ['conv1d_46[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv1d_47 (Conv1D)          (None, 512, 16)              6928      ['batch_normalization_43[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " batch_normalization_44 (Ba  (None, 512, 16)              64        ['conv1d_47[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " dropout_7 (Dropout)         (None, 512, 16)              0         ['batch_normalization_44[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " up_sampling1d_7 (UpSamplin  (None, 1024, 16)             0         ['dropout_7[0][0]']           \n",
      " g1D)                                                                                             \n",
      "                                                                                                  \n",
      " conv1d_48 (Conv1D)          (None, 1024, 16)             528       ['up_sampling1d_7[0][0]']     \n",
      "                                                                                                  \n",
      " batch_normalization_45 (Ba  (None, 1024, 16)             64        ['conv1d_48[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " concatenate_7 (Concatenate  (None, 1024, 24)             0         ['batch_normalization_37[0][0]\n",
      " )                                                                  ',                            \n",
      "                                                                     'batch_normalization_45[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv1d_49 (Conv1D)          (None, 1024, 8)              5192      ['concatenate_7[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_46 (Ba  (None, 1024, 8)              32        ['conv1d_49[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv1d_50 (Conv1D)          (None, 1024, 8)              1736      ['batch_normalization_46[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " batch_normalization_47 (Ba  (None, 1024, 8)              32        ['conv1d_50[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv1d_51 (Conv1D)          (None, 1024, 1)              217       ['batch_normalization_47[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 92161 (360.00 KB)\n",
      "Trainable params: 91745 (358.38 KB)\n",
      "Non-trainable params: 416 (1.62 KB)\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-27 03:22:51.544907: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-04-27 03:22:52.717332: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node Adam/AssignAddVariableOp.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1/180 [..............................] - ETA: 38:12 - loss: 2.3287 - cross_correlation: -0.0304"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-27 03:23:02.688588: I tensorflow/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2024-04-27 03:23:02.688601: I tensorflow/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2/180 [..............................] - ETA: 2:33 - loss: 2.2397 - cross_correlation: -0.0265 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-27 03:23:03.545426: I tensorflow/tsl/profiler/lib/profiler_session.cc:70] Profiler session collecting data.\n",
      "2024-04-27 03:23:03.548063: I tensorflow/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n",
      "2024-04-27 03:23:03.548358: I tensorflow/tsl/profiler/rpc/client/save_profile.cc:144] Collecting XSpace to repository: logs/hparam_tuning/20240427-032249/plugins/profile/2024_04_27_03_23_03/Lanas-iMac.fritz.box.xplane.pb\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - ETA: 0s - loss: 0.5380 - cross_correlation: 0.0116"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-27 03:24:03.923897: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 83s 391ms/step - loss: 0.5380 - cross_correlation: 0.0116 - val_loss: 0.3244 - val_cross_correlation: -0.0079\n",
      "Epoch 2/200\n",
      " 49/180 [=======>......................] - ETA: 38s - loss: 0.2514 - cross_correlation: 0.0258"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "results_mse = []\n",
    "results_corr = []\n",
    "results_cc = []\n",
    "downsampled_window_size = 1024\n",
    "window_size=int(downsampled_window_size*1.953125)\n",
    "train_ind = []\n",
    "val_ind = []\n",
    "\n",
    "k = 5\n",
    "kf = KFold(n_splits=k)\n",
    "\n",
    "# Now you can perform indexing\n",
    "for train_index, val_index in kf.split(train_val_patients_array):\n",
    "    train_ind.append(train_index)\n",
    "    val_ind.append(val_index)\n",
    "\n",
    "for split_ind in range(k):     # Run the garbage collector\n",
    "\n",
    "    train_index, val_index = train_ind[split_ind], val_ind[split_ind]\n",
    "    train_patients = [patients[i] for i in train_index]\n",
    "    val_patients = [patients[i] for i in val_index]\n",
    "\n",
    "    windows_ecg_train, windows_resp_train = process_data_segment(data, window_size, downsampled_window_size, train_patients)\n",
    "    windows_ecg_validation, windows_resp_validation = process_data_segment(data, window_size, downsampled_window_size, val_patients)\n",
    "\n",
    "    if tf.config.list_physical_devices('GPU'):\n",
    "        print(\"GPU enabled\")\n",
    "        with tf.device('/GPU:0'):\n",
    "            windows_ecg_train = tf.convert_to_tensor(windows_ecg_train, dtype=tf.float16)\n",
    "            windows_resp_train = tf.convert_to_tensor(windows_resp_train, dtype=tf.float16)\n",
    "            windows_ecg_validation = tf.convert_to_tensor(windows_ecg_validation, dtype=tf.float16)\n",
    "            windows_resp_validation = tf.convert_to_tensor(windows_resp_validation, dtype=tf.float16)\n",
    "    \n",
    "    config = {\n",
    "        'learning_rate': 3e-4,\n",
    "        'start_filters': 8,\n",
    "        'input_size': 1024,\n",
    "        'kernel_size': 27,\n",
    "        'reg': 0.0005,\n",
    "        'dropout': 0.6,\n",
    "        'batch_size': 256,\n",
    "        'split_ind': split_ind\n",
    "    }\n",
    "\n",
    "    model = train(config)\n",
    "    mse, cc = model.evaluate(windows_ecg_validation, windows_resp_validation)\n",
    "    results_cc.append(cc)\n",
    "    results_mse.append(mse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376de770-a67f-4c36-9e04-b1d2a14f349b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Average MSE performance across folds:\", np.mean(results_mse))\n",
    "print(\"Average CORR performance across folds:\", np.mean(results_corr))\n",
    "print(\"Average CC performance across folds:\", np.mean(results_cc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684f5a87-d8aa-4306-b87c-024af70b337c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def create_sweep_config():\n",
    "    return {\n",
    "        'method': 'random',\n",
    "        'metric': {\n",
    "            'name': 'val_loss',\n",
    "            'goal': 'minimize'\n",
    "        },\n",
    "        'parameters': {\n",
    "            'learning_rate': {\n",
    "                'values': [0.0003]\n",
    "               # 'min': 2e-4,\n",
    "               # 'max': 5e-3\n",
    "            },\n",
    "            'batch_size': {\n",
    "                'values': [256]\n",
    "            },\n",
    "            'kernel_size': {\n",
    "                'values': [27]\n",
    "            },\n",
    "            'reg': {\n",
    "                'min': 1e-5,\n",
    "                'max': 1e-2\n",
    "            },\n",
    "            'dropout': {\n",
    "                'min': 0.1,\n",
    "                'max': 0.9\n",
    "            },\n",
    "            'start_filters': {\n",
    "                'values': [8]\n",
    "            },\n",
    "            'input_size': {\n",
    "                'values': [1024]\n",
    "            },\n",
    "            'split_ind': {\n",
    "                'values': [0]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "sweep_config = create_sweep_config()\n",
    "sweep_id = wandb.sweep(sweep_config, project=\"biosignal_deeplearning\")\n",
    "\n",
    "# Run sweep\n",
    "wandb.agent(sweep_id, train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c104d1ec-ff7f-4ef6-a6dd-1fea03600ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss_curves(history):\n",
    "  \"\"\"\n",
    "  Returns separate loss curves for training and validation metrics.\n",
    "\n",
    "  Args:\n",
    "    history: TensorFlow model History object (see: https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/History)\n",
    "  \"\"\" \n",
    "  loss = history.history['loss']\n",
    "  val_loss = history.history['val_loss']\n",
    "\n",
    "  epochs = range(len(history.history['loss']))\n",
    "\n",
    "  # Plot loss\n",
    "  plt.plot(epochs, loss, label='training_loss')\n",
    "  plt.plot(epochs, val_loss, label='val_loss')\n",
    "  plt.title('Loss')\n",
    "  plt.xlabel('Epochs')\n",
    "  plt.legend();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4558c09f-2acd-4379-a69c-67a62d24ca87",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start_filters = 8\n",
    "input_size = 1024\n",
    "\n",
    "config = {\n",
    "        \"learning_rate\": 0.0003,\n",
    "        \"epochs\": 200,\n",
    "        \"batch_size\": 256,\n",
    "        \"start_filters\": start_filters,\n",
    "        \"input_size\": input_size,\n",
    "        \"kernel_size\": 27,\n",
    "        \"reg\": 0.0003,\n",
    "        \"dropout\": 0.2,\n",
    "        \"split_ind\": split_ind\n",
    "    }\n",
    "model = train(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc8bf0b-3ee4-4d81-a95b-8ade4bca139d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_curves(model.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a94db21-5985-46b2-93e7-951607f0d868",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the learning rate decay curve\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "lrs = 1e-3 * (10**(np.arange(50)/20))\n",
    "plt.semilogx(lrs, model.history.history['loss']) # want the x-axis to be log-scale\n",
    "plt.xlabel(\"Learning rate\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Finding the ideal learning rate\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5937e720-ed94-423c-bf77-cbfd2a717e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('models/model_crossval0-size8-input1024-lr0.009-kernel27-reg0.0002-dropout0.6.h5', custom_objects={'correlation':correlation})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffab717c-fe12-4538-94b8-69ef2576bc7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import neurokit2 as nk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec4fd03-64c6-4f81-bfe6-6bcacfda12aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "resp_predict = model(windows_ecg_validation)\n",
    "nk.signal_plot([resp_predict[0].numpy().flatten(), windows_resp_validation[0].numpy().flatten()], labels=['val_pred', 'val_true'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3daca0-c5ef-42bf-8be4-4b8a43da75df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check visually\n",
    "def plot_signals_in_grid(predicted_signals, true_signals, labels=['Predicted', 'True']):\n",
    "    fig, axs = plt.subplots(len(predicted_signals)//2, 2, figsize=(20, 50))\n",
    "    axs = axs.flatten() \n",
    "\n",
    "    for i in range(len(predicted_signals)):  \n",
    "        ax = axs[i]\n",
    "        pred_signal = predicted_signals[i]\n",
    "        true_signal = true_signals[i]\n",
    "\n",
    "        # Plotting both signals in the same subplot\n",
    "        ax.plot(pred_signal, label=labels[0])\n",
    "        ax.plot(true_signal, label=labels[1], alpha=0.75)\n",
    "        ax.legend()\n",
    "        ax.set_title(f'Example {i+1}')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78fc1d8-47f5-4f9f-8317-745dae0bdb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_signals_in_grid(resp_predict[0:50], windows_resp_validation[0:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a6260e-0835-4b7a-a3c5-0592c5f4b232",
   "metadata": {},
   "source": [
    "BIDMC: https://wandb.ai/lana-caldarevic1/biosignal_deeplearning/runs/i0kym9l5?nw=nwuserlanacaldarevic1\n",
    "\n",
    "Elena: https://wandb.ai/lana-caldarevic1/biosignal_deeplearning-phd_biosignal_deeplearning/runs/oyukl2uq?nw=nwuserlanacaldarevic1\n",
    "\n",
    "https://poloclub.github.io/cnn-explainer/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b9e393-fcce-406c-91a7-f4b194e52e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv1D, BatchNormalization, Activation, Concatenate, Add\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "def dilated_residual_inception_block(input_tensor, filters):\n",
    "    branches = []\n",
    "    dilation_rates = [2, 4, 8]\n",
    "\n",
    "    branch = Conv1D(filters=filters*4, kernel_size=1, padding='same')(input_tensor)\n",
    "    branch = BatchNormalization()(branch)\n",
    "    branches.append(branch)\n",
    "\n",
    "    for dilation_rate in dilation_rates:\n",
    "        branch = Conv1D(filters=filters, kernel_size=1, padding='same')(branch)\n",
    "        branch = BatchNormalization()(branch)\n",
    "        branch = Activation('relu')(branch)\n",
    "        \n",
    "        branch = Conv1D(filters=filters, kernel_size=3, dilation_rate=dilation_rate, padding='same')(branch)\n",
    "        branch = BatchNormalization()(branch)\n",
    "        branch = Activation('relu')(branch)\n",
    "\n",
    "        branches.append(branch)\n",
    "\n",
    "    concatenated = Concatenate()(branches)\n",
    "    residual_output = Add()([input_tensor, concatenated])\n",
    "\n",
    "    return residual_output\n",
    "\n",
    "\n",
    "def encoder_block(x, filters):\n",
    "    # Encoder uses 1x4 Conv with stride 4\n",
    "    x = Conv1D(filters, 4, strides=4, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "def decoder_block(x, shortcut, filters):\n",
    "    # Decoder uses 1x4 transposed Conv with stride 1 (since upsampling is separate)\n",
    "    x = Conv1D(filters, 4, padding='same')(x)\n",
    "    x = UpSampling1D(4)(x)\n",
    "    x = Concatenate()([x, shortcut])  # skip connection from the encoder\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "def build_respnet(input_shape):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    features = inputs.shape[1]\n",
    "\n",
    "    lvls = 8\n",
    "\n",
    "    # Encoder\n",
    "    e1 = encoder_block(inputs, 32)\n",
    "    print(e1.shape)\n",
    "    e2 = encoder_block(e1, 64)\n",
    "    print(e2.shape)\n",
    "    e3 = encoder_block(e2, 128)\n",
    "    print(e3.shape)\n",
    "    e4 = encoder_block(e3, 256)\n",
    "    print(e4.shape)\n",
    "    e5 = encoder_block(e4, 512)\n",
    "    print(e5.shape)\n",
    "\n",
    "    # Dilated residual inception block\n",
    "    bridge = dilated_residual_inception_block(e5, 512)\n",
    "\n",
    "    # Decoder\n",
    "    d1 = decoder_block(bridge, e4, 256)\n",
    "    d2 = decoder_block(d1, e3, 128)\n",
    "    d3 = decoder_block(d2, e2, 64)\n",
    "    d4 = decoder_block(d3, e1, 32)\n",
    "\n",
    "    # Output layer\n",
    "    outputs = Conv1D(1, 1, activation='sigmoid', padding='same')(d4)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "# Assuming input PPG signal is of shape (batch_size, 2048, 1)\n",
    "input_shape = (2048, 1)\n",
    "model = build_respnet(input_shape)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091cbaf6-ee1b-42a4-9cb7-0e9578dea6c6",
   "metadata": {},
   "source": [
    "```\n",
    "The proposed network is adapted from the IncResU-Net\n",
    "network [10] which was made for 2D medical image segmentation\n",
    "application. The architecture of the proposed fully\n",
    "convolutional network for performing Respiration signal\n",
    "extraction is shown in Fig. 1. The encoder section is divided\n",
    "into eight levels to perform the downsampling operation. A\n",
    "1D convolution operation of size 14 is used to downsample\n",
    "the input features. Instead of carrying out the downsampling\n",
    "operation using max-pooling, strided convolution is used\n",
    "instead to improve training efficiency [11]. The downsampling\n",
    "operation decreases the input size while increasing the\n",
    "number of filters at each encoder by a factor of two till the\n",
    "number of encoder filters are 512 after which subsequent\n",
    "encoder levels are maintained at 512 filters. In each encoder\n",
    "level, 1D Convolution with stride 4 is applied followed by\n",
    "Batch Normalization and leaky ReLU (with slope 0.2).\n",
    "The output of each encoder level is then provided to the\n",
    "dilated residual inception block is seen in Fig. 2. Usage\n",
    "of the dilated residual inception block provides a larger\n",
    "receptive field without a significant increase in parameters.\n",
    "Further the use of residual connections within the block\n",
    "is meant to greatly reduce the vanishing gradient problem\n",
    "and reduce the convergence time during training [12]. The\n",
    "decoder section of the proposed network utilizes feature\n",
    "concatenation between the feature map of the decoder block\n",
    "along with its corresponding encoder pair at the respective\n",
    "level similar to the original U-Net [6]. After performing\n",
    "convolution and dilated residual convolution operation, upsampling\n",
    "is performed using a deconvolution operation at\n",
    "each level of the decoder. In the final level of the decoder\n",
    "11 1D convolution operation is performed to map the\n",
    "features channels to the desired number of output channels.\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f567a98-c439-4a8d-bd4c-0a8aec463527",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import LeakyReLU\n",
    "def dilated_residual_inception_block(input_tensor, filters):\n",
    "    branches = []\n",
    "    dilation_rates = [2, 4, 8]\n",
    "\n",
    "    branch = Conv1D(filters=filters, kernel_size=1, padding='same')(input_tensor)\n",
    "    branch = BatchNormalization()(branch)\n",
    "    branches.append(branch)\n",
    "\n",
    "    for dilation_rate in dilation_rates:\n",
    "        branch = Conv1D(filters=filters, kernel_size=1, padding='same')(branch)\n",
    "        branch = BatchNormalization()(branch)\n",
    "        branch = Activation('relu')(branch)\n",
    "        \n",
    "        branch = Conv1D(filters=filters, kernel_size=3, dilation_rate=dilation_rate, padding='same')(branch)\n",
    "        branch = BatchNormalization()(branch)\n",
    "        branch = Activation('relu')(branch)\n",
    "\n",
    "        branches.append(branch)\n",
    "\n",
    "    concatenated = Concatenate()(branches)\n",
    "    residual_output = Add()([input_tensor, concatenated])\n",
    "\n",
    "    return residual_output\n",
    "\n",
    "def encoder_block(x, filters):\n",
    "    # Encoder uses 1x4 Conv with stride 4\n",
    "    x = Conv1D(filters, 4, strides=4, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    return x\n",
    "    \n",
    "x = Input(shape=(2048, 1))\n",
    "\n",
    "features = x.shape[2]\n",
    "\n",
    "lvls = 8\n",
    "\n",
    "for i in range(lvls):\n",
    "    features = features*2\n",
    "    print(f\"Lvl: {i+1}\")\n",
    "    print(f\"input shape: {x.shape}\")\n",
    "    print(f\"features: {features}\")\n",
    "    x = dilated_residual_inception_block(x, features)\n",
    "    print(f\"after diluted conv shape: {x.shape}\")\n",
    "    x = encoder_block(x, features)\n",
    "    print(f\"after encoder downsampling shape: {x.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726d4482-35ad-4228-80b9-3eb26d6f194e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf_m1)",
   "language": "python",
   "name": "tf_m1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
