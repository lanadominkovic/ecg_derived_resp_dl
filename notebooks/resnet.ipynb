{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a8c1069-e83d-4a2a-820c-613639415d95",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-16T13:12:35.916905Z",
     "iopub.status.busy": "2024-04-16T13:12:35.915920Z",
     "iopub.status.idle": "2024-04-16T13:12:36.369843Z",
     "shell.execute_reply": "2024-04-16T13:12:36.369092Z",
     "shell.execute_reply.started": "2024-04-16T13:12:35.916850Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 512, 32)\n",
      "(None, 128, 64)\n",
      "(None, 32, 128)\n",
      "(None, 8, 256)\n",
      "(None, 2, 512)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Inputs have incompatible shapes. Received shapes (2, 512) and (2, 2048)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 81\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;66;03m# Assuming input PPG signal is of shape (batch_size, 2048, 1)\u001b[39;00m\n\u001b[1;32m     80\u001b[0m input_shape \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m2048\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 81\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_respnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_shape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m model\u001b[38;5;241m.\u001b[39msummary()\n",
      "Cell \u001b[0;32mIn[4], line 65\u001b[0m, in \u001b[0;36mbuild_respnet\u001b[0;34m(input_shape)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28mprint\u001b[39m(e5\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     64\u001b[0m \u001b[38;5;66;03m# Dilated residual inception block\u001b[39;00m\n\u001b[0;32m---> 65\u001b[0m bridge \u001b[38;5;241m=\u001b[39m \u001b[43mdilated_residual_inception_block\u001b[49m\u001b[43m(\u001b[49m\u001b[43me5\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m512\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;66;03m# Decoder\u001b[39;00m\n\u001b[1;32m     68\u001b[0m d1 \u001b[38;5;241m=\u001b[39m decoder_block(bridge, e4, \u001b[38;5;241m256\u001b[39m)\n",
      "Cell \u001b[0;32mIn[4], line 25\u001b[0m, in \u001b[0;36mdilated_residual_inception_block\u001b[0;34m(input_tensor, filters)\u001b[0m\n\u001b[1;32m     22\u001b[0m     branches\u001b[38;5;241m.\u001b[39mappend(branch)\n\u001b[1;32m     24\u001b[0m concatenated \u001b[38;5;241m=\u001b[39m Concatenate()(branches)\n\u001b[0;32m---> 25\u001b[0m residual_output \u001b[38;5;241m=\u001b[39m \u001b[43mAdd\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43minput_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconcatenated\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m residual_output\n",
      "File \u001b[0;32m~/miniforge3/envs/tf_m1/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniforge3/envs/tf_m1/lib/python3.9/site-packages/keras/src/layers/merging/base_merge.py:74\u001b[0m, in \u001b[0;36m_Merge._compute_elemwise_op_output_shape\u001b[0;34m(self, shape1, shape2)\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     73\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m!=\u001b[39m j:\n\u001b[0;32m---> 74\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     75\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInputs have incompatible shapes. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     76\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived shapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mshape1\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mshape2\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     77\u001b[0m             )\n\u001b[1;32m     78\u001b[0m         output_shape\u001b[38;5;241m.\u001b[39mappend(i)\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(output_shape)\n",
      "\u001b[0;31mValueError\u001b[0m: Inputs have incompatible shapes. Received shapes (2, 512) and (2, 2048)"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv1D, BatchNormalization, Activation, Concatenate, Add\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "def dilated_residual_inception_block(input_tensor, filters):\n",
    "    branches = []\n",
    "    dilation_rates = [2, 4, 8]\n",
    "\n",
    "    branch = Conv1D(filters=filters, kernel_size=1, padding='same')(input_tensor)\n",
    "    branch = BatchNormalization()(branch)\n",
    "    branches.append(branch)\n",
    "\n",
    "    for dilation_rate in dilation_rates:\n",
    "        branch = Conv1D(filters=filters, kernel_size=1, padding='same')(branch)\n",
    "        branch = BatchNormalization()(branch)\n",
    "        branch = Activation('relu')(branch)\n",
    "        \n",
    "        branch = Conv1D(filters=filters, kernel_size=3, dilation_rate=dilation_rate, padding='same')(branch)\n",
    "        branch = BatchNormalization()(branch)\n",
    "        branch = Activation('relu')(branch)\n",
    "\n",
    "        branches.append(branch)\n",
    "\n",
    "    concatenated = Concatenate()(branches)\n",
    "    residual_output = Add()([input_tensor, concatenated])\n",
    "\n",
    "    return residual_output\n",
    "\n",
    "\n",
    "def encoder_block(x, filters):\n",
    "    # Encoder uses 1x4 Conv with stride 4\n",
    "    x = Conv1D(filters, 4, strides=4, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "def decoder_block(x, shortcut, filters):\n",
    "    # Decoder uses 1x4 transposed Conv with stride 1 (since upsampling is separate)\n",
    "    x = Conv1D(filters, 4, padding='same')(x)\n",
    "    x = UpSampling1D(4)(x)\n",
    "    x = Concatenate()([x, shortcut])  # skip connection from the encoder\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "def build_respnet(input_shape):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    features = inputs.shape[1]\n",
    "\n",
    "    lvls = 8\n",
    "\n",
    "    # Encoder\n",
    "    e1 = encoder_block(inputs, 32)\n",
    "    print(e1.shape)\n",
    "    e2 = encoder_block(e1, 64)\n",
    "    print(e2.shape)\n",
    "    e3 = encoder_block(e2, 128)\n",
    "    print(e3.shape)\n",
    "    e4 = encoder_block(e3, 256)\n",
    "    print(e4.shape)\n",
    "    e5 = encoder_block(e4, 512)\n",
    "    print(e5.shape)\n",
    "\n",
    "    # Dilated residual inception block\n",
    "    bridge = dilated_residual_inception_block(e5, 512)\n",
    "\n",
    "    # Decoder\n",
    "    d1 = decoder_block(bridge, e4, 256)\n",
    "    d2 = decoder_block(d1, e3, 128)\n",
    "    d3 = decoder_block(d2, e2, 64)\n",
    "    d4 = decoder_block(d3, e1, 32)\n",
    "\n",
    "    # Output layer\n",
    "    outputs = Conv1D(1, 1, activation='sigmoid', padding='same')(d4)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "# Assuming input PPG signal is of shape (batch_size, 2048, 1)\n",
    "input_shape = (2048, 1)\n",
    "model = build_respnet(input_shape)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab981ac8-9d16-46c9-a336-5516f9e37043",
   "metadata": {},
   "source": [
    "```\n",
    "The proposed network is adapted from the IncResU-Net\n",
    "network [10] which was made for 2D medical image segmentation\n",
    "application. The architecture of the proposed fully\n",
    "convolutional network for performing Respiration signal\n",
    "extraction is shown in Fig. 1. The encoder section is divided\n",
    "into eight levels to perform the downsampling operation. A\n",
    "1D convolution operation of size 1 4 is used to downsample\n",
    "the input features. Instead of carrying out the downsampling\n",
    "operation using max-pooling, strided convolution is used\n",
    "instead to improve training efficiency [11]. The downsampling\n",
    "operation decreases the input size while increasing the\n",
    "number of filters at each encoder by a factor of two till the\n",
    "number of encoder filters are 512 after which subsequent\n",
    "encoder levels are maintained at 512 filters. In each encoder\n",
    "level, 1D Convolution with stride 4 is applied followed by\n",
    "Batch Normalization and leaky ReLU (with slope 0.2).\n",
    "The output of each encoder level is then provided to the\n",
    "dilated residual inception block is seen in Fig. 2. Usage\n",
    "of the dilated residual inception block provides a larger\n",
    "receptive field without a significant increase in parameters.\n",
    "Further the use of residual connections within the block\n",
    "is meant to greatly reduce the vanishing gradient problem\n",
    "and reduce the convergence time during training [12]. The\n",
    "decoder section of the proposed network utilizes feature\n",
    "concatenation between the feature map of the decoder block\n",
    "along with its corresponding encoder pair at the respective\n",
    "level similar to the original U-Net [6]. After performing\n",
    "convolution and dilated residual convolution operation, upsampling\n",
    "is performed using a deconvolution operation at\n",
    "each level of the decoder. In the final level of the decoder\n",
    "1 1 1D convolution operation is performed to map the\n",
    "features channels to the desired number of output channels.\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1c99568-0401-4a4e-882c-8933ee26872a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-16T13:06:17.941575Z",
     "iopub.status.busy": "2024-04-16T13:06:17.940255Z",
     "iopub.status.idle": "2024-04-16T13:06:18.312845Z",
     "shell.execute_reply": "2024-04-16T13:06:18.311992Z",
     "shell.execute_reply.started": "2024-04-16T13:06:17.941507Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lvl: 1\n",
      "input shape: (None, 2048, 1)\n",
      "features: 2\n",
      "after diluted conv shape: (None, 2048, 8)\n",
      "after encoder downsampling shape: (None, 2048, 2)\n",
      "Lvl: 2\n",
      "input shape: (None, 2048, 2)\n",
      "features: 4\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Inputs have incompatible shapes. Received shapes (2048, 2) and (2048, 16)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 44\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeatures: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfeatures\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 44\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mdilated_residual_inception_block\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mafter diluted conv shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     46\u001b[0m x \u001b[38;5;241m=\u001b[39m encoder_block(x, features)\n",
      "Cell \u001b[0;32mIn[3], line 22\u001b[0m, in \u001b[0;36mdilated_residual_inception_block\u001b[0;34m(input_tensor, filters)\u001b[0m\n\u001b[1;32m     19\u001b[0m     branches\u001b[38;5;241m.\u001b[39mappend(branch)\n\u001b[1;32m     21\u001b[0m concatenated \u001b[38;5;241m=\u001b[39m Concatenate()(branches)\n\u001b[0;32m---> 22\u001b[0m residual_output \u001b[38;5;241m=\u001b[39m \u001b[43mAdd\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43minput_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconcatenated\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m residual_output\n",
      "File \u001b[0;32m~/miniforge3/envs/tf_m1/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniforge3/envs/tf_m1/lib/python3.9/site-packages/keras/src/layers/merging/base_merge.py:74\u001b[0m, in \u001b[0;36m_Merge._compute_elemwise_op_output_shape\u001b[0;34m(self, shape1, shape2)\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     73\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m!=\u001b[39m j:\n\u001b[0;32m---> 74\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     75\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInputs have incompatible shapes. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     76\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived shapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mshape1\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mshape2\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     77\u001b[0m             )\n\u001b[1;32m     78\u001b[0m         output_shape\u001b[38;5;241m.\u001b[39mappend(i)\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(output_shape)\n",
      "\u001b[0;31mValueError\u001b[0m: Inputs have incompatible shapes. Received shapes (2048, 2) and (2048, 16)"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import LeakyReLU\n",
    "def dilated_residual_inception_block(input_tensor, filters):\n",
    "    branches = []\n",
    "    dilation_rates = [2, 4, 8]\n",
    "\n",
    "    branch = Conv1D(filters=filters, kernel_size=1, padding='same')(input_tensor)\n",
    "    branch = BatchNormalization()(branch)\n",
    "    branches.append(branch)\n",
    "\n",
    "    for dilation_rate in dilation_rates:\n",
    "        branch = Conv1D(filters=filters, kernel_size=1, padding='same')(branch)\n",
    "        branch = BatchNormalization()(branch)\n",
    "        branch = Activation('relu')(branch)\n",
    "        \n",
    "        branch = Conv1D(filters=filters, kernel_size=3, dilation_rate=dilation_rate, padding='same')(branch)\n",
    "        branch = BatchNormalization()(branch)\n",
    "        branch = Activation('relu')(branch)\n",
    "\n",
    "        branches.append(branch)\n",
    "\n",
    "    concatenated = Concatenate()(branches)\n",
    "    residual_output = Add()([input_tensor, concatenated])\n",
    "\n",
    "    return residual_output\n",
    "\n",
    "def encoder_block(x, filters):\n",
    "    # Encoder uses 1x4 Conv with stride 4\n",
    "    x = Conv1D(filters, 4, strides=4, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    return x\n",
    "    \n",
    "x = Input(shape=(2048, 1))\n",
    "\n",
    "features = x.shape[2]\n",
    "\n",
    "lvls = 8\n",
    "\n",
    "for i in range(lvls):\n",
    "    features = features*2\n",
    "    print(f\"Lvl: {i+1}\")\n",
    "    print(f\"input shape: {x.shape}\")\n",
    "    print(f\"features: {features}\")\n",
    "    x = dilated_residual_inception_block(x, features)\n",
    "    print(f\"after diluted conv shape: {x.shape}\")\n",
    "    x = encoder_block(x, features)\n",
    "    print(f\"after encoder downsampling shape: {x.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e73b672-04c1-4a11-8944-ba373bc9b220",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf_m1)",
   "language": "python",
   "name": "tf_m1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
